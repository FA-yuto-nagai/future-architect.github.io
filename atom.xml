<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>フューチャー技術ブログ</title>
  <icon>https://future-architect.github.io/feed_icon.png</icon>
  <subtitle>Future Tech Blog</subtitle>
  <link href="https://future-architect.github.io/atom.xml" rel="self"/>
  
  <link href="https://future-architect.github.io/"/>
  <updated>2023-10-16T03:22:18.013Z</updated>
  <id>https://future-architect.github.io/</id>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Cloudflare R2でTerraformのStateを管理する方法: Cloudflare Meetup Nagano Vol.2 に登壇しました</title>
    <link href="https://future-architect.github.io/articles/20231016a/"/>
    <id>https://future-architect.github.io/articles/20231016a/</id>
    <published>2023-10-15T15:00:00.000Z</published>
    <updated>2023-10-16T03:22:18.013Z</updated>
    
    <content type="html"><![CDATA[<img src="/images/20231016a/cloudflare_nagano.png" alt="" width="660" height="371" loading="lazy"><p>イベントリンク： <a href="https://cfm-cts.connpass.com/event/295067/">https://cfm-cts.connpass.com/event/295067/</a></p><p>こんにちは。TIGの伊藤です。</p><p>10&#x2F;14に開催されたCloudflare Meetup Naganoに登壇したので発表内容のサマリとイベントのレポートです。</p><h2 id="当日のセッション内容"><a href="#当日のセッション内容" class="headerlink" title="当日のセッション内容"></a>当日のセッション内容</h2><p>当日のセッション内容は以下のスライドになります。</p><iframe class="speakerdeck-iframe" frameborder="0" src="https://speakerdeck.com/player/25755a81f5c64cebad8f4f8d4e3e4fc1" title="Cloudflare Meetup Nagano Vol.2" allowfullscreen="true" style="border: 0px; background: padding-box padding-box rgba(0, 0, 0, 0.1); margin: 0px; padding: 0px; border-radius: 6px; box-shadow: rgba(0, 0, 0, 0.2) 0px 5px 40px; width: 100%; height: auto; aspect-ratio: 560 / 315;" data-ratio="1.7777777777777777"></iframe><p><a href="https://github.com/kaedemalu/cf-teraform-handson">https://github.com/kaedemalu/cf-teraform-handson</a></p><h3 id="Cloudflare-R2でTerraformのStateを管理する方法"><a href="#Cloudflare-R2でTerraformのStateを管理する方法" class="headerlink" title="Cloudflare R2でTerraformのStateを管理する方法"></a>Cloudflare R2でTerraformのStateを管理する方法</h3><p>今回の登壇では、CloudflareのR2でTerraformのStateを管理できるのか、を調べたので、これを登壇ネタとしました。</p><p>TerraformのStateは一般的にはクラウドプロバイダーが提供するストレージサービスで管理します。例えばAWSであればS3、Google CloudであればGCSのようなものです。</p><p>この時に、S3にホストさせるのであればいかのようなブロックを書いてBackendの設定を行います。</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">terraform &#123;</span><br><span class="line">  backend <span class="string">&quot;s3&quot;</span> &#123;</span><br><span class="line">    bucket = <span class="string">&quot;sample-tfstate&quot;</span> <span class="comment"># バケット名</span></span><br><span class="line">    key    = <span class="string">&quot;state&quot;</span> <span class="comment"># オブジェクトのパスを指定</span></span><br><span class="line">    region = <span class="string">&quot;us-east-1&quot;</span> <span class="comment"># バケットのリージョン</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>もし、Cloudflareの管理はCloudflareのみで行いたい思いが出てきた時は、ストレージサービスであるR2をBackendとする場合、以下のように書けるとおよそ想像できます(サポートされている前提ですが)。</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">terraform &#123;</span><br><span class="line">  backend <span class="string">&quot;r2&quot;</span> &#123;</span><br><span class="line">    bucket = <span class="string">&quot;sample-tfstate&quot;</span></span><br><span class="line">    key    = <span class="string">&quot;state&quot;</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ただ、R2を直接的にBackendとして指定することは現時点では対応していない状態です。が、リクエストはTerraform側に出ています。</p><p><a href="https://github.com/hashicorp/terraform/issues/33847">https://github.com/hashicorp/terraform/issues/33847</a></p><p>そこで目をつけたのが、<a href="https://developers.cloudflare.com/r2/api/s3/api/">S3 API compatibility</a>に記載されている、R2とS3の互換性です。R2ではS3の一定のAPIを担保しており、<code>aws</code>コマンドでR2を操作することができます。そのため同様にTerraformでも、<code>backend</code>ブロックでS3を宣言していても実態はR2を見せることができるのではないかと思って今回のネタにしました。</p><h4 id="R2でState管理を実際に行う"><a href="#R2でState管理を実際に行う" class="headerlink" title="R2でState管理を実際に行う"></a>R2でState管理を実際に行う</h4><p>R2のバケットや、クレデンシャルの作成については登壇資料でもある程度触れているので、記事では実際に遭遇したエラーの解消過程を書いていきます。</p><p>S3に互換性のあるAPIを利用するということで、TerraformからはS3を使っているように見せることが必要になります。そのため、利用するBackendタイプは<code>s3</code>を使います。</p><p>まずは単純にR2バケット名を指定して<code>terraform init</code>コマンドを実行しました。</p><figure class="highlight sh"><figcaption><span>backend.tf</span></figcaption><table><tr><td class="code"><pre><span class="line">terraform &#123;</span><br><span class="line">  backend <span class="string">&quot;s3&quot;</span> &#123;</span><br><span class="line">    bucket = <span class="string">&quot;kaedemalu-tfstate&quot;</span></span><br><span class="line">    key    = <span class="string">&quot;default.state&quot;</span></span><br><span class="line">    region = <span class="string">&quot;us-east-1&quot;</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># エラー1</span></span><br><span class="line">terraform init</span><br><span class="line"></span><br><span class="line">Initializing the backend...</span><br><span class="line">╷</span><br><span class="line">│ Error: error configuring S3 Backend: error validating provider credentials: error calling sts:GetCallerIdentity: InvalidClientTokenId: The security token included <span class="keyword">in</span> the request is invalid.</span><br><span class="line">│       status code: 403, request <span class="built_in">id</span>: 98614ab4-7f7d-46c6-a5fb-1a8aae073866</span><br><span class="line">│ </span><br><span class="line">│ </span><br><span class="line">╵</span><br></pre></td></tr></table></figure><p><code>error validating provider credentials</code>ということでクレデンシャルのバリデーションに失敗しているようです。これはまず回避するために、<code>skip_credentials_validation = true</code>を追加して再度コマンド実行しました。</p><figure class="highlight sh"><figcaption><span>backend.tf</span></figcaption><table><tr><td class="code"><pre><span class="line">terraform &#123;</span><br><span class="line">  backend <span class="string">&quot;s3&quot;</span> &#123;</span><br><span class="line">    bucket                      = <span class="string">&quot;kaedemalu-tfstate&quot;</span></span><br><span class="line">    key                         = <span class="string">&quot;default.state&quot;</span></span><br><span class="line">    region                      = <span class="string">&quot;us-east-1&quot;</span></span><br><span class="line">    skip_credentials_validation = <span class="literal">true</span> <span class="comment"># 追加</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># エラー2</span></span><br><span class="line">terraform init</span><br><span class="line"></span><br><span class="line">Initializing the backend...</span><br><span class="line"></span><br><span class="line">Successfully configured the backend <span class="string">&quot;s3&quot;</span>! Terraform will automatically</span><br><span class="line">use this backend unless the backend configuration changes.</span><br><span class="line">Error refreshing state: InvalidAccessKeyId: The AWS Access Key Id you provided does not exist <span class="keyword">in</span> our records.</span><br><span class="line">        status code: 403, request <span class="built_in">id</span>: W0GM5Q8918T7P5AT, host <span class="built_in">id</span>: 55kKe3sn45n/RxCHZA5V2fR7lg0TE3OH0CGZlN6gi2bDzQfey8/oQALJWbRo9h1czaK7+f9t4i0=</span><br></pre></td></tr></table></figure><p>S3としてTerraformに対して見せることはできているようですが、<code>The AWS Access Key Id you provided does not exist in our records.</code>とエラーが返ってきて、AWSで発行するアクセスキーIDではないと怒られました。Cloudflareから発行するアクセスキーIDとAWSのそれとは異なるので、このエラーに対しても納得できます。</p><p>このエラーをよく考えてみると、上記の書き方ではS3エンドポイントのBackendを使うので、デフォルトでは<code>https://s3.us-east-1.amazonaws.com</code>を見に行っていることが考えられました。R2では<code>https://&lt;CLOUDFLARE_ACCOUNT_ID&gt;.r2.cloudflarestorage.com</code>をエンドポイントとしているので、<code>endpoint</code>パラメータでエンドポイントを上書きしました。。この状態で<code>terraform init</code>コマンドを実行することで、無事、R2をS3と見せかけた状態で成功しました。</p><figure class="highlight sh"><figcaption><span>backend.tf</span></figcaption><table><tr><td class="code"><pre><span class="line">terraform &#123;</span><br><span class="line">  backend <span class="string">&quot;s3&quot;</span> &#123;</span><br><span class="line">    bucket                      = <span class="string">&quot;kaedemalu-tfstate&quot;</span></span><br><span class="line">    key                         = <span class="string">&quot;default.state&quot;</span></span><br><span class="line">    region                      = <span class="string">&quot;us-east-1&quot;</span></span><br><span class="line">    endpoint                    = <span class="string">&quot;https://&lt;CLOUDFLARE_ACCOUNT_ID&gt;.r2.cloudflarestorage.com&quot;</span> <span class="comment"># 追加</span></span><br><span class="line">    skip_credentials_validation = <span class="literal">true</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>これで、無事R2でState管理をできるようになり、リソース作成を行うと、実際にStateファイル(<code>default.state</code>)が配置されたり、更新されることがわかりました。そのため、現在のS3互換のAPIサポート状況でも問題なく利用できることがわかりました。</p><p>　</p><h2 id="ほかの登壇内容"><a href="#ほかの登壇内容" class="headerlink" title="ほかの登壇内容"></a>ほかの登壇内容</h2><h3 id="Cloudflare-亀田さんのセッション"><a href="#Cloudflare-亀田さんのセッション" class="headerlink" title="Cloudflare 亀田さんのセッション"></a>Cloudflare 亀田さんのセッション</h3><p>当日のハンズオン資料：<a href="https://zenn.dev/kameoncloud/articles/ee68d54bcadf90">Cloudflare AI Gateway を試してみた</a></p><p>今回はイベント当時ベータ版であるAI Gatewayを経由して、Cloudflare WorkersからOpenAI(Chat GPT)にリクエストを実行するハンズオンでした。今回はOpenAIでしたが、プロキシするサービスはこれ以外にも複数選択することが可能で、これはマルチクラウドで使うことが考えられるCloudflareならではと感じたサービスでした。</p><p>ハンズオンを通して、Workersの手軽さはもちろん、デプロイに利用するWranglerも含めてしっかり整っていることを感じました。また、ハンズオンの時間が少々余ったので、ほかのハンズオン資料として、<a href="https://zenn.dev/kameoncloud/articles/707b3b623bdb87">Cloudflare Workers AI のハンズオン手順</a>も試してみました。これはCloudflareのエッジポイントに配置されているGPUをWorkersで利用し、推論などを行うハンズオンでした。そのため、</p><ul><li>ほかのサービスを利用する場合：AI Gateway</li><li>Cloudflare上で完結させる場合：Workers AI</li></ul><p>と感じました。Clouflare内で構築済みのモデルを利用して私自身もいくつか質問を投げてみましたが、現状は英語での質問がそれなりの精度になる一方日本語については文章の組み立てなどに課題がありそうでした。</p><h3 id="Cloudflare-Pages入門してみた"><a href="#Cloudflare-Pages入門してみた" class="headerlink" title="Cloudflare Pages入門してみた"></a>Cloudflare Pages入門してみた</h3><iframe class="speakerdeck-iframe" frameborder="0" src="https://speakerdeck.com/player/b7619952be484ddc9be5780247ab0f63" title="Cloudflare Pages に入門してみた / 2023-10-14 Cloudflare Meetup Nagano Vol.2" allowfullscreen="true" style="border: 0px; background: padding-box padding-box rgba(0, 0, 0, 0.1); margin: 0px; padding: 0px; border-radius: 6px; box-shadow: rgba(0, 0, 0, 0.2) 0px 5px 40px; width: 100%; height: auto; aspect-ratio: 560 / 315;" data-ratio="1.7777777777777777"></iframe><p>Cloudflare Pagesの話ではありましたが、モダンフロントエンド、Webフレームワークの話として参考になりました。私自身、Next.jsを最近触っていることもあり、機能としてフルに生かすために、やほかのフレームワークとの比較がなんとなくイメージつくLTでした。</p><h3 id="Cloudflare-WorkersでOpenAIのLINE-Chatbotを作ってみた"><a href="#Cloudflare-WorkersでOpenAIのLINE-Chatbotを作ってみた" class="headerlink" title="Cloudflare WorkersでOpenAIのLINE Chatbotを作ってみた"></a>Cloudflare WorkersでOpenAIのLINE Chatbotを作ってみた</h3><iframe class="speakerdeck-iframe" frameborder="0" src="https://speakerdeck.com/player/d263bb47e8cf4438a958135a550fe97e" title="Cloudflare Workers で OpenAI の LINE Chatbotを作ってみた" allowfullscreen="true" style="border: 0px; background: padding-box padding-box rgba(0, 0, 0, 0.1); margin: 0px; padding: 0px; border-radius: 6px; box-shadow: rgba(0, 0, 0, 0.2) 0px 5px 40px; width: 100%; height: auto; aspect-ratio: 560 / 315;" data-ratio="1.7777777777777777"></iframe><p>LTのネタとして昨今話題になっているOpenAIについて取り上げていましたが、作成の動機がお子さんにAIに触れる機会を作りたい、という親心に心を打たれました。肝心のLINE Chatbotについても半日くらいで作れたようで、開発体験の良さなどのメリット、いまいちなポイントなども知れました。フレームワークについても<a href="https://hono.dev/">hono</a>を利用されていたので、以下のリポジトリ試してみようと思います。</p><p><a href="https://github.com/koda-masaru/chat-bot">https://github.com/koda-masaru/chat-bot</a></p><h3 id="Cloudflare-Zero-Trustを設定して使ってもらってみた"><a href="#Cloudflare-Zero-Trustを設定して使ってもらってみた" class="headerlink" title="Cloudflare Zero Trustを設定して使ってもらってみた"></a>Cloudflare Zero Trustを設定して使ってもらってみた</h3><p>こちらは、前回のCloudflare Meetup Nagano Vol.1に参加して、Cloudflareに興味を持ったことから実際に仕事でZero Trustを導入した話でした。</p><p>仕事で開発されているシステムのデモ環境への接続のスピード、セキュリティの担保をするためにZero Trustを導入して、導入前でもできていたポイントはもちろん、課題とされていた接続スピードについても解消されているということで、Cloudflareのサービス群の導入に対するフットワークの軽さ・導入コストの低さを改めて感じました。</p><h2 id="まとめ"><a href="#まとめ" class="headerlink" title="まとめ"></a>まとめ</h2><p>前回に引き続きVol.2も参加し、かつ今回は登壇の機会をいただけたので、調べても出てこなかったことをネタにして形にすることができました。<br>また、イベントの開催地が私の地元である長野であるということもあり、地元のコミュニティに関われたことがとても嬉しかったので、今後もなんらかの形で関われればと考えています。</p><h2 id="余談）地方勉強会参加のススメ"><a href="#余談）地方勉強会参加のススメ" class="headerlink" title="余談）地方勉強会参加のススメ"></a>余談）地方勉強会参加のススメ</h2><p>今回、長野のイベントに参加するきっかけは帰省しながら参加できることにつきますが、これに限らず地方で開催される勉強会も改めて足をのばすと良いなと思いました。普段足を伸ばすきっかけがない土地でも、技術やイベントに誘われて参加しつつ、近隣の観光やその土地の料理を味わえるのも地方勉強会ならではの良さだと考えています。今回は懇親会で長野の日本酒をたくさん楽しめました。</p><img src="/images/20231016a/IMG_3553.jpg" alt="" width="1200" height="1093" loading="lazy"><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>技術ブログのほかのClouflare記事<ul><li><a href="https://future-architect.github.io/articles/20230427a/">CDN 入門とエッジでのアプリケーション実行</a></li><li><a href="https://future-architect.github.io/articles/20230502a/">cf-terraformingで入門するCloudflare</a></li></ul></li><li>イベント当日のハッシュタグ <a href="https://twitter.com/hashtag/CloudflareUG_mmj">#CloudflareUG_mmj</a></li><li><a href="https://togetter.com/li/2241595">Togetter</a></li></ul>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;img src=&quot;/images/20231016a/cloudflare_nagano.png&quot; alt=&quot;&quot; width=&quot;660&quot; height=&quot;371&quot; loading=&quot;lazy&quot;&gt;

&lt;p&gt;イベントリンク： &lt;a</summary>
        
      
    
    
    
    <category term="Infrastructure" scheme="https://future-architect.github.io/categories/Infrastructure/"/>
    
    
    <category term="Terraform" scheme="https://future-architect.github.io/tags/Terraform/"/>
    
    <category term="Cloudflare" scheme="https://future-architect.github.io/tags/Cloudflare/"/>
    
    <category term="登壇資料" scheme="https://future-architect.github.io/tags/%E7%99%BB%E5%A3%87%E8%B3%87%E6%96%99/"/>
    
  </entry>
  
  <entry>
    <title>Meta Quest 3開封の儀＆フルカラーパススルーで家にテルミンを置いた</title>
    <link href="https://future-architect.github.io/articles/20231013a/"/>
    <id>https://future-architect.github.io/articles/20231013a/</id>
    <published>2023-10-12T15:00:00.000Z</published>
    <updated>2023-10-13T00:50:10.322Z</updated>
    
    <content type="html"><![CDATA[<h1 id="はじめに"><a href="#はじめに" class="headerlink" title="はじめに"></a>はじめに</h1><p>こんにちは。TIG DX ユニット所属、金欠コンサルタントの藤井です。</p><p>2023年10月10日、とうとう発売されましたね。<a href="https://www.meta.com/jp/quest/quest-3/">Meta Quest 3</a>（以下 Quest3 と略記）が。しっかり予約して発売日に手に入れようとしたんですが、何故か配達日がズレて 1 日遅れで入手しました。<br>せっかくなので、開封の儀と、Quest3 の目玉機能の一つである、<a href="https://www.meta.com/ja-jp/help/quest/articles/getting-started/getting-started-with-quest-pro/full-color-passthrough/">フルカラーパススルー</a>を使って遊んでみようと思います。</p><p>ちなみに、この記事は<a href="https://immersed.com/">immersed</a>を用いて、VR 空間のバーチャルディスプレイを使って書いています。バーチャルデスクトップについては<a href="/articles/20221031b">井上さんの記事をご参照</a>ください。</p><h2 id="開封の儀"><a href="#開封の儀" class="headerlink" title="開封の儀"></a>開封の儀</h2><h3 id="外観確認・Quest2-との比較"><a href="#外観確認・Quest2-との比較" class="headerlink" title="外観確認・Quest2 との比較"></a>外観確認・Quest2 との比較</h3><p>それでは早速開封していきます。<br>ケースと箱はシンプルで、思ったよりコンパクトでした。（ダンボールに梱包されて届いた時点で想像より小さかったのでちょっと驚きました。）</p><img src="/images/20231013a/box.jpg" alt="box.jpg" width="1200" height="1091" loading="lazy"><p>箱から取り出して Quest2 と比較してみます。</p><p>まずは本体を上から見た図です。（右が Quest3）</p><img src="/images/20231013a/up.jpg" alt="up.jpg" width="1200" height="841" loading="lazy"><p>ディスプレイ部分が明らかに薄くなっており、全体的にコンパクトに感じます。<br>レンズをパンケーキレンズに変更したことでサイズダウンするとは聞いていましたが、思ったより大幅に薄くなっていました。</p><p>装着する部分のバンドも明らかに見た目が違うのですが、これは私が Quest2 のバンドをバッテリー付きの Elite ストラップに変更しているからというのもあります。</p><p>この Elite ストラップというのが非常につけ心地が良いのもあり、正直 Quest3 のバンドはちょっと微妙でした。あまり頭にフィットせず、調整も難しいです。Quest3 用の Elite ストラップも買うことにしました。</p><p>一応 Quest2 の頃から改修は加えられており、頭頂部～後頭部部分が Y 字になって、よりフィットしやすくなってはいるようです。（この Y 字が開くことで締め付けが調整できる、というのになかなか気づけず…Quest3 を装着してから見ることができるチュートリアルで調整の仕方が紹介されるため、先にチュートリアルを進めるのが良いかもしれません。）</p><p>次に前から見た図がこちらです。（下が Quest3）ついでにコントローラーも並べています。</p><img src="/images/20231013a/front.jpg" alt="front.jpg" width="1200" height="1155" loading="lazy"><p>本体には特徴的な三つ目がついており、左右のそれぞれに RGB カメラと IR カメラが1つずつ、真ん中には深度センサーが取り付けられています。これらを用いてフルカラーパススルー及び MR のための空間認識機能を提供しているようです。<br>また、これに加えて、底面側に 2 つカメラがついているので、トータルで 6 つのカメラと 1 つの深度センサーが搭載されています。</p><p>コントローラーも大幅に変化していて、Quest2 のコントローラーにあったリングが無くなっています。元々このリングは赤外線を発しており、それを本体の赤外線カメラで検知することでコントローラーのトラッキング（位置・姿勢の取得）していました。</p><p>Quest3 ではリングが無くなった分、上面（ボタンやスティックが配置されている面）から赤外線を発しているようです。ただ、コントローラーを握っていたり、回転させると本体に赤外線が届かなくなってしまいます。そこで赤外線の検知に加え、ハンドトラッキングも並列で行ったり、加速度センサー・ジャイロセンサーの入力で補正したりと、多角的にトラッキングを行うことで安定したトラッキングを実現しているようです。<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup></p><p>ハンドトラッキングに関しては<a href="/articles/20220823a/">私の記事</a>でちょっとだけ解説しています。（この記事はもう一回参照します。）実際の使用感としても、リングが無くなったことでトラッキングの精度が落ちた実感はありませんでした。</p><h3 id="フルカラーパススルーと-MR-を体験してみる"><a href="#フルカラーパススルーと-MR-を体験してみる" class="headerlink" title="フルカラーパススルーと MR を体験してみる"></a>フルカラーパススルーと MR を体験してみる</h3><p>開封も済んだので、三つ目を活かしたフルカラーパススルー・MR を体験してみようと思います。Meta が Quest3 の MR 体験用に提供しているゲームである<a href="https://www.meta.com/ja-jp/experiences/6236169136472090/">First Encounters</a>をプレイしてみました。何枚かキャプチャも撮ったのですが、あんまりキャプチャだと凄さが伝わりそうになかったため、あえて文字だけで紹介してみます。できれば体験会や持っている知人に頼んで実際にプレイしてみていただきたいです。</p><p>まずゲームが始まる前に、プレイエリアを認識するため、部屋のスキャンを行います。と言っても、やることは部屋中をぐるりと眺めるぐらいです。ここで三つ目が活用され、リアルタイムに壁や障害物が認識されていきます。部屋のスキャンが完了すればゲーム開始です。ゲーム内容は簡単な FPS（ちょっとだけパズル要素あり）という感じなのですが、そこは MR、舞台は今自分がいる部屋なので、慣れ親しんだ空間がプレイエリアになるのでとても楽しい…と言う話ではありません（多分それは AR）。なんとゲームが始まると早々に天井の一部が崩れ落ちて宇宙船が落ちてきたのです。上階の人が床をぶち抜いたのかと思いました。</p><p>その後もちっちゃい宇宙人が壁を壊して部屋に入り込んできたり、自分が撃った弾が壁を壊したりと、だんだんと自分の部屋だったはずの空間が広大な空間（どこかの星）に変わっていきます。</p><p>こうなるともう脳はしっかり騙されてしまい、段々とどこが自分の部屋でどこがゲーム空間かわからなくなってきます。シームレスに現実と仮想空間が混ざり合っていく。なるほどこれが Mixed Reality か、という気持ちになりました。<br>（なお、二度ほど壁にぶつかりました。痛い。）</p><p>繰り返しになりますが、スクリーンショットやプレイ動画、文章だけではこの感覚は伝わらないので、ぜひとも何らかの方法で一度体験していただきたいです。</p><h2 id="フルカラーパススルーを使って、家にテルミンを置いてみる"><a href="#フルカラーパススルーを使って、家にテルミンを置いてみる" class="headerlink" title="フルカラーパススルーを使って、家にテルミンを置いてみる"></a>フルカラーパススルーを使って、家にテルミンを置いてみる</h2><p>さて、公式のしっかりした MR を体験したところで、自分でも触ってみたくなったので、まずはフルカラーパススルーを試してみます。<br>とはいえ一からコンテンツを作っていると時間がかかるので、<a href="/articles/20220823a/">以前作成したハンドトラッキングテルミンシミュレータ</a>を流用して、我が家にテルミンを召喚してみましょう。</p><p>Oculus Integration のパッケージを導入していましたが、かなりアップデートが入っていたため、執筆時最新バージョンである 57.0 にアップデートした上で開発していきます。（その他 Unity のバージョンも 2022 まで上げたりしています。）</p><p>いつの間にか Oculus Integration が非常に便利になっており、直感的に必要なあれこれをシーンに追加できるようになっていました。メニューバーから Oculus -&gt; Tools -&gt; Building Blocks と行くと、各機能ごとのブロックが表示されるので、この中から必要なものをヒエラルキーに D&amp;D するだけで導入が完了します。</p><p>今回は Camera Rig と Hand Tracking（以前テルミンシミュレータを作ったときのもとと競合するので、そちらは削除してから）を導入し、加えてパススルーを提供してくれる、Background Passthrough を導入します。</p><img src="/images/20231013a/image.png" alt="image.png" width="1200" height="906" loading="lazy"><p>あとはテルミン側のスクリプトから、ハンドトラッキングの参照を設定し直せば準備完了です。ビルドして動かしてみましょう。</p><p>我が家にテルミンが来た！（思ったより大きい）</p><img src="/images/20231013a/6e962269ed7aea050fd5c2cf96faf4fa.png" alt="6e962269ed7aea050fd5c2cf96faf4fa.png" width="1200" height="1066" loading="lazy"><p>床にもちゃんと接してますね。（画像だとわかりにくいですが）</p><p>ただ、自分の手との前後関係はパススルーのみでは判定しようがないので、（本当はテルミンのほうが奥にあるのに）手の手前にテルミンが描画されてしまっています。このあたりはおそらく深度センサーを適切に使うことで解決する気はします。</p><p>ところでテルミンの 3D モデル、全く作り込んでいないのであからさまに 3D オブジェクト、という感じなのですが、それでもフルカラーパススルーで現実世界に登場させると、一気にそこに物があるような錯覚に襲われます。（ぶつかりそうになったら無意識に避けようとしてしまうぐらい）</p><p>もっとリアルなものを登場させたり、逆に First Encounters のようなコミカルなものと現実世界を融合させたりと、可能性は非常に広そうだと改めて感じました。</p><h2 id="おわりに"><a href="#おわりに" class="headerlink" title="おわりに"></a>おわりに</h2><p>テルミン、やっぱり難しい。</p><p>というのは冗談として、やはり新しいデバイスというのは胸が躍りますね。私が XR 系が好きだというのもありますが、特に XR 系の発展は身近に未来を感じられてハッピーです。</p><p>今後も新しい技術・デバイスが現れる度に色々とトライしていきたいと思います。</p><p>とりあえず直近は、深度センサーも活用してなにか作って遊べないか試したいです。</p><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0;"><li id="fn:1"><span style="vertical-align: top; padding-right: 10px;">1.</span><span style="vertical-align: top;">Meta Reveals How Quest 3 Controller Tracking Works As Beat Saber Founder Gives His Take <a href="https://www.uploadvr.com/meta-explains-quest-3-controller-tracking/">https://www.uploadvr.com/meta-explains-quest-3-controller-tracking/</a></span><a href="#fnref:1" rev="footnote"> ↩</a></li></ol></div></div>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h1 id=&quot;はじめに&quot;&gt;&lt;a href=&quot;#はじめに&quot; class=&quot;headerlink&quot; title=&quot;はじめに&quot;&gt;&lt;/a&gt;はじめに&lt;/h1&gt;&lt;p&gt;こんにちは。TIG DX</summary>
        
      
    
    
    
    <category term="VR" scheme="https://future-architect.github.io/categories/VR/"/>
    
    
    <category term="VR" scheme="https://future-architect.github.io/tags/VR/"/>
    
    <category term="MetaQuest3" scheme="https://future-architect.github.io/tags/MetaQuest3/"/>
    
  </entry>
  
  <entry>
    <title>Makefile覚書: Goアプリ開発に役立ちそうな基礎知識</title>
    <link href="https://future-architect.github.io/articles/20231012a/"/>
    <id>https://future-architect.github.io/articles/20231012a/</id>
    <published>2023-10-11T15:00:00.000Z</published>
    <updated>2023-10-12T00:38:23.851Z</updated>
    
    <content type="html"><![CDATA[<img src="/images/20231012a/gnu-make.png" alt="" width="800" height="418"><h2 id="はじめに"><a href="#はじめに" class="headerlink" title="はじめに"></a>はじめに</h2><p>TIG真野です。育休明けです。</p><p>フューチャー社内のタスクランナーはmakeや<a href="https://taskfile.dev/">Task</a>など複数の流派があり、チームによって使い分けられています。個人的にはmakeで良いんじゃないかと思っていますが、Taskも良いですよね。</p><p>makeは細かい記法をいつも忘れる＋調べるとC言語向けの情報が出てきて脳内変換に手間を感じたため、makeを用いてWebバックエンドアプリをGoで開発するということをテーマに、役立ちそうな情報をまとめます。</p><p>なお、今記事におけるmakeは、GNU Makeを指します。バージョンは以下で動かしています。</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ make -v | <span class="built_in">head</span> -n 1</span><br><span class="line">GNU Make 4.2.1</span><br></pre></td></tr></table></figure><h2 id="MakefileのためのEditorConfig"><a href="#MakefileのためのEditorConfig" class="headerlink" title="MakefileのためのEditorConfig"></a>MakefileのためのEditorConfig</h2><p>Makefileのインデントはハードタブである必要があります。誤りを防ぐためにも<a href="https://editorconfig.org/">EditorConfig</a>を設定しておくと良いでしょう。</p><p>makeは通常、Makefileという名称をデフォルトで認識しますが、同一フォルダに複数のファイルを用意したいときや、includeように共通の変数などを定義したファイルを作る場合は、<code>.mk</code> という拡張子を付けますので、<code>[&#123;Makefile,**.mk&#125;]</code> というセクションが良いでしょう（<a href="https://www.gnu.org/software/make/manual/html_node/Makefile-Names.html">小文字の<code>makefile</code> より <code>Makefile</code> の方を推奨する</a>とのことなので小文字の方はあえて入れてません）。</p><figure class="highlight ini"><figcaption><span>.editorconfig</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="attr">root</span> = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="section">[*]</span></span><br><span class="line"><span class="attr">indent_style</span> = space</span><br><span class="line"><span class="attr">indent_size</span> = <span class="number">2</span></span><br><span class="line"><span class="attr">end_of_line</span> = lf</span><br><span class="line"><span class="attr">charset</span> = utf-<span class="number">8</span></span><br><span class="line"><span class="attr">trim_trailing_whitespace</span> = <span class="literal">true</span></span><br><span class="line"><span class="attr">insert_final_newline</span> = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="section">[*.go]</span></span><br><span class="line"><span class="attr">indent_style</span> = tab</span><br><span class="line"></span><br><span class="line"><span class="section">[&#123;Makefile,**.mk&#125;]</span></span><br><span class="line"><span class="attr">indent_style</span> = tab</span><br></pre></td></tr></table></figure><p>記事によっては以下のように <code>indent_size</code> を指定する設定例もよく見かけます。こちらを指定していると、ハードタブの場合でも、エディタやGitHub上の表示幅を制御してくれるため、チーム開発で見た目まで統一を効かせたい場合は追加すると良いでしょう。個人的にはここは個々人に委ねても良い領域だと感じたので上の例から省いています。</p><figure class="highlight ini"><figcaption><span>.editorconfig</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="section">[&#123;Makefile,**.mk&#125;]</span></span><br><span class="line"><span class="comment"># 表示幅もEditorconfigで制御したい場合はindent_sizeの設定を加える</span></span><br><span class="line"><span class="attr">indent_size</span> = <span class="number">4</span></span><br><span class="line"><span class="attr">indent_style</span> = tab</span><br></pre></td></tr></table></figure><h2 id="リンター"><a href="#リンター" class="headerlink" title="リンター"></a>リンター</h2><p>Makefileのリンターとして<a href="https://github.com/mrtazz/checkmake">mrtazz&#x2F;checkmake</a> があります。2023.10.6時点でv0.2.2、<code>experimental tool</code> とREADMEにかかれているGo製のツールです。まだ実験的な取り組みのようですが、すでに <a href="https://github.com/oxsecurity/megalinter">MegaLinter</a>にネイティブで組み込まれており、利用しているチームも増えているように感じます。</p><p>v0.2.2時点での<a href="https://github.com/mrtazz/checkmake/tree/main/rules">実装</a>から、次の4種類のチェックを行ってくれるようです。</p><ol><li>ターゲットボディがN行以内（デフォルト5）</li><li>all, clean, testのターゲットがPHONYにあること</li><li>ボディがないターゲットはPHONY宣言すること</li><li>ビルドの一貫性のためdateの利用有無</li></ol><p>また、先のEditorConfigの設定値が正しく反映されたエディタで編集されているかチェックするため、<a href="https://github.com/editorconfig-checker/editorconfig-checker">editorconfig-checker</a>を使うという考え方もあります。こちらはMakefile以外のファイルに対しても利用できるものなので、一律設定しておくとベターだと思います。</p><p>リンターと合わせてフォーマッターについても触れたかったですが、有益なものを探せませんでした。もし、ご存知の方がいれば教えてください。</p><h2 id="コーディング規約"><a href="#コーディング規約" class="headerlink" title="コーディング規約"></a>コーディング規約</h2><p>Makefileそのものの、コーディング規約（スタイルガイド）で広く周知されているものの1つが<a href="https://www.gnu.org/prep/standards/html_node/Makefile-Conventions.html">GNUのマニュアル</a> でしょう。多くの慣習がここから来ていそうな大本です。</p><p>重要そうなものを抜粋します。</p><ul><li>Makefile Basics（Makefile基礎）<ul><li>すべてのMakefileは <code>SHELL = /bin/sh</code> が含まれるべきとある</li><li>こちらについては後述しますが、 <code>bash</code> の方がベターだと思います</li></ul></li><li>Standard Targets（標準ターゲット）<ul><li>すべてのGNUプログラムには次のターゲットが含まれるべきとある<ul><li><code>all</code>、<code>install</code>、<code>install-html</code>、(中略)、<code>clean</code>、(中略)、<code>TAGS</code>、<code>info</code>、<code>dvi</code>、<code>html</code>、<code>pdf</code>、<code>ps</code>、<code>dist</code>、<code>check</code>、(省略)</li></ul></li><li><code>install-html</code> の例にある通り、 <strong>ターゲット名はハイフン区切り</strong> が推奨だと思われます</li></ul></li></ul><p>ターゲット名はこれをベースにできるのが嬉しいですね。GoでWebバックエンドアプリ開発だと、<code>all</code>, <code>install</code>, <code>uninstall</code>, <code>clean</code>, <code>dist</code>, <code>check</code> あたりは使えそうですが、変わって来ているものもあります。</p><ul><li><code>all</code>: make の慣習でプログラム全体をビルドするターゲット名です。<code>make</code>コマンドのみでターゲット名を指定しない場合に通常呼び出されます。<code>test</code>、<code>build</code> などすべてを実施しておくとよいでしょう。デプロイは行わないほうが良いかと思います</li><li><code>check</code>: <code>test</code> にすることがWebアプリ開発では多いように思います。先程の<code>mrtazz/checkmake</code>も<code>test</code>想定です。</li><li><code>install</code>: 本来は開発中のプログラムのインストールを行うターゲットで、開発環境セットアップの意味では無いです。そのため <code>setup</code> と別の用語を用いることも多いと思います。しかし Goだと <code>go install</code> で必要なツールを入れることも多いこともあり、 <code>install</code> を使っている場面もよく見ますが、意味合いが異なるため <code>setup</code> がベターだと思います</li><li><code>dist</code>: サーバデプロイ用にzipで固める場合などに使っても良い気がしますし、開発者にとってはさして重要でなければ <code>bootstrap.zip</code> などというターゲット名のみにして良い気がします</li><li><code>clean</code>: 生成したバイナリを削除したり、Goアプリ開発の場合は<code>go clean</code> なども合わせて実施すると良いでしょう</li></ul><p>次にメジャーだと思われる規約に<a href="https://clarkgrubb.com/makefile-style-guide">clarkgrubbのスタイルガイド</a>があります。こちらについてはまた別の機会で紹介します。</p><h2 id="Makefileオプション"><a href="#Makefileオプション" class="headerlink" title="Makefileオプション"></a>Makefileオプション</h2><p>Makefileの先頭によく設定するオプションは次です。それぞれ説明していきます。</p><figure class="highlight makefile"><figcaption><span>Makefile</span></figcaption><table><tr><td class="code"><pre><span class="line">SHELL := bash</span><br><span class="line">.SHELLFLAGS := -eu -o pipefail -c</span><br><span class="line">.DEFAULT_GOAL := help</span><br></pre></td></tr></table></figure><ul><li><p><code>SHELL</code>: 次の <code>.SHELLFLAGS</code> を利用するために <code>bash</code> を宣言します。<code>/bin/bash</code> でも良いと思いますが、<code>bash</code> そのままの方が移植性が高いと考えます</p></li><li><p><code>.SHELLFLAGS</code>: シェルスクリプトの実行時オプション（疑似ターゲット）です</p><ul><li><code>-eu</code>: <code>-e</code> はbashで実行したコマンドが失敗した場合に終了させるものです。<code>;</code> などで複数のコマンドをワンライナーで記述した場合でも止めたいのでオプションに加えます。 <code>-u</code> はbashで変数未定義の場合にエラーで止めるためのオプションです</li><li><code>-o pipefail</code>: パイプを使った処理を書いた場合に、パイプの最初や途中で処理が失敗した場合、全体を失敗したとみなすためのオプションです</li><li><code>-c</code>: <code>.SHELLFLAGS</code> オプションを用いるときには最後につけるのが必須です。理由は内部的には各行が <code>$(SHELL) -$(SHELLFLAGS) 何かしらのcommands</code> といった形で動くためです（<code>bash -c &quot;echo &#39;Hello&#39;&quot;</code> のようにコマンドとして評価させるためのオプションです）。<code>.SHELLFLAGS</code>のデフォルト値は <code>-c</code> が入っています。</li></ul></li><li><p><code>.DEFAULT_GOAL</code>: デフォルト（ターゲットを未指定にした場合に選ばれる対象）は一番最初に定義したターゲットです。慣習的には <code>all</code> ターゲットを最初に定義することが多いようです。しかし、後述するスクリプトを機械的に追加して、<code>help</code> にしておくと便利だと思います（allだと実行時間が長いので）。これは好みなのでチームによってはなくしても良いと思います</p></li></ul><p>特に <code>.SHELLFLAGS</code> で渡す値は個人的に重要で、指定を忘れるとその後、高確率でハマるメンバーが出現する体感がありますので、Makefileには機械的につける慣習化しておくと良いかなと思います。</p><p>makeには様々な設定ができますが、以下は1度は付けたものの運用をとして外した設定値です。備忘に残しておきます</p><ul><li><code>MAKEFLAGS += --warn-undefined-variables</code>: makeの実行オプションで、<code>--warn-undefined-variables</code> はmake上で未定義の変数を $(undefined_var) などで利用すると警告を上げるものです。これ自体は良さそうだと思いましたが、後述する <code>go test $(option) ./...</code> のように拡張用のパラメータを指定するときにノイズだったので削除しました</li><li><code>MAKEFLAGS += --no-print-directory</code>: 後述がありますが、こちらは一律指定しても良いレベルだと思います。この記事では先頭行をあまり増やすのも、makeを難しいものと思われそうだったので除外しています</li><li><code>MAKEFLAGS += --no-builtin-rules</code>: <code>make</code> が暗黙的に探すファイルを無効化する設定です。性能向上が見込まれるようですが、Go環境だと大きな差は生まれなかったため、シンプル化のためなくします</li><li><code>.SUFFIXES:</code>:  <code>MAKEFLAGS += --no-builtin-rules</code> と同様です</li><li><code>.DELETE_ON_ERROR</code>: レシピが失敗した場合にターゲットのファイルを削除するオプション（疑似ターゲット）です。便利そうですがmakeを知らない開発者からするとこの挙動が直感的ではないため、make上級者が集うチームでない限りは未設定で良いと思いました</li><li><code>.ONESHELL</code>: <code>make</code>は通常1行ごと別のプロセスで起動しますが、これを1つのシェルとして動かすオプションです（<code>;</code>や<code>\</code>を減らせて便利です）。 規模感にもよりますが私が関わったGo Webアプリ開発の規模感では <code>make</code> にそれほど複雑な処理を行うことはなかったので、なるべく先頭の宣言部分をシンプルにしたかったため外す方針としました</li></ul><h2 id="Goアプリに環境変数を渡す"><a href="#Goアプリに環境変数を渡す" class="headerlink" title="Goアプリに環境変数を渡す"></a>Goアプリに環境変数を渡す</h2><p>クラウドネイティブなアプリケーション開発のためにThe Twelve-Factor Appを守っているチームは多いと思います。そうすると、DBや外部接続先など、それなりの数の環境変数をGoのアプリケーションに渡す必要が出てくるでしょう。</p><p>このとき、有名なよくある間違いは次のようなターゲット内のコマンドに変数をexportして記載するパターンです（※パスワードはラフに扱ってますのがイメージとして捉えてください）。</p><figure class="highlight ini"><figcaption><span>Makefile（NG例）</span></figcaption><table><tr><td class="code"><pre><span class="line">SHELL := bash</span><br><span class="line">.SHELLFLAGS := -eu -o pipefail -c</span><br><span class="line"></span><br><span class="line">.PHONY: run</span><br><span class="line"></span><br><span class="line"><span class="comment"># run is launching server</span></span><br><span class="line">run:</span><br><span class="line">@export <span class="attr">DB_HOST</span>=localhost</span><br><span class="line">@export <span class="attr">DB_PORT</span>=<span class="number">5432</span></span><br><span class="line">@export <span class="attr">DB_NAME</span>=pg</span><br><span class="line">@export <span class="attr">DB_USER</span>=pg</span><br><span class="line">@export <span class="attr">DB_PASS</span>=xxxxx</span><br><span class="line">@go run cmd/main/main.go</span><br></pre></td></tr></table></figure><figure class="highlight go"><figcaption><span>cmd/main/main.go</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">&quot;fmt&quot;</span></span><br><span class="line"><span class="string">&quot;log&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;github.com/kelseyhightower/envconfig&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> DBConfig <span class="keyword">struct</span> &#123;</span><br><span class="line">Host <span class="type">string</span></span><br><span class="line">Port <span class="type">int</span></span><br><span class="line">Name <span class="type">string</span></span><br><span class="line">User <span class="type">string</span></span><br><span class="line">Pass <span class="type">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">var</span> dc DBConfig</span><br><span class="line"><span class="keyword">if</span> err := envconfig.Process(<span class="string">&quot;db&quot;</span>, &amp;dc); err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Fatal(err.Error())</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">fmt.Printf(<span class="string">&quot;Load env: %+v\n&quot;</span>, dc)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>環境変数は適用されません。</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ make run</span><br><span class="line">Load <span class="built_in">env</span>: &#123;Host: Port:0 Name: User: Pass:&#125;</span><br></pre></td></tr></table></figure><p>これは make のターゲットのレシピ1行1行でシェルスクリプトのプロセスが別々になるためです（※ <code>.ONESHELL:</code> の疑似ターゲットが無い場合）。</p><p>回避するには、インラインで変数宣言するか（エスケープで改行しているのでインライン感は無いですが）、<code>&amp;&amp;</code> で同一シェル内で宣言するかなどが考えられます。</p><figure class="highlight ini"><figcaption><span>Makefile(インラインパターン）</span></figcaption><table><tr><td class="code"><pre><span class="line">run:</span><br><span class="line">@<span class="attr">DB_HOST</span>=localhost \</span><br><span class="line">    <span class="attr">DB_PORT</span>=<span class="number">5432</span> \</span><br><span class="line">    <span class="attr">DB_NAME</span>=pg \</span><br><span class="line">    <span class="attr">DB_USER</span>=pg \</span><br><span class="line">    <span class="attr">DB_PASS</span>=pgpass \</span><br><span class="line">    go run cmd/main/main.go</span><br></pre></td></tr></table></figure><figure class="highlight ini"><figcaption><span>Makefile（同一シェルで動かすパターン）</span></figcaption><table><tr><td class="code"><pre><span class="line">run:</span><br><span class="line">@export <span class="attr">DB_HOST</span>=localhost &amp;&amp; \</span><br><span class="line">export <span class="attr">DB_PORT</span>=<span class="number">5432</span> &amp;&amp; \</span><br><span class="line">export <span class="attr">DB_NAME</span>=pg &amp;&amp; \</span><br><span class="line">export <span class="attr">DB_USER</span>=pg &amp;&amp; \</span><br><span class="line">export <span class="attr">DB_PASS</span>=pgpass &amp;&amp; \</span><br><span class="line">go run cmd/main/main.go</span><br></pre></td></tr></table></figure><p>どちらもgit差分がわかりやすくするため改行を入れています。また先頭行はmake実行時にコマンドを非表示にするため<code>@</code>を追加しています。</p><p>個人的には開発上もっとも利用頻度が高い値に関してはトップレベルで変数宣言 + export（これだけ記載すると全変数をexportする）するのがてっとり早いと思います。たまに <code>.EXPORT_ALL_VARIABLES</code> という疑似ターゲットで説明した例がありますが、<a href="https://www.gnu.org/software/make/manual/html_node/Variables_002fRecursion.html">古いmakeのバージョンで用いるもの</a>であるとのことで、通常はexportを使えば良いと思います。</p><figure class="highlight ini"><figcaption><span>Makefile</span></figcaption><table><tr><td class="code"><pre><span class="line">SHELL := bash</span><br><span class="line">.SHELLFLAGS := -eu -o pipefail -c</span><br><span class="line"></span><br><span class="line">.PHONY: run</span><br><span class="line"></span><br><span class="line">export</span><br><span class="line"><span class="attr">DB_HOST</span>=localhost</span><br><span class="line"><span class="attr">DB_PORT</span>=<span class="number">5432</span></span><br><span class="line"><span class="attr">DB_NAME</span>=pg</span><br><span class="line"><span class="attr">DB_USER</span>=pg</span><br><span class="line"><span class="attr">DB_PASS</span>=pgpass</span><br><span class="line"></span><br><span class="line"><span class="comment"># run is launching server</span></span><br><span class="line">run:</span><br><span class="line">@go run cmd/main/main.go</span><br></pre></td></tr></table></figure><p>あるいは、 <code>make</code> に慣れないメンバーが多い場合、 <code>export</code> が少しわかりにくいのでいっそ変数毎に付けたほうが直感的かもしれません。</p><figure class="highlight makefile"><figcaption><span>Makefile</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="comment"># ...省略...</span></span><br><span class="line"><span class="keyword">export</span> DB_HOST=localhost</span><br><span class="line"><span class="keyword">export</span> DB_PORT=5432</span><br><span class="line"><span class="keyword">export</span> DB_NAME=pg</span><br><span class="line"><span class="keyword">export</span> DB_USER=pg</span><br><span class="line"><span class="keyword">export</span> DB_PASS=pgpass</span><br><span class="line"></span><br><span class="line"><span class="comment"># run is launching server</span></span><br><span class="line"><span class="section">run:</span></span><br><span class="line">@go run cmd/main/main.go</span><br></pre></td></tr></table></figure><p>すこし冗長ですが、こちらの方がサブプロセスに引き継がせたくない変数が出てきた場合に都合が良いため、すべての変数を環境変数としてGoのプロセスに与えたい場合も、あえてこちらの方針を採用するのもありじゃないかと思います。</p><h2 id="env-を読み込む"><a href="#env-を読み込む" class="headerlink" title=".env を読み込む"></a>.env を読み込む</h2><p>チームによっては <code>.env</code> で環境変数を管理している場合もあるでしょう。記載された変数をGoのプログラムにすべて渡すには以下のように <code>include</code> を用います。<a href="https://dev.to/serhatteker/get-environment-variables-from-a-file-into-makefile-2m5l">こちら</a>を参考にしました。</p><figure class="highlight makefile"><figcaption><span>Makefile</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">include</span> <span class="variable">$(PWD)</span>/.env</span><br><span class="line"><span class="keyword">export</span></span><br><span class="line"></span><br><span class="line"><span class="section">run:</span></span><br><span class="line">go run cmd/main/main.go</span><br></pre></td></tr></table></figure><p>これは少しテクニカルで、 <code>include</code> は本来は別のMakefileを読み込むディレクティブです。たまたま <code>.env</code> のファイルレイアウトがMakefileとして読み込める形式であったため、このように扱えます。 私は <code>.env</code> の形式に詳しくないため、厳密には扱えないケースがあるかもしれませんが、key1&#x3D;value1、key2&#x3D;${value1} といった代表的なユースケースであれば問題なかったので、シンプルな使い方に留めるのであれば利用して良いのではないかと考えています。</p><p>ここでややこしいのは、developなど別環境に接続したい場合です。利用する環境変数を書き換える必要があります。もし、 <code>.env.develop</code> などのファイルが存在する場合は、<code>.env</code> の読み込みを変数化して切り替えられるようにすると良いかもしれません。基本的にはローカル環境、動作確認など限られたケースでのみクラウド上の開発環境に接続するといった場合を想定しています。</p><figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line">DOTENV := <span class="variable">$(PWD)</span>/.env</span><br><span class="line"><span class="keyword">include</span> <span class="variable">$(DOTENV)</span></span><br><span class="line"><span class="keyword">export</span></span><br><span class="line"></span><br><span class="line"><span class="section">run: ## run launches go server</span></span><br><span class="line">go run cmd/main/main.go</span><br></pre></td></tr></table></figure><p>develop環境に接続する場合は、次のように<code>DOTENV</code> 変数を指定して実行します。</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ make DOTENV=.env.develop run</span><br></pre></td></tr></table></figure><p>もし、 <code>run-dev</code> のようなターゲットを補完目的などで個別に定義したい場合は厄介です。ターゲット内のコマンドをインラインで変数上書きするか、以下のように <code>$(MAKECMDGOALS)</code> で includeするファイルを動的に <code>.env.develop</code> を書き換える必要があります。後者の例をあげます。 <code>lastword</code> は最後の文字列が一致するか判定するmakeの関数で <code>-dev</code> で終わっているかどうかを示します。</p><figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line">DOTENV := <span class="variable">$(PWD)</span>/.env</span><br><span class="line"></span><br><span class="line"><span class="comment"># run-dev 時に環境変数を書き換えたいため、includeをmakeのゴールのsuffixによって分岐する</span></span><br><span class="line"><span class="keyword">ifeq</span> (<span class="variable">$(<span class="built_in">lastword</span> <span class="variable">$(MAKECMDGOALS)</span>)</span>, -dev)</span><br><span class="line">DOTENV := <span class="variable">$(PWD)</span>/.env.develop</span><br><span class="line"><span class="keyword">endif</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">include</span> <span class="variable">$(DOTENV)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span></span><br><span class="line"></span><br><span class="line"><span class="section">run: ## run launches go server</span></span><br><span class="line">go run cmd/main/main.go</span><br><span class="line"></span><br><span class="line"><span class="section">run-dev: ## run-dev launches go server with development configurations</span></span><br><span class="line">go run cmd/main/main.go</span><br></pre></td></tr></table></figure><p>このあたりから、初見の人から見ると魔術感が漂ってくるため、ベタに環境変数をインラインで上書きするの戦略としてありだと思います。用法用量はチームメンバーのスキルセットも鑑み、調整していきましょう。</p><h2 id="サブフォルダのMakefileを呼び出す"><a href="#サブフォルダのMakefileを呼び出す" class="headerlink" title="サブフォルダのMakefileを呼び出す"></a>サブフォルダのMakefileを呼び出す</h2><p>クラウドネイティブ時代になり、複数の機能を1つのAPサーバにデプロイするのではなく、レポート、監視、システム間I&#x2F;Fなどの非同期処理はAWS Lambdaなど別サービスにデプロイすることが多くなりました。そのため、あるサービスを開発中にも複数のmainパッケージを持つプログラムを開発していると思います。それに相応してMakefile自体もそれぞれ存在していると思います。例えば、以下のようにMakefileを束ねるMakefileが存在し、一括でテスト、デプロイなどをしたいケースが出てくるかと思います。</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">.</span><br><span class="line">├── Makefile         <span class="comment"># ルートのMakefile</span></span><br><span class="line">├── go.mod</span><br><span class="line">├── go.sum</span><br><span class="line">├── batch</span><br><span class="line">│   ├── Makefile     <span class="comment"># ラッパー（一括実行用）</span></span><br><span class="line">│   ├── ***batch1</span><br><span class="line">│   │   └── Makefile <span class="comment"># 個別のMakefile</span></span><br><span class="line">│   ├── ***batch2</span><br><span class="line">│       └── Makefile <span class="comment"># 個別のMakefile</span></span><br><span class="line">├── send</span><br><span class="line">│   ├── Makefile     <span class="comment"># ラッパー（一括実行用）</span></span><br><span class="line">│   ├── enterprisesystem1</span><br><span class="line">│   │   └── Makefile <span class="comment"># 個別のMakefile</span></span><br><span class="line">│   ├── enterprisesystem2</span><br><span class="line">│       └── Makefile <span class="comment"># 個別のMakefile</span></span><br><span class="line">├── receive</span><br><span class="line">│   ├── Makefile     <span class="comment"># ラッパー（一括実行用）</span></span><br><span class="line">│   ├── johoukeisystem1</span><br><span class="line">│       └── Makefile <span class="comment"># 個別のMakefile</span></span><br><span class="line">├── job</span><br><span class="line">│   ├── Makefile     <span class="comment"># ラッパー（一括実行用）</span></span><br><span class="line">│   ├── ***-db-snapshot</span><br><span class="line">│       └── Makefile <span class="comment"># 個別のMakefile</span></span><br><span class="line">├── webapi</span><br></pre></td></tr></table></figure><p>Makefileが多段になるイメージですが、注意としてサブフォルダ側のMakefileは親フォルダ側のMakefileに依存しないように作るべきでしょう。例えば親側で環境変数のロードしたとして、それが無いと子ども側のMakefileが実行できないといった状態は避けるべきです。</p><p>上記のようなあるMakefileから別のMakefileを呼ぶ方法は次のように書くと良いでしょう。</p><figure class="highlight makefile"><figcaption><span>Makefile</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="section">build:</span></span><br><span class="line">    <span class="variable">$(MAKE)</span> -C batch   build --no-print-directory</span><br><span class="line">    <span class="variable">$(MAKE)</span> -C send    build --no-print-directory</span><br><span class="line">    <span class="variable">$(MAKE)</span> -C receive build --no-print-directory</span><br><span class="line">    <span class="variable">$(MAKE)</span> -C job     build --no-print-directory</span><br><span class="line">    <span class="variable">$(MAKE)</span> -C webapi  build --no-print-directory</span><br></pre></td></tr></table></figure><ul><li><code>$(MAKE)</code>: <code>make</code> ではなく <code>$(MAKE)</code> の変数を利用することで、<a href="https://www.gnu.org/software/make/manual/html_node/MAKE-Variable.html">-t (–touch), -n (–just-print) or –q (–question) のオプションが引き継がれたり</a>、<code>make ENV=dev build</code> などの変数を引き継いだりします</li><li><code>-C</code>: <code>--directory</code> と同義で、 <code>cd subdir &amp;&amp; $(MAKE)</code> と <code>$(MAKE) -C subdir</code> は同義です</li><li><code>--no-print-directory</code>: サブディレクトリへの移動したことの標準出力を抑制します。Goアプリ開発でmakeをタスクランナーのように利用する場合において、そこまで有益ではない情報なので消して良いでしょう。これについては、<code>MAKEFLAGS += --no-print-directory</code> をMakefileの先頭行に毎回つけるルールにするのもありかもしれません。</li></ul><p>ちなみにですが、次のように <code>-f</code> でMakefileを指定することもができますがこの場合には、makeを動かす作業ディレクトリが<code>subdir</code>ではなく、親側のディレクトリであるためおそらくうまく動作しません。たまにハマる人を見かけますのでご注意ください。</p><figure class="highlight makefile"><figcaption><span>Makefile（うまく動かない例）</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="section">run:</span></span><br><span class="line"><span class="variable">$(MAKE)</span> -f subdir/Makefile build --no-print-directory</span><br></pre></td></tr></table></figure><p>余談ですが、おそらく上述の <code>go build</code> はbatch, sendなどのパッケージ間で依存関係はないので、並列実行ができそうです（元の書き方では、batch→send→receive→job→webapiの順番で同期的に動作します）</p><p>面倒ですが個別にターゲットを定義する＋前提条件（Prerequisites）に追加すると、並列実行できます（前提条件同士は依存が無いと認識できるので、makeが並列で動かしてくれます）。例えばCIでビルドが可能か一括でチェックしているなどの場面で高速化したいケースがあるかと思います。</p><figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="section">build-batch: ## build all batch packages</span></span><br><span class="line">    <span class="variable">$(MAKE)</span> -C batch build --no-print-directory</span><br><span class="line"></span><br><span class="line"><span class="section">build-send: ## build all send packages </span></span><br><span class="line">    <span class="variable">$(MAKE)</span> -C send build --no-print-directory</span><br><span class="line"></span><br><span class="line"><span class="section">build-receive: ## build all receive packages </span></span><br><span class="line">    <span class="variable">$(MAKE)</span> -C receive build --no-print-directory</span><br><span class="line"></span><br><span class="line"><span class="section">build-job: ## build all job packages </span></span><br><span class="line">    <span class="variable">$(MAKE)</span> -C job build --no-print-directory</span><br><span class="line"></span><br><span class="line"><span class="section">build-webapi: ## build all webapi package</span></span><br><span class="line">    <span class="variable">$(MAKE)</span> -C webapi build --no-print-directory</span><br><span class="line"></span><br><span class="line"><span class="section">build: build-batch build-send build-receive build-job build-webapi</span></span><br></pre></td></tr></table></figure><p>実行する場合には、<code>-j</code> オプションで並列度を指定します。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">make build -j 4</span><br></pre></td></tr></table></figure><p>ここまでチューニングが必要な場合、このMakefileを手動でメンテナンスすることは大変なので、Makefileを自動生成するコードを準備すると良さそうです。</p><h2 id="CIサービスとの棲み分け"><a href="#CIサービスとの棲み分け" class="headerlink" title="CIサービスとの棲み分け"></a>CIサービスとの棲み分け</h2><p>意識しないと、 <code>make</code> と CI（CircleCIやGitHub Actions）で用いるYAMLに重複した内容を記述してしまいがちです。ポリシーとしては、リント・フォーマッタ・ビルド・デプロイなど基本的な操作はMakefileに記載し、CIからは makeコマンド経由でそれらを呼び出す形がよいでしょう。</p><p>例えば、<a href="https://circleci.com/docs/parallelism-faster-jobs/">CircleCIにはテスト並列</a>の仕組みがあります。Go側のテストがDBのデータに依存し、 <code>go test -p 4</code> で分割すると、同じテーブルに対しての複数のテストで書き込みされることでうまく動作しないことがあります。そのため、アプリ・DBのセットでまとめて並列実行してくれるようなCI側の仕組みを用いると便利です。</p><p>この場合もYAMLに記載するのではなく、Makefile側に <code>circleci tests split</code> というテスト並列の仕組みを記載すると統一感を維持できます。あまり Makefileにif文を記載するのはおすすめしませんが、この程度であれば許容しても良いでしょう。</p><figure class="highlight makefile"><figcaption><span>Makefile</span></figcaption><table><tr><td class="code"><pre><span class="line">SHELL := bash</span><br><span class="line">.SHELLFLAGS := -eu -o pipefail -c</span><br><span class="line"></span><br><span class="line"><span class="meta"><span class="keyword">.PHONY</span>: test</span></span><br><span class="line"></span><br><span class="line">PACKAGES ?= <span class="variable">$(<span class="built_in">shell</span> go list ./...)</span></span><br><span class="line"><span class="keyword">ifneq</span> (<span class="variable">$(CIRCLECI)</span>,)</span><br><span class="line">PACKAGES=<span class="variable">$(<span class="built_in">shell</span> go list ./... | circleci tests split --split-by=timings)</span></span><br><span class="line"><span class="keyword">endif</span></span><br><span class="line"></span><br><span class="line"><span class="section">test: ## test calls go test</span></span><br><span class="line">go test -p 1 -race -timeout 30m <span class="variable">$(PACKAGES)</span></span><br></pre></td></tr></table></figure><h2 id="環境別のデプロイ"><a href="#環境別のデプロイ" class="headerlink" title="環境別のデプロイ"></a>環境別のデプロイ</h2><p>CI&#x2F;CDパイプラインが整理されており、開発者が手動でデプロイするケースが減っているかもしれませんが、緊急パッチなど運用として環境別のデプロイが行えると一定の利便性があると思います。よくある構成例として、develop（dev）, staging（stg）, production（prod） の3つの環境へのデプロイを行うとします。</p><p>通常は各環境でリソース名に命名体系を持たせることが多いため、環境識別子だけ異なるにコマンドが並んでしまうと見通しが悪い場合があります。一方で、makeの引数に環境識別子を渡すときのチェックも行いたいです。そこで<a href="https://dev.classmethod.jp/articles/lambda-deploy-with-make/">make は強いタスクランナーだった。Lambda Function のライフサイクルを Makefile でまわす | DevelopersIO</a> にあるように、<code>gurd-%</code>のターゲットを前提条件とすることで、環境識別子（env）を必須入力とさせることがおすすめです。</p><p>また、<code>deploy-dev</code>, <code>deploy-stg</code>, <code>deploy-prod</code> などのターゲット名を宣言すると、ターミナルの補完が効くため利便性が高くなります。合わせると以下のような設定になると思います。AWS Lambdaにデプロイする例で書いています。</p><figure class="highlight makefile"><figcaption><span>Makefile</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="comment"># ...(省略)....</span></span><br><span class="line"></span><br><span class="line"><span class="section">deploy-dev: ## deploy development</span></span><br><span class="line"><span class="variable">$(MAKE)</span> deploy env=dev -s</span><br><span class="line"></span><br><span class="line"><span class="section">deploy-stg: ## deploy staging</span></span><br><span class="line"><span class="variable">$(MAKE)</span> deploy env=stg -s</span><br><span class="line"></span><br><span class="line"><span class="section">deploy-prod: ## deploy production</span></span><br><span class="line"><span class="variable">$(MAKE)</span> deploy env=prod -s</span><br><span class="line"></span><br><span class="line"><span class="section">deploy: guard-env build</span></span><br><span class="line">echo <span class="string">&quot;deploy $&#123;env&#125;&quot;</span></span><br><span class="line">aws lambda update-function-code --profile my_$&#123;env&#125; --region ap-northeast-1 --function-name $&#123;env&#125;-fuga-web-api --zip-file fileb://bin/bootstrap.zip</span><br><span class="line"></span><br><span class="line"><span class="section">guard-%:</span></span><br><span class="line">@ if [ <span class="string">&quot;$&#123;$&#123;*&#125;&#125;&quot;</span> = <span class="string">&quot;&quot;</span> ]; then \</span><br><span class="line">echo <span class="string">&quot;[ERROR] Environment variable <span class="variable">$*</span> not set&quot;</span>; \</span><br><span class="line">exit 1; \</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><p>本来であれば、 <code>deploy</code> や <code>guard-%</code> のターゲットはプライベート関数のような扱いで、直接開発者には呼び出しも補完もされず非可視化したかったのですが、残念ながらmakeにはそのような仕組みはありません（共通化したいターゲットを別Makefileにしてincludeしても無駄でした）。どこまでコードの冗長さを許容するかですが、扱うリソースや環境は増えやすいので、これくらいの集約は行ったほうがオススメしたいと思います。</p><h2 id="help"><a href="#help" class="headerlink" title="help"></a>help</h2><p><a href="https://postd.cc/auto-documented-makefile/">Makefileを自己文書化する | POSTD</a> から流用して、ファイルの最後に次のようにhelpコマンドを追加します。そうすると、 ターゲットの右側に <code>help: ## display this help screen</code> といったコメントを記載すると、helpコマンドで内容が表示されるようになります。</p><figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ...(省略)...</span></span><br><span class="line">.DEFAULT_GOAL := help</span><br><span class="line"><span class="comment"># ...(省略)...</span></span><br><span class="line"></span><br><span class="line"><span class="section">help: ## display this help screen</span></span><br><span class="line">    @grep -E &#x27;^[a-zA-Z_-]+:.*?<span class="comment">## .*$$&#x27; $(MAKEFILE_LIST) | sort | awk &#x27;BEGIN &#123;FS = &quot;:.*?## &quot;&#125;; &#123;printf &quot;\033[36m%-30s\033[0m %s\n&quot;, $$1, $$2&#125;&#x27;</span></span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ make <span class="built_in">help</span></span><br><span class="line">run                  run launches go server</span><br><span class="line"><span class="built_in">test</span>                 <span class="built_in">test</span> calls go <span class="built_in">test</span></span><br><span class="line">deploy-dev           deploy development</span><br><span class="line">deploy-stg           deploy staging</span><br><span class="line">deploy-prod          deploy production</span><br><span class="line"><span class="built_in">help</span>                 display this <span class="built_in">help</span> screen</span><br></pre></td></tr></table></figure><p>さきほど、<code>deploy</code>、<code>guard-%</code> などのターゲットは内部処理用でなるべく外に出したくないという話をしました。完全ではないですが、この<code>help</code>コマンドではそういった内部処理用のターゲットはコメントを書かないことで、公開用のターゲットではないという意図を込めることができます（やや婉曲的ですが）。</p><p>もし、ターゲットの右側にコメントを書くのではなく、以下のようにコメント＋改行で表現したい場合は、Songmuさんの<a href="https://github.com/Songmu/make2help">Songmu&#x2F;make2help</a>というツールもあります。コメントを記載するお作法としてはこちらの方がおそらく直感的であるため、コマンドのインストールが必要ですが、チームの方針としてこちらを採用することもお勧めです。</p><figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="comment">## Run tests</span></span><br><span class="line"><span class="section">test:</span></span><br><span class="line">    go test ./...</span><br><span class="line"></span><br><span class="line"><span class="comment">## Show help</span></span><br><span class="line"><span class="section">help:</span></span><br><span class="line">  @make2help <span class="variable">$(MAKEFILE_LIST)</span></span><br></pre></td></tr></table></figure><h2 id="ターゲット名をtypoした場合にhelpメッセージを出す"><a href="#ターゲット名をtypoした場合にhelpメッセージを出す" class="headerlink" title="ターゲット名をtypoした場合にhelpメッセージを出す"></a>ターゲット名をtypoした場合にhelpメッセージを出す</h2><p>趣味的な作り込みですが、<code>make bulid</code> や <code>make h</code>のように、タイポしたり短縮形のコマンドを入力してしまった場合に、helpメッセージを出したいとします（helpが実装されているかどうか気が付かない場合があるので、気づきやすくする目的です）。その場合、全てに一致する <code>%</code> というターゲットを利用するのも手です。</p><p>例として次のように定義します。</p><figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="section">%:</span></span><br><span class="line">@echo &#x27;command <span class="string">&quot;<span class="variable">$@</span>&quot;</span> is not found.&#x27;</span><br><span class="line">@<span class="variable">$(MAKE)</span> help</span><br><span class="line">@exit 2</span><br></pre></td></tr></table></figure><p>実行すると、 “h” というターゲット名が存在しない場合は、helpの内容を出すことができます。</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ make h</span><br><span class="line"><span class="built_in">command</span> <span class="string">&quot;h&quot;</span> is not found.</span><br><span class="line">run                  run launches go server</span><br><span class="line"><span class="built_in">test</span>                 <span class="built_in">test</span> calls go <span class="built_in">test</span></span><br><span class="line">deploy-dev           deploy development</span><br><span class="line">deploy-stg           deploy staging</span><br><span class="line">deploy-prod          deploy production</span><br><span class="line"><span class="built_in">help</span>                 display this <span class="built_in">help</span> screen</span><br><span class="line">make: *** [Makefile:80: 1] エラー 2</span><br><span class="line"></span><br><span class="line">$ <span class="built_in">echo</span> $?</span><br><span class="line">2</span><br></pre></td></tr></table></figure><p>元の挙動と合わせるために、終了ステータスを2に設定しているため、エラー文が出てしまうのがノイズですね。なるべく <code>help</code> を出して問い合わせを減らしたい場合など、状況を見て追加すると良いでしょう。</p><h2 id="標準的なターゲット名と成果物ファイル名"><a href="#標準的なターゲット名と成果物ファイル名" class="headerlink" title="標準的なターゲット名と成果物ファイル名"></a>標準的なターゲット名と成果物ファイル名</h2><p>開発者フレンドリーを目指すと、<code>make build</code> でコードがビルドできたほうが直感的でしょう。一方でmakeの成果物管理を考えると、 <code>go build -o bootstrap main.go</code> などで用いる、コンパイル対象の.goのファイルや ビルド結果の <code>bootstrap</code> をmakeファイルとして定義していきたいです。両者をバランスを取ると、どちらも定義していくことが多いと思います。</p><p>例えば次のように、 <code>build</code> は <code>bootstrap</code> への依存のみで、実態は <code>bootstrap</code> 側に処理を記載すると行った具合です。</p><figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ...(省略)...</span></span><br><span class="line">GO_FILES:=<span class="variable">$(<span class="built_in">shell</span> find . -type f -name &#x27;*.go&#x27; -print)</span></span><br><span class="line"><span class="comment"># ...(省略)...</span></span><br><span class="line"></span><br><span class="line"><span class="section">build: bootstrap ## build creates go binary</span></span><br><span class="line">@:</span><br><span class="line"></span><br><span class="line"><span class="section">bootstrap: <span class="variable">$(GO_FILES)</span> go.mod go.sum .git/HEAD .git/refs/tags .git/refs/heads</span></span><br><span class="line">@GOOS=linux GOARCH=amd64 go build \</span><br><span class="line">-ldflags=<span class="string">&quot;-s -w -buildid= -X main.version=$(shell git describe --tags --abbrev=0) -X main.revision=$(shell git rev-parse --short HEAD)&quot;</span> \</span><br><span class="line">-trimpath -o bootstrap cmd/main/main.go</span><br></pre></td></tr></table></figure><p>bootstrapターゲット内で <code>go build</code> を行っています。業務でよく使いそうなオプションを渡したり、GitタグやGitリビジョンも埋め込むようにしています。依存関係として <code>.go</code> のファイル以外にもgo.mod, go.sum を追加しています。<code>.git</code> 系の3フォルダは通常不要ですが、Gitのタグ名やリビジョンをビルド時に含めているため追加しています。他にも <code>go:embed</code> で外部ファイルを埋め込みしている場合は個別に依存関係に追加する必要があります（ややこしいので、goファイルが配備されるパッケージ配下すべてを追加するのもありですね）。</p><p><code>build</code> ターゲットで <code>@:</code> としているのは、もしbootstrapが作成済みの場合に<code>make: &#39;build&#39; に対して行うべき事はありません.</code> という警告を無視するためのハックです。<code>@</code>がコマンドを表示させないという意味で、<code>:</code> は何も行わないシェルスクリプト側のコマンドです。<code>@:</code> は無くても構いません。</p><p>他にも有名な標準ターゲットは定義しておくと良いでしょう。追加で私がよく用いるターゲットもまとめます。</p><figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="section">all: generate fmt lint test build</span></span><br><span class="line"></span><br><span class="line"><span class="section">setup: ## install tools for development</span></span><br><span class="line">    @go install xxxx  </span><br><span class="line"></span><br><span class="line"><span class="section">generate: ## code generate</span></span><br><span class="line">    @<span class="comment"># コード生成処理があれば</span></span><br><span class="line"></span><br><span class="line"><span class="section">fmt: ## code format</span></span><br><span class="line">    @<span class="comment"># フォーマット処理</span></span><br><span class="line"></span><br><span class="line"><span class="section">lint: ## Lint</span></span><br><span class="line">    @<span class="comment"># リント処理（go vet ./...など）、markdownlint、misspell、govulncheck、など（いくつかは前提条件にしたほうが並列化が効く）</span></span><br><span class="line"></span><br><span class="line"><span class="section">test: ## test calls go test（e.g. make option=-v test、 make option=&quot;-v -short&quot; test、 make option=&quot;-run TestAttach&quot;）</span></span><br><span class="line">date</span><br><span class="line">go test -race -timeout 30m <span class="variable">$(option)</span> ./...</span><br><span class="line"></span><br><span class="line"><span class="section">test-coverage: cover.html ## test-coverage displays code coverage per package</span></span><br><span class="line">@go tool cover -func cover.out</span><br><span class="line"></span><br><span class="line"><span class="section">cover.out:</span></span><br><span class="line">@go test -race -timeout 30m -cover ./... -coverprofile=cover.out</span><br><span class="line">@echo <span class="string">&quot;create cover.out&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="section">cover.html: cover.out</span></span><br><span class="line">@go tool cover -html=cover.out -o cover.html</span><br><span class="line">@echo <span class="string">&quot;create cover.html&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="section">clean: ## Remove output files and clean cache</span></span><br><span class="line">    @rm -rf bootstrap</span><br><span class="line">    @go clean</span><br></pre></td></tr></table></figure><p>Goのテストですが、<code>$(option)</code> というオプションを追加しています。Goでテスト実行の場合、特定のテストだけ実行したい場合は <code>-run TestSum</code> などと指定したいときや、 <code>-v</code>、<code>-short</code>、<code>-vet=all</code> など様々なオプションを渡したいときがあります。その場合にmake経由で対応できるようにするため拡張用に用意しています。</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 通常</span></span><br><span class="line">$ make <span class="built_in">test</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># -v を渡したい</span></span><br><span class="line">$ make option=-v <span class="built_in">test</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># -v と-short を渡したい</span></span><br><span class="line">$ make option=<span class="string">&quot;-v -short&quot;</span> <span class="built_in">test</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># -run を渡したい</span></span><br><span class="line">$ make option=<span class="string">&quot;-run TestCalcPoint&quot;</span> <span class="built_in">test</span></span><br></pre></td></tr></table></figure><h2 id="まとめ"><a href="#まとめ" class="headerlink" title="まとめ"></a>まとめ</h2><p>ここ数年間、業務ではGoを用いてアプリケーションを開発してきました。そのお供にとしてMakefileもよく編集してきたのですが、一度仕様が固まるとめったに書き換えないため、知識が定着しないのが悩みでした。今回、複数チームで利用頻度が高そう＋実践的な内容を抽出して、まとめました。よい機会でした。</p><p>それでは良いmakeライフを。ありがとうございました。</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;img src=&quot;/images/20231012a/gnu-make.png&quot; alt=&quot;&quot; width=&quot;800&quot; height=&quot;418&quot;&gt;

&lt;h2 id=&quot;はじめに&quot;&gt;&lt;a href=&quot;#はじめに&quot; class=&quot;headerlink&quot;</summary>
        
      
    
    
    
    <category term="Programming" scheme="https://future-architect.github.io/categories/Programming/"/>
    
    
    <category term="Go" scheme="https://future-architect.github.io/tags/Go/"/>
    
    <category term="チーム開発" scheme="https://future-architect.github.io/tags/%E3%83%81%E3%83%BC%E3%83%A0%E9%96%8B%E7%99%BA/"/>
    
    <category term="Makefile" scheme="https://future-architect.github.io/tags/Makefile/"/>
    
    <category term="EditorConfig" scheme="https://future-architect.github.io/tags/EditorConfig/"/>
    
    <category term="checkmake" scheme="https://future-architect.github.io/tags/checkmake/"/>
    
    <category term="dotenv" scheme="https://future-architect.github.io/tags/dotenv/"/>
    
  </entry>
  
  <entry>
    <title>Prompt Flowをローカルで動かす＆コードで管理する</title>
    <link href="https://future-architect.github.io/articles/20231011a/"/>
    <id>https://future-architect.github.io/articles/20231011a/</id>
    <published>2023-10-10T15:00:00.000Z</published>
    <updated>2023-10-11T01:57:02.974Z</updated>
    
    <content type="html"><![CDATA[<h2 id="はじめに"><a href="#はじめに" class="headerlink" title="はじめに"></a>はじめに</h2><p>こんにちは、SAIG&#x2F;MLOpsチームでアルバイトをしている板野です。</p><p>AzureのPrompt Flowをローカル環境で動かし、作成したフローをコードで管理する方法をご紹介します。</p><p>Prompt Flowとは、Azure Machine Learning上の機能で、Azure OpenAIで提供されているLLMを利用したアプリケーション開発を円滑にするためのツールです。</p><p>実際にLLMアプリケーションを開発する場合、「プロンプトを入力して終わり」ではなく、ベクトル検索など複数の要素を組み合わせることもあります。このため、Prompt Flowでは処理のフローをDAG(有向非巡回グラフ)で可視化することで、開発効率が大きく向上します。</p><p>Prompt FlowはPython<a href="https://github.com/microsoft/promptflow">ライブラリ</a>（2023&#x2F;09&#x2F;27時点ではMITライセンス）として提供されており、Azureのコンソール画面だけでなく、ローカル環境でも実行することができます。</p><p>ローカルで実行できることには以下の利点があります。</p><ul><li>特定のクラウドベンダーに依存しないので開発の選択肢が広がる</li><li>フローをコードで管理できる<ul><li>よくアップデートされるGUIの変化に戸惑う必要がない</li><li>コード編集の差分を記録できる</li></ul></li></ul><p>※本記事では、読者は「Azureのコンソール画面でのPrompt Flowの操作をしたことがある」という前提でご説明します。</p><h2 id="事前準備"><a href="#事前準備" class="headerlink" title="事前準備"></a>事前準備</h2><h3 id="1-Pythonのインストール"><a href="#1-Pythonのインストール" class="headerlink" title="1. Pythonのインストール"></a>1. Pythonのインストール</h3><p>Prompt Flowを動かすには、<code>Python 3.9</code>あるいは<code>Python 3.10</code>以上がインストールされている必要があります。</p><h3 id="2-Prompt-Flowライブラリのインストール"><a href="#2-Prompt-Flowライブラリのインストール" class="headerlink" title="2. Prompt Flowライブラリのインストール"></a>2. Prompt Flowライブラリのインストール</h3><p>以下のコマンドで<code>promptflow</code>,<code>promptflow-tools</code>のライブラリをインストールします</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">pip install promptflow promptflow-tools</span><br></pre></td></tr></table></figure><p>インストールが完了したら以下のコマンドでpromptflowのバージョンが出力されます</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># (例) &quot;0.1.0b5&quot;</span></span><br><span class="line">pf -v </span><br></pre></td></tr></table></figure><h3 id="3-VSCode拡張機能をインストール"><a href="#3-VSCode拡張機能をインストール" class="headerlink" title="3. VSCode拡張機能をインストール"></a>3. VSCode拡張機能をインストール</h3><p>Prompt FlowのVSCode拡張機能をインストールします。</p><p>VSCodeの拡張機能にて「Prompt Flow」で検索すると出てきます。</p><img src="/images/20231011a/image.png" alt="Prompt Flow for VS Code" width="1200" height="560" loading="lazy"><p>VSCode拡張機能が無くてもPrompt Flow自体は動かせますが、フローの可視化機能があるので、VSCodeが使用できる場合は入れておきましょう。</p><p>本記事ではVSCode拡張機能がインストールされている前提で説明していきます。</p><h2 id="シンプルな標準フローを作成する"><a href="#シンプルな標準フローを作成する" class="headerlink" title="シンプルな標準フローを作成する"></a>シンプルな標準フローを作成する</h2><p>以下のコマンドで、最もシンプルな標準フローが作成できます。<br><code>my-simple-flow</code>の部分はお好きなフロー名に変更してください。</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">pf flow init --flow my-simple-flow</span><br></pre></td></tr></table></figure><p>コマンドを実行したディレクトリの直下に<code>my-simple-flow</code>ディレクトリが自動生成されます。</p><p>中身は以下の通りです。</p><img src="/images/20231011a/image_2.png" alt="my-simple-flow, \pycache_, promptflow, flow.tools.json, .gitignore, data.jsonl, flow.dag.yaml, hello.jinja, hello.py, requirements.txt" width="432" height="330" loading="lazy"><ul><li><code>__pycache__</code>: Pythonを実行する際に生成されるキャッシュディレクトリ（削除しても特に問題はない）</li><li><code>.promptflow/flow.tools.json</code>: flow.dag.yamlから参照されるToolsのメタデータ（修正する必要はない） </li><li><code>data.jsonl</code>: フローに入力するデータ</li><li><code>flow.dag.yaml</code>: 入出力・ノード・バリアント等を含むフローの全てを定義したファイル</li><li><code>.py, .jinja2等のファイル</code>: フロー内のツールが参照するコードスクリプト</li><li><code>requirements.txt</code>: フローの実行に必要なPythonパッケージのリスト</li></ul><p><code>flow.dag.yaml</code>ファイルの中身は以下の通りです。テキストベースなフロー定義データなので、直感では何をするフローか分かりにくいですね。</p><p>そこで赤枠の<code>Visual editor</code>を押してみます。</p><img src="/images/20231011a/コメント_2023-09-25_163948.png" alt="Visual editoor(Ctrl + k, v)" width="1156" height="1140" loading="lazy"><p>すると、Azureコンソールでお馴染みのGUIベースの編集画面が出てきます。</p><p>「入力されたテキストをシステムプロンプトに含めて出力する」という、LLMを使わない簡単なフローのようです。</p><img src="/images/20231011a/pic.png" alt="" width="1200" height="612" loading="lazy"><p>このVisual editorで編集した内容は、<code>flow.dag.yaml</code>のテキストデータに反映されるので、GUIベース及びテキストベースのどちらからでも編集可能です。</p><p>一度、フローを動かしてみます。</p><p>上図赤枠の部分に好きなテキスト（ここでは<code>Hello World!</code>）を入力し、<code>my-simple-flow</code>の親ディレクトリから以下のコマンドを打ちます。</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">pf flow <span class="built_in">test</span> --flow my-simple-flow</span><br></pre></td></tr></table></figure><p>すると、以下のようなコンソール出力が返ってきます。</p><img src="/images/20231011a/pic2.png" alt="output_prompt: Prompt: Write a simple Hello World! program that displays the greeting message when executed." width="1200" height="147" loading="lazy"><p>「入力されたテキストをシステムプロンプトに含めて出力する」というシンプルな標準フローが実行できました。</p><h2 id="LLM付きの標準フローを作成する"><a href="#LLM付きの標準フローを作成する" class="headerlink" title="LLM付きの標準フローを作成する"></a>LLM付きの標準フローを作成する</h2><p>ここでは、入力された質問に対する応答をしてもらうフローを作っていきます。</p><p>前章で作成したフローの中にLLM（Prompt FlowではLLMツール&#x2F;LLMノードと呼ぶ）を追加し、少し複雑になったフローです。</p><h3 id="1-Connectionの設定"><a href="#1-Connectionの設定" class="headerlink" title="1. Connectionの設定"></a>1. Connectionの設定</h3><p>まずはConnection（接続）の設定を行います。</p><p>任意のディレクトリ上で、接続先を定義するYAMLファイルを作成します。（ここでは<code>connection-azure-openai.yaml</code>という名前で作成）</p><p>YAMLファイルの中身は<a href="https://microsoft.github.io/promptflow/how-to-guides/manage-connections.html">公式Docs</a>を参考に以下のように作ります。</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">$schema:</span> <span class="string">https://azuremlschemas.azureedge.net/promptflow/latest/AzureOpenAIConnection.schema.json</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">connection-azure-openai</span> <span class="comment"># 好きなコネクション名に設定可</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">azure_open_ai</span></span><br><span class="line"><span class="attr">api_key:</span> <span class="string">&lt;API_KEY&gt;</span> <span class="comment"># Azure OpenAIリソースのAPIキー</span></span><br><span class="line"><span class="attr">api_base:</span> <span class="string">&lt;API_BASE&gt;</span> <span class="comment"># Azure OpenAIリソースのベース（エンドポイントURL）</span></span><br><span class="line"><span class="attr">api_type:</span> <span class="string">azure</span></span><br><span class="line"><span class="attr">api_version:</span> <span class="number">2023-07-01</span><span class="string">-preview</span> <span class="comment"># バージョンは変わる可能性あり</span></span><br></pre></td></tr></table></figure><p>YAMLファイルが作成できたら、以下のコマンドでconnectionを追加します。</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">pf connection create -f &lt;YAMLファイルのパス&gt;</span><br></pre></td></tr></table></figure><p>以下のように詳細が表示されればConnection（接続）の設定は完了です。</p><img src="/images/20231011a/pic3.png" alt="" width="1200" height="257" loading="lazy"><h3 id="2-LLMツールの追加"><a href="#2-LLMツールの追加" class="headerlink" title="2. LLMツールの追加"></a>2. LLMツールの追加</h3><p>続いて、LLMツールを追加していきます。<code>flow.dag.yaml</code>のVisual editorの画面から「+LLM」を押します。</p><img src="/images/20231011a/pic4.png" alt="+LLM" width="1200" height="436" loading="lazy"><p>上部に、LLMツールの名前入力が求められるので好きな名前を設定します。（ここでは<code>llm_node</code>と設定）</p><img src="/images/20231011a/image_3.png" alt="llm_node" width="889" height="97" loading="lazy"><p>名前入力が完了すると、「new file」を選択します。（<code>&lt;LLMツール名&gt;.jinja2</code>というファイルが新規生成されます）</p><img src="/images/20231011a/image_4.png" alt="new file" width="885" height="131" loading="lazy"><p>LLMツールが追加されました。connectionには先程設定した接続先が選択できるようになっています。</p><img src="/images/20231011a/pic5.png" alt="connection:connection-azure-openai api:chat deployment_name:***-gpt35-01 temperature:1 stop: max_tokens:" width="1200" height="266" loading="lazy"><h3 id="3-フローの編集"><a href="#3-フローの編集" class="headerlink" title="3. フローの編集"></a>3. フローの編集</h3><p>入力された質問に対する応答をしてもらうフローを作っていきます。</p><p>Azureコンソールでは、1つの画面で全てのソースコードやプロンプトを直接編集できますが、ここではソースファイル毎に編集する必要があります。</p><p>フローの概略は以下の通りです。</p><p><code>Inputs</code>でユーザーからの質問を受け取り、<code>system_prompt</code>でシステムプロンプトにユーザーの質問を埋め込み、<code>llm_node</code>でLLMにプロンプトを投げ、<code>echo_llm_output</code>でLLMからの回答を加工して<code>output</code>に出力します。</p><img src="/images/20231011a/image_5.png" alt="inputs -> system_prompt -> llm_node -> echo_llm_output -> outputs" width="1200" height="1266" loading="lazy"><details><summary>flow.dag.yaml</summary><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">environment:</span></span><br><span class="line">  <span class="attr">python_requirements_txt:</span> <span class="string">requirements.txt</span></span><br><span class="line"><span class="attr">inputs:</span></span><br><span class="line">  <span class="attr">question:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">string</span></span><br><span class="line">    <span class="attr">default:</span> <span class="string">東京はどこの国の都市？</span></span><br><span class="line"><span class="attr">outputs:</span></span><br><span class="line">  <span class="attr">output:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">string</span></span><br><span class="line">    <span class="attr">reference:</span> <span class="string">$&#123;echo_llm_output.output&#125;</span></span><br><span class="line"><span class="attr">nodes:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">system_prompt</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">prompt</span></span><br><span class="line">  <span class="attr">source:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">code</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">system_prompt.jinja2</span></span><br><span class="line">  <span class="attr">inputs:</span></span><br><span class="line">    <span class="attr">question:</span> <span class="string">$&#123;inputs.question&#125;</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">echo_llm_output</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">python</span></span><br><span class="line">  <span class="attr">source:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">code</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">echo_llm_output.py</span></span><br><span class="line">  <span class="attr">inputs:</span></span><br><span class="line">    <span class="attr">input:</span> <span class="string">$&#123;llm_node.output&#125;</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">llm_node</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">llm</span></span><br><span class="line">  <span class="attr">source:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">code</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">llm_node.jinja2</span></span><br><span class="line">  <span class="attr">inputs:</span></span><br><span class="line">    <span class="attr">input_prompt:</span> <span class="string">$&#123;system_prompt.output&#125;</span></span><br><span class="line">    <span class="attr">deployment_name:</span> <span class="string">gpt35-01</span></span><br><span class="line">    <span class="attr">max_tokens:</span> <span class="number">256</span></span><br><span class="line">  <span class="attr">connection:</span> <span class="string">connection-azure-openai</span></span><br><span class="line">  <span class="attr">api:</span> <span class="string">chat</span></span><br></pre></td></tr></table></figure></details><p>各ノードの詳細は以下の通りです。</p><h4 id="Inputs-amp-Outputs"><a href="#Inputs-amp-Outputs" class="headerlink" title="Inputs&amp;Outputs"></a>Inputs&amp;Outputs</h4><img src="/images/20231011a/image_6.png" alt="question string 東京はどこの国の都市？" width="1200" height="333" loading="lazy"><h4 id="system-prompt"><a href="#system-prompt" class="headerlink" title="system_prompt"></a>system_prompt</h4><img src="/images/20231011a/image_7.png" alt="${inputs.question}" width="1200" height="222" loading="lazy"><details><summary>system_prompt.jinja2</summary><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">system:</span><br><span class="line">あなたは優秀なAIチャットボットです。ユーザーからの質問に答えて下さい。</span><br><span class="line"></span><br><span class="line">user: </span><br><span class="line">&#123;&#123;question&#125;&#125; </span><br><span class="line"></span><br><span class="line">AI:</span><br></pre></td></tr></table></figure></details><h4 id="llm-node"><a href="#llm-node" class="headerlink" title="llm_node"></a>llm_node</h4><img src="/images/20231011a/pic6.png" alt="" width="1200" height="309" loading="lazy"><details><summary>llm_node.jinja2</summary><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;&#123;input_prompt&#125;&#125;</span><br></pre></td></tr></table></figure></details><h4 id="echo-llm-output"><a href="#echo-llm-output" class="headerlink" title="echo_llm_output"></a>echo_llm_output</h4><img src="/images/20231011a/image_8.png" alt="" width="1200" height="218" loading="lazy"><details><summary>echo_llm_output.py</summary><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> promptflow <span class="keyword">import</span> tool</span><br><span class="line"></span><br><span class="line"><span class="meta">@tool</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">echo_llm_output</span>(<span class="params"><span class="built_in">input</span>: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;LLM出力: &quot;</span> + <span class="built_in">input</span></span><br></pre></td></tr></table></figure></details><h3 id="4-フローの実行"><a href="#4-フローの実行" class="headerlink" title="4. フローの実行"></a>4. フローの実行</h3><p>フローの編集が終わったら、先程と同様に以下のコマンドで実行します。</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">pf flow <span class="built_in">test</span> --flow my-simple-flow</span><br></pre></td></tr></table></figure><p>Outputsの欄に出力が表示されます。</p><img src="/images/20231011a/image_9.png" alt="" width="914" height="440" loading="lazy"><h3 id="5-フローの一括実行"><a href="#5-フローの一括実行" class="headerlink" title="5. フローの一括実行"></a>5. フローの一括実行</h3><p>複数の入力を一括で実行することもできます。</p><p>まずは<code>flow.dag.yaml</code>ファイルを編集し、<code>default: 東京はどこの国の都市？</code>の行をコメントアウトします。</p><details><summary>flow.dag.yaml（コメントアウト後）</summary><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">environment:</span></span><br><span class="line">  <span class="attr">python_requirements_txt:</span> <span class="string">requirements.txt</span></span><br><span class="line"><span class="attr">inputs:</span></span><br><span class="line">  <span class="attr">question:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">string</span></span><br><span class="line">    <span class="comment"># default: 東京はどこの国の都市？</span></span><br><span class="line"><span class="attr">outputs:</span></span><br><span class="line">  <span class="attr">output:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">string</span></span><br><span class="line">    <span class="attr">reference:</span> <span class="string">$&#123;echo_llm_output.output&#125;</span></span><br><span class="line"><span class="attr">nodes:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">system_prompt</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">prompt</span></span><br><span class="line">  <span class="attr">source:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">code</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">system_prompt.jinja2</span></span><br><span class="line">  <span class="attr">inputs:</span></span><br><span class="line">    <span class="attr">question:</span> <span class="string">$&#123;inputs.question&#125;</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">echo_llm_output</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">python</span></span><br><span class="line">  <span class="attr">source:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">code</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">echo_llm_output.py</span></span><br><span class="line">  <span class="attr">inputs:</span></span><br><span class="line">    <span class="attr">input:</span> <span class="string">$&#123;llm_node.output&#125;</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">llm_node</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">llm</span></span><br><span class="line">  <span class="attr">source:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">code</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">llm_node.jinja2</span></span><br><span class="line">  <span class="attr">inputs:</span></span><br><span class="line">    <span class="attr">input_prompt:</span> <span class="string">$&#123;system_prompt.output&#125;</span></span><br><span class="line">    <span class="attr">deployment_name:</span> <span class="string">gpt35-01</span></span><br><span class="line">    <span class="attr">max_tokens:</span> <span class="number">256</span></span><br><span class="line">  <span class="attr">connection:</span> <span class="string">connection-azure-openai</span></span><br><span class="line">  <span class="attr">api:</span> <span class="string">chat</span></span><br></pre></td></tr></table></figure></details><p>次に、フローのディレクトリ内にあった<code>data.jsonl</code>を編集し、以下のような内容を記載します。</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;question&quot;</span><span class="punctuation">:</span> <span class="string">&quot;オーストラリアの首都は？&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;question&quot;</span><span class="punctuation">:</span> <span class="string">&quot;アメリカの首都は？&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;question&quot;</span><span class="punctuation">:</span> <span class="string">&quot;イギリスの首都は？&quot;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>1行が1つの入力に相当します。質問文を変えたり行を追加したりしても大丈夫です。</p><p>最後に、フローの親ディレクトリから以下のコマンドを実行します。（<code>my_run_001</code>の部分は任意）</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">pf run create --flow my-simple-flow --data ./my-simple-flow/data.jsonl --name my_run_001</span><br></pre></td></tr></table></figure><p>以下のような出力が返ってくれば一括実行は成功です。</p><img src="/images/20231011a/7.png" alt="" width="1200" height="297" loading="lazy"><p>複数実行の結果はログとして記録されており、以下のコマンドでいつでも可視化できます。</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">pf run show-details --name my_run_001</span><br></pre></td></tr></table></figure><img src="/images/20231011a/8.png" alt="" width="1007" height="312" loading="lazy"><h2 id="作成したフローをコードで管理する"><a href="#作成したフローをコードで管理する" class="headerlink" title="作成したフローをコードで管理する"></a>作成したフローをコードで管理する</h2><p>今回作成したファイル群は以下の通りです。</p><img src="/images/20231011a/image_10.png" alt="" width="472" height="368" loading="lazy"><p>これらはgitで管理することができます。</p><p>予め<code>.gitignore</code>ファイルが含まれているため、余計なキャッシュ等を含まずプッシュすることができますが、connection情報が入ったYAMLファイルは後で作成したファイルなので、プッシュしてしまう恐れがあります。</p><p>該当ファイルを<code>.gitignore</code>に追記するなどして、十分注意してください。</p><h2 id="まとめ"><a href="#まとめ" class="headerlink" title="まとめ"></a>まとめ</h2><p>本記事ではAzureのPrompt Flowをローカル環境で動かし、作成したフローをコードで管理する方法をご紹介しました。</p><p>LLMの開発や運用(LLMOps)に携わっている方々や、Prompt Flowを試している方々の参考となれば幸いです。</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h2 id=&quot;はじめに&quot;&gt;&lt;a href=&quot;#はじめに&quot; class=&quot;headerlink&quot; title=&quot;はじめに&quot;&gt;&lt;/a&gt;はじめに&lt;/h2&gt;&lt;p&gt;こんにちは、SAIG&amp;#x2F;MLOpsチームでアルバイトをしている板野です。&lt;/p&gt;
&lt;p&gt;AzureのPrompt</summary>
        
      
    
    
    
    <category term="DataScience" scheme="https://future-architect.github.io/categories/DataScience/"/>
    
    
    <category term="Azure" scheme="https://future-architect.github.io/tags/Azure/"/>
    
    <category term="LLM" scheme="https://future-architect.github.io/tags/LLM/"/>
    
    <category term="Prompt Flow" scheme="https://future-architect.github.io/tags/Prompt-Flow/"/>
    
    <category term="AzureOpenAIService" scheme="https://future-architect.github.io/tags/AzureOpenAIService/"/>
    
  </entry>
  
  <entry>
    <title>go vet に含まれないスタンドアロンな静的解析ツールたち</title>
    <link href="https://future-architect.github.io/articles/20231005a/"/>
    <id>https://future-architect.github.io/articles/20231005a/</id>
    <published>2023-10-04T15:00:00.000Z</published>
    <updated>2023-10-05T00:26:23.899Z</updated>
    
    <content type="html"><![CDATA[<img src="/images/20231005a/etactics-inc-g3PsF4_y7ZY-unsplash.jpg" alt="" width="800" height="533"><h2 id="はじめに"><a href="#はじめに" class="headerlink" title="はじめに"></a>はじめに</h2><p>TIG真野です。育休明けです。</p><p>Go言語の特徴の一つに、静的解析ツールがリッチということがあると思いますが、代表格である <code>go vet</code> と付随する（という表現が正しいか不明ですが）ツール群についてまとめます。知っておくと似たようなツールを作ってしまうことを防げるかなという点と、類似のチェックを行いたい場合に参考にしたいこと、ユースケースが合えばこれらを利用してハッピーになりたいという思いがあります。</p><h2 id="go-vetとは"><a href="#go-vetとは" class="headerlink" title="go vetとは"></a>go vetとは</h2><p><a href="https://pkg.go.dev/cmd/vet">go vet</a> はGo言語に標準で組み込まれた静的解析ツールで、コンパイラによってキャッチされないエラーや懸念を検出し報告してくれます。Linter（リンター）の一種です。</p><p>チェック内容の一覧は <code>go tool vet help</code> コマンドで確認できます。デフォルトでは全て有効になっており（<code>-asmdecl=false</code> などで個別に無効化は可能）、Go1.21時点では30のチェックが存在します。</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ go version</span><br><span class="line">go version go1.21.1 linux/amd64</span><br><span class="line"></span><br><span class="line">$ go tool vet <span class="built_in">help</span></span><br><span class="line">(中略)</span><br><span class="line">Registered analyzers:</span><br><span class="line"></span><br><span class="line">    asmdecl      report mismatches between assembly files and Go declarations</span><br><span class="line">    assign       check <span class="keyword">for</span> useless assignments</span><br><span class="line">    atomic       check <span class="keyword">for</span> common mistakes using the <span class="built_in">sync</span>/atomic package</span><br><span class="line">    bools        check <span class="keyword">for</span> common mistakes involving boolean operators</span><br><span class="line">    buildtag     check //go:build and // +build directives</span><br><span class="line">    cgocall      detect some violations of the cgo pointer passing rules</span><br><span class="line">    composites   check <span class="keyword">for</span> unkeyed composite literals</span><br><span class="line">    copylocks    check <span class="keyword">for</span> locks erroneously passed by value</span><br><span class="line">    directive    check Go toolchain directives such as //go:debug</span><br><span class="line">    errorsas     report passing non-pointer or non-error values to errors.As</span><br><span class="line">    framepointer report assembly that clobbers the frame pointer before saving it</span><br><span class="line">    httpresponse check <span class="keyword">for</span> mistakes using HTTP responses</span><br><span class="line">    ifaceassert  detect impossible interface-to-interface <span class="built_in">type</span> assertions</span><br><span class="line">    loopclosure  check references to loop variables from within nested <span class="built_in">functions</span></span><br><span class="line">    lostcancel   check cancel func returned by context.WithCancel is called</span><br><span class="line">    nilfunc      check <span class="keyword">for</span> useless comparisons between <span class="built_in">functions</span> and nil</span><br><span class="line">    <span class="built_in">printf</span>       check consistency of Printf format strings and arguments</span><br><span class="line">    <span class="built_in">shift</span>        check <span class="keyword">for</span> shifts that equal or exceed the width of the <span class="built_in">integer</span></span><br><span class="line">    sigchanyzer  check <span class="keyword">for</span> unbuffered channel of os.Signal</span><br><span class="line">    slog         check <span class="keyword">for</span> invalid structured logging calls</span><br><span class="line">    stdmethods   check signature of methods of well-known interfaces</span><br><span class="line">    stringintconv check <span class="keyword">for</span> string(int) conversions</span><br><span class="line">    structtag    check that struct field tags conform to reflect.StructTag.Get</span><br><span class="line">    testinggoroutine report calls to (*testing.T).Fatal from goroutines started by a <span class="built_in">test</span>.</span><br><span class="line">    tests        check <span class="keyword">for</span> common mistaken usages of tests and examples</span><br><span class="line">    timeformat   check <span class="keyword">for</span> calls of (time.Time).Format or time.Parse with 2006-02-01</span><br><span class="line">    unmarshal    report passing non-pointer or non-interface values to unmarshal</span><br><span class="line">    unreachable  check <span class="keyword">for</span> unreachable code</span><br><span class="line">    unsafeptr    check <span class="keyword">for</span> invalid conversions of uintptr to unsafe.Pointer</span><br><span class="line">    unusedresult check <span class="keyword">for</span> unused results of calls to some <span class="built_in">functions</span></span><br><span class="line">(省略)</span><br></pre></td></tr></table></figure><p>vetは<a href="https://tip.golang.org/doc/go1.19#vet">Go1.19でerrorsas</a>が、<a href="https://tip.golang.org/doc/go1.20#vet">Go1.20でloopclosureとtimeformat</a>が追加されるなど、高品質にメンテナンスされているため安心して利用しているチームがほとんどだと思います。さすが標準ツールです。</p><p>Go1.20のvetについては<a href="https://tip.golang.org/doc/go1.20#vet">Go 1.20 vetのアップデート</a>の記事もあります。</p><p>ちなみに、<code>go test</code> を実行すると<a href="https://budougumi0617.github.io/2018/08/19/go-testing2018/#go110%E3%81%8B%E3%82%89%E4%BA%8B%E5%89%8D%E3%81%ABgo-vet%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89%E3%81%8C%E5%AE%9F%E8%A1%8C%E3%81%95%E3%82%8C%E3%81%A6%E3%81%84%E3%82%8B">Go 1.10から内部的にgo vetも動作するようになっている</a> そうです。注意として、go testでgo vetのすべてのチェックが動くのではなく、信頼性の高い以下9つののサブセットに限る点です。<code>go test</code> で <code>go vet</code> の30種類すべてを動かしたい場合は <code>go test -vet=all</code> とオプションつけましょう。</p><ol><li>atomic</li><li>bools</li><li>buildtags</li><li>directive</li><li>errorsas</li><li>ifaceassert</li><li>nilfunc</li><li>printf</li><li>stringintconv</li></ol><h2 id="go-vetを構成する要素"><a href="#go-vetを構成する要素" class="headerlink" title="go vetを構成する要素"></a>go vetを構成する要素</h2><p><code>go vet</code> の実装のうち、 <a href="https://github.com/golang/go/blob/master/src/cmd/vet/main.go#L48">mainパッケージのコード</a>から抜粋します。 <code>unitchecker.Main()</code> の引数が先程の <code>go tool vet help</code> 結果で出てきたチェック一覧と一致することがわかると思います。</p><figure class="highlight go"><figcaption><span>cmd/vet/main.goから抜粋</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">objabi.AddVersionFlag()</span><br><span class="line"></span><br><span class="line">unitchecker.Main(</span><br><span class="line">asmdecl.Analyzer,</span><br><span class="line">assign.Analyzer,</span><br><span class="line">atomic.Analyzer,</span><br><span class="line">bools.Analyzer,</span><br><span class="line">buildtag.Analyzer,</span><br><span class="line">cgocall.Analyzer,</span><br><span class="line">composite.Analyzer,</span><br><span class="line">copylock.Analyzer,</span><br><span class="line">directive.Analyzer,</span><br><span class="line">errorsas.Analyzer,</span><br><span class="line">framepointer.Analyzer,</span><br><span class="line">httpresponse.Analyzer,</span><br><span class="line">ifaceassert.Analyzer,</span><br><span class="line">loopclosure.Analyzer,</span><br><span class="line">lostcancel.Analyzer,</span><br><span class="line">nilfunc.Analyzer,</span><br><span class="line">printf.Analyzer,</span><br><span class="line">shift.Analyzer,</span><br><span class="line">sigchanyzer.Analyzer,</span><br><span class="line">slog.Analyzer,</span><br><span class="line">stdmethods.Analyzer,</span><br><span class="line">stringintconv.Analyzer,</span><br><span class="line">structtag.Analyzer,</span><br><span class="line">tests.Analyzer,</span><br><span class="line">testinggoroutine.Analyzer,</span><br><span class="line">timeformat.Analyzer,</span><br><span class="line">unmarshal.Analyzer,</span><br><span class="line">unreachable.Analyzer,</span><br><span class="line">unsafeptr.Analyzer,</span><br><span class="line">unusedresult.Analyzer,</span><br><span class="line">)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>では、引数の <code>asmdecl.Analyzer</code> ～ <code>unusedresult.Analyzer</code> たちが何かというと、import元のパッケージを見ると、 <a href="https://pkg.go.dev/golang.org/x/tools/go/analysis/passes">golang.org&#x2F;x&#x2F;tools&#x2F;go&#x2F;analysis&#x2F;passes</a> であることがわかります。 <code>passes</code> パッケージは <code>golang.org/x/tools/go/analysis</code> パッケージの静的解析のAPIを利用して作られている集合で、各パッケージごとに静的解析のチェックが実装されているというわけです。わかりやすい構成ですね。</p><h2 id="スタンドアロンドライバー"><a href="#スタンドアロンドライバー" class="headerlink" title="スタンドアロンドライバー"></a>スタンドアロンドライバー</h2><p>さて、<a href="https://pkg.go.dev/golang.org/x/tools/go/analysis/passes">golang.org&#x2F;x&#x2F;tools&#x2F;go&#x2F;analysis&#x2F;passes</a> のGoDocを見ると、 foo&#x2F;cmd&#x2F;foo といった形式で存在するドライバー（コマンド）が存在します。2023年9月5日公開 Version: v0.13.0だと、以下の5種類です。日本語訳はChatGPTさんにお願いしました。なぜかifaceassert、lostcancel、stringintconv、unmarshal、unusedresultはcmdパッケージがあるものの、go vetに含まれているため除外しています。</p><p>これらは先程紹介した<code>go tool vet help</code> にも <code>cmd/vet/main.go</code> にも含まれないため、<code>golang.org/x/tools/go/analysis/passes</code> パッケージに存在すれど <code>go vet</code> で行われないチェックツールです。この記事の趣旨はこいつらってどういう存在か抑えておこうというものです。これらの使い方は後述します。</p><div class="scroll"><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td><a href="https://pkg.go.dev/golang.org/x/tools@v0.13.0/go/analysis/passes/defers">defers</a></td><td>package defersは、defer文の一般的な間違いをチェックするAnalyzerを定義します。</td></tr><tr><td><a href="https://pkg.go.dev/golang.org/x/tools@v0.13.0/go/analysis/passes/fieldalignment">fieldalignment</a></td><td>package fieldalignmentは、フィールドがソートされている場合に、より少ないメモリを使用するstructを検出するAnalyzerを定義します。</td></tr><tr><td><a href="https://pkg.go.dev/golang.org/x/tools@v0.13.0/go/analysis/passes/fieldalignment">findcall</a></td><td>package findcallは、Analysis APIの単純な例とテストとして機能するAnalyzerを定義します。</td></tr><tr><td><a href="https://pkg.go.dev/golang.org/x/tools@v0.13.0/go/analysis/passes/nilness">nilness</a></td><td>package nilnessは、SSA関数の制御フローグラフを検査し、nilポインタの参照や退化したnilポインタの比較などのエラーを報告します。</td></tr><tr><td><a href="https://pkg.go.dev/golang.org/x/tools@v0.13.0/go/analysis/passes/shadow">shadow</a></td><td>package shadowは、シャドウされた変数をチェックするAnalyzerを定義します。</td></tr></tbody></table></div><p>使い方は5種類すべて同様に以下の流れで利用できます。</p><ol><li>各 xxx&#x2F;cmd&#x2F;xxx をインストールする</li><li><code>go vet</code> の <code>-vettool</code> オプションでインストールしたコマンドのパスを渡す<ul><li><code>-vettool</code> で渡す値は、絶対パスである必要があるので注意ください（後述で <code>command -v</code> やらを使っている理由がそれです）</li></ul></li></ol><p>まずは5つのツールをすべてインストールします。</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">go install golang.org/x/tools/go/analysis/passes/defers/cmd/defers@latest</span><br><span class="line">go install golang.org/x/tools/go/analysis/passes/fieldalignment/cmd/fieldalignment@latest</span><br><span class="line">go install golang.org/x/tools/go/analysis/passes/findcall/cmd/findcall@latest</span><br><span class="line">go install golang.org/x/tools/go/analysis/passes/nilness/cmd/nilness@latest</span><br><span class="line">go install golang.org/x/tools/go/analysis/passes/shadow/cmd/shadow@latest</span><br></pre></td></tr></table></figure><h2 id="defers"><a href="#defers" class="headerlink" title="defers"></a>defers</h2><p>defersはdefer構文でのよくある間違いを検知してくれるツールです。</p><p>検知するためのコードを準備します。このコードはdefersのGoDocに掲載されていた内容なので新規性は無いです。</p><figure class="highlight go"><figcaption><span>defersで検知するコード</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> example</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">&quot;time&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Defers</span><span class="params">()</span></span> &#123;</span><br><span class="line">start := time.Now()</span><br><span class="line"><span class="keyword">defer</span> recordLatency(time.Since(start)) <span class="comment">// error: call to time.Since is not deferred</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// any logic</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">recordLatency</span><span class="params">(d time.Duration)</span></span> &#123;</span><br><span class="line"><span class="comment">// any logging</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight sh"><figcaption><span>defersの実行</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="comment"># （Windowsでは $()の部分を %USERPROFILE%\go\bin\defer などに書き換えてください）</span></span><br><span class="line">$ go vet -vettool=$(<span class="built_in">command</span> -v defers) ./...</span><br><span class="line"><span class="comment"># example</span></span><br><span class="line">.\vetdefers.go:7:22: call to time.Since is not deferred</span><br></pre></td></tr></table></figure><p><code>-vettool</code> オプションで<code>defers</code> を渡すことで実行できました。最後の行に出ているのが検知したメッセージです。</p><p>検知した内容としては vetders.go のL7行目の deferで呼ばれる <code>recordLatency()</code> の引数、 <code>time.Since(start)</code> がdeferが呼ばれるタイミングではなく、即時評価されちゃっているということです。</p><p>おそらく以下が正しいのでは？という検知です。うっかりやっちゃいそうですね。</p><figure class="highlight go"><figcaption><span>おそらく正しいと思われる実装</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">defer</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123; recordLatency(time.Since(start)) &#125;()</span><br></pre></td></tr></table></figure><p>これが標準で入っていない理由ですが、ハッキリとしたIssueやレビューのやり取りを見つけられずでした。推測ですが、検知するのが time.Since のみなのでピンポイントすぎる内容であること、影響度も処理時間計測で用いられるものが大半だと思われるので、クリティカルで無いとみなされたのかなと思います。</p><h2 id="fieldalignment"><a href="#fieldalignment" class="headerlink" title="fieldalignment"></a>fieldalignment</h2><p>fieldalignmentはフィールドを並び替えた場合にメモリ消費量が抑えられるstructを検出してくれるツールです。</p><p>例えば以下のようなコードがあったとします（※GoDocから引っ張ってきているのでコード例にも新規性は無いです）。</p><figure class="highlight go"><figcaption><span>fieldalignment.go</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> example</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Good <span class="keyword">struct</span> &#123;</span><br><span class="line">y <span class="type">int32</span> <span class="comment">//4byte</span></span><br><span class="line">x <span class="type">byte</span>  <span class="comment">// 1byte</span></span><br><span class="line">z <span class="type">byte</span>  <span class="comment">// 1byte</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Bad <span class="keyword">struct</span> &#123;</span><br><span class="line">x <span class="type">byte</span>  <span class="comment">// 1byte</span></span><br><span class="line">y <span class="type">int32</span> <span class="comment">// 4byte</span></span><br><span class="line">z <span class="type">byte</span>  <span class="comment">// 1byte</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">go vet -vettool=$(<span class="built_in">command</span> -v fieldalignment) ./...</span><br><span class="line"><span class="comment"># example</span></span><br><span class="line">.\fieldalignment.go:9:10: struct of size 12 could be 8</span><br></pre></td></tr></table></figure><p>実行すると、9行目の Bad という structが検知されます。byte型は1byteです。メモリは4byteごとに確保され（64bit OSだと最大8byteまでは同じ領域に連続して格納できるため）、x,zを連続させると4byteで格納できます。int32(4byte) + byte型の2フィールド(4byte) &#x3D; 8byteにできるわけです。もし、int32を間に入れると(Bad structの場合）、4byte(x分) + 4byte（y分） + 4byte（z分）で12byteとなってしまい、無駄が生じているよというわけです。</p><p>一応、Playgroundも用意しました。気になる方は確認ください。</p><p><a href="https://go.dev/play/p/BMtHxH9B_cF">https://go.dev/play/p/BMtHxH9B_cF</a></p><p>これも <code>go vet</code> 標準に含めな議論を見つけられなかったですが、推測するとStructのフィールドを並び替えることで可読性などを落としメモリ省力化を追求することで利点が多いユースケースがメジャーではないこと（組み込みなど厳しいマッチしたケースは当然あると思います）があるのかなと思います。有用ですがデフォルトで有効にするものではないよねということです。</p><h2 id="findcall"><a href="#findcall" class="headerlink" title="findcall"></a>findcall</h2><p>findcallは特定の関数・メソッドが呼ばれているかチェックするツールです。 <code>-name</code> オプションで対象の関数・メソッドを指定します。</p><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> example</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="built_in">println</span>(<span class="string">&quot;hi&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;hi&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">println</span><span class="params">(s <span class="type">string</span>)</span></span> &#123;&#125;</span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">go vet -vettool=$(<span class="built_in">command</span> -v findcall) -name println ./...</span><br><span class="line"><span class="comment"># example</span></span><br><span class="line">.\findcall.go:4:9: call of println(...)</span><br></pre></td></tr></table></figure><p>これについてはユースケースがピンと来ず、CIで組み込むというよりは開発中に個別で気になった関数・メソッドの利用可否をチェックするといった使われ方でしょうか。検査対象の名称を引数で渡す必要があるため、現在の形式では <code>go vet</code> 標準で組み込まれることはない認識です。</p><p>静的解析の題材としてtennntenさんが取り上げているイメージがあるので、これを土台として有用なツールが作られており、その観点では重要な位置づけにあるツールに見えます。</p><p><a href="https://engineering.mercari.com/blog/entry/2018-12-16-150000/">https://engineering.mercari.com/blog/entry/2018-12-16-150000/</a></p><h2 id="nilness"><a href="#nilness" class="headerlink" title="nilness"></a>nilness</h2><p>nilness は nil ポインターの逆参照などを検知するツールです。例えばif分でnil検査をしているにもかかわらず、その変数にアクセスするとpanicが生じます。そういった実装を検知してくれます。</p><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> example</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> X <span class="keyword">struct</span>&#123; f, g <span class="type">int</span> &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">fnilness</span><span class="params">(x, y *X)</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> x == <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="built_in">print</span>(x.f) <span class="comment">// L7 ★検知</span></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="built_in">print</span>(x.f)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> x == <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">if</span> <span class="literal">nil</span> != y &#123;</span><br><span class="line"><span class="built_in">print</span>(<span class="number">1</span>)</span><br><span class="line"><span class="built_in">panic</span>(<span class="number">0</span>)</span><br><span class="line">&#125;</span><br><span class="line">x.f = <span class="number">1</span> <span class="comment">// L17 ★検知</span></span><br><span class="line">y.f = <span class="number">1</span> <span class="comment">// L18 ★検知</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">&gt;go vet -vettool=$(<span class="built_in">command</span> -v nilness) ./...</span><br><span class="line"><span class="comment"># example</span></span><br><span class="line">.\nilness.go:7:11: nil dereference <span class="keyword">in</span> field selection</span><br><span class="line">.\nilness.go:17:5: nil dereference <span class="keyword">in</span> field selection</span><br><span class="line">.\nilness.go:18:5: nil dereference <span class="keyword">in</span> field selection</span><br></pre></td></tr></table></figure><p>便利そうな気もしますね。なぜこれが <code>go vet</code> 標準でないのかは良く分かりませんでしたが、プロポーサルに理由が書いてありました。</p><ul><li><a href="https://github.com/golang/go/issues/59714">proposal: cmd&#x2F;vet: enable nilness checker by default #59714</a></li></ul><p>それによると、<code>go vet</code> は <code>go test</code> に最終的にはすべて含まれることを目指しており、 <code>nilness</code> はそのための（速度）基準をまだ満たしていないといったことが壁のようです。</p><h2 id="shadow"><a href="#shadow" class="headerlink" title="shadow"></a>shadow</h2><p>shadowはシャドウイングを検知してくれるツールです。シャドウイングについてはmattnさんの<a href="https://mattn.kaoriya.net/software/lang/go/20200227102218.htm">Go 言語で変数のシャドウイングを避けたいなら shadow を使おう。</a>記事を参考ください（まさにshadowの紹介もしていますね）。</p><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> example</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">&quot;fmt&quot;</span></span><br><span class="line"><span class="string">&quot;os&quot;</span></span><br><span class="line"><span class="string">&quot;testing&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">BadRead</span><span class="params">(f *os.File, buf []<span class="type">byte</span>)</span></span> <span class="type">error</span> &#123;</span><br><span class="line"><span class="keyword">var</span> err <span class="type">error</span> <span class="comment">// L10L</span></span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line">_, err := f.Read(buf) <span class="comment">// L12</span></span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">break</span> <span class="comment">// L14</span></span><br><span class="line">&#125;</span><br><span class="line">foo(buf)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">foo</span><span class="params">(buf []<span class="type">byte</span>)</span></span> &#123;&#125;</span><br></pre></td></tr></table></figure><p>これに対してshadowを実行します。</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">&gt;go vet -vettool=$(<span class="built_in">command</span> -v shadow) ./...</span><br><span class="line"><span class="comment"># example</span></span><br><span class="line">.\shadow.go:12:6: declaration of <span class="string">&quot;err&quot;</span> shadows declaration at line 10</span><br></pre></td></tr></table></figure><p>12行目の <code>, err := f.Read(buf)</code> で、 <code>:=</code> で代入しているため、L10行目で宣言した <code>err</code> とは同一名称で異なる変数が宣言されています。そのためL14でbreakしても戻り値のerrはnilのままです。いい感じに検知してくれていますね。</p><p>シャドウイング自体はGoの言語機能として本来問題ないはずなのでgo vet標準には組み込まれていないのだと思います。</p><h2 id="vettool-に複数プログラムを指定できない"><a href="#vettool-に複数プログラムを指定できない" class="headerlink" title="-vettool に複数プログラムを指定できない"></a>-vettool に複数プログラムを指定できない</h2><p>なんとなく、以下のように一括でチェックができるイメージがありましたが、以下のような指定はできません。</p><figure class="highlight sh"><figcaption><span>NGケース（複数の-vettoolオプションは渡せない）</span></figcaption><table><tr><td class="code"><pre><span class="line">go vet -vettool=$(<span class="built_in">command</span> -v defers) \</span><br><span class="line">  -vettool=$(<span class="built_in">command</span> -v fieldalignment)  \</span><br><span class="line">  -vettool=$(<span class="built_in">command</span> -v nilness) \</span><br><span class="line">  -vettool=$(<span class="built_in">command</span> -v shadow) ./...</span><br></pre></td></tr></table></figure><p>そのため、go vetを複数回起動することになると思います。<code>go vet</code> 標準と、スタンドアロンドライバー4種類を実行する場合は以下のようにコマンドを並べることになると思います。</p><figure class="highlight sh"><figcaption><span>OKケース</span></figcaption><table><tr><td class="code"><pre><span class="line">go vet ./...</span><br><span class="line">go vet -vettool=$(<span class="built_in">command</span> -v defers) ./...</span><br><span class="line">go vet -vettool=$(<span class="built_in">command</span> -v fieldalignment) ./...</span><br><span class="line">go vet -vettool=$(<span class="built_in">command</span> -v nilness) ./...</span><br><span class="line">go vet -vettool=$(<span class="built_in">command</span> -v shadow) ./...</span><br></pre></td></tr></table></figure><p>また、 <code>-vettool</code> を指定すると、go vet組み込み＋vettoolのチェックを行うと私は勘違いしてしまいましたが、あくまで<code>vettool</code>のチェックのみ行われることに注意ください。 </p><h2 id="まとめ"><a href="#まとめ" class="headerlink" title="まとめ"></a>まとめ</h2><p>go vet に近い静的解析ツールを5種類紹介しました。それらが解決する課題がチームにマッチする場合は、有効にして取り入れてると良いかなと思いました。また、類似の課題の場合はそれらのコードを参考に、自分たちで解析ツールを作るといったことにも役立つと思います。</p><p>アイキャッチは<a href="https://unsplash.com/ja/%E5%86%99%E7%9C%9F/g3PsF4_y7ZY?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Unsplash</a>の<a href="https://unsplash.com/ja/@etactics?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Etactics Inc</a>が撮影した写真です。 </p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;img src=&quot;/images/20231005a/etactics-inc-g3PsF4_y7ZY-unsplash.jpg&quot; alt=&quot;&quot; width=&quot;800&quot; height=&quot;533&quot;&gt;

&lt;h2 id=&quot;はじめに&quot;&gt;&lt;a href=&quot;#はじめに&quot;</summary>
        
      
    
    
    
    <category term="Programming" scheme="https://future-architect.github.io/categories/Programming/"/>
    
    
    <category term="Go" scheme="https://future-architect.github.io/tags/Go/"/>
    
    <category term="Linter" scheme="https://future-architect.github.io/tags/Linter/"/>
    
    <category term="静的解析" scheme="https://future-architect.github.io/tags/%E9%9D%99%E7%9A%84%E8%A7%A3%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>アクセシビリティに考慮した出力値のHTMLマークアップ</title>
    <link href="https://future-architect.github.io/articles/20231003a/"/>
    <id>https://future-architect.github.io/articles/20231003a/</id>
    <published>2023-10-02T15:00:00.000Z</published>
    <updated>2023-10-04T08:28:28.771Z</updated>
    
    <content type="html"><![CDATA[<p><strong>10&#x2F;4追記:</strong> 本記事の中で不具合のような動作があると書いていたのですが、<a href="https://github.com/microsoft/playwright/issues/27403">issueで報告したところ</a>、すぐに修正されました。次のバージョン1.39で修正版がリリースされるようです。</p><p>以前書いたCypressの記事で、アクセシビリティ情報を使うことで壊れにくくなるよ、と（今では当たり前のようにみんな言っていますが）いう記事を書きました。</p><ul><li><a href="/articles/20210226/">アクセシビリティ情報を使った壊れにくいE2Eテスト</a></li></ul><p>この時は出力に使うべきロールが何か？というのがわかっていませんでした。</p><blockquote><p>サーバーからとってきた動的な値を表示するテキストって、DOM上は単なるテキストなのでロールを持っていないのですよね。テスト上はここにロールがあって要素取得できるととても助かる。</p><p>次のどちらかな、と思っているのですが、どちらの方がスクリーンリーダーユーザーにとって自然なロール指定のかはちょっとわかってません。とりあえず前者にしています。</p></blockquote><p>先日、「実際使えるロールとか、それに適したタグって全部でどのぐらいあるんだろうか？」というのが気になってPlaywrightのソースコードを眺めていたところ、それが定義されているファイルが<a href="https://github.com/microsoft/playwright/blob/ac9d1ec421b572d6ac23f1dd169f292a1108e102/packages/playwright-core/src/server/injected/roleUtils.ts">playwright-core&#x2F;src&#x2F;server&#x2F;injected&#x2F;roleUtils.ts</a>であることがわかり、その中で <code>&lt;output&gt;</code> タグがあるというのを知りました。<code>&lt;output&gt;</code>タグにはデフォルトで<code>status</code>というaria-roleがついていることがわかります。</p><p>多くのブラウザが <code>aria-live</code> の領域としてこのタグを扱ってくれるため、何かしらのロジックが走って結果が変わった時のとかにうまく変更をユーザーに知らせてくれるらしいです。ReactとかVueで計算した結果を出す先をマークアップするには良さそうですね。</p><h1 id="lt-output-gt-タグを使ってみる"><a href="#lt-output-gt-タグを使ってみる" class="headerlink" title="&lt;output&gt;タグを使ってみる"></a><code>&lt;output&gt;</code>タグを使ってみる</h1><p><a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/output">MDNの説明</a>を読むと、<code>&lt;output&gt;</code>タグは<code>for</code>属性を使って、フォーム要素っぽく、HTMLとして<code>&lt;label&gt;</code>と関連付けられることがわかりました。これを使うのがHTMLのセマンティクス的に良さそうですね。</p><p>viteでReactの雛形を作って、サンプルアプリを作ってみました。2つの数値のフォームがあり、それに数値を入れると合計値、積算した結果を表示します。</p><figure class="highlight tsx"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> &#123; useCallback, useState, <span class="title class_">ChangeEvent</span> &#125; <span class="keyword">from</span> <span class="string">&#x27;react&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">App</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="keyword">const</span> [value1, setValue1] = <span class="title function_">useState</span>(<span class="number">0</span>)</span><br><span class="line">  <span class="keyword">const</span> [value2, setValue2] = <span class="title function_">useState</span>(<span class="number">0</span>)</span><br><span class="line">  <span class="keyword">const</span> updateValue1 = <span class="title function_">useCallback</span>(<span class="function">(<span class="params">e: ChangeEvent&lt;HTMLInputElement&gt;</span>) =&gt;</span> &#123;</span><br><span class="line">    <span class="title function_">setValue1</span>(<span class="title class_">Number</span>(e.<span class="property">target</span>.<span class="property">value</span>));</span><br><span class="line">  &#125;, [setValue1])</span><br><span class="line">  <span class="keyword">const</span> updateValue2 = <span class="title function_">useCallback</span>(<span class="function">(<span class="params">e: ChangeEvent&lt;HTMLInputElement&gt;</span>) =&gt;</span> &#123;</span><br><span class="line">    <span class="title function_">setValue2</span>(<span class="title class_">Number</span>(e.<span class="property">target</span>.<span class="property">value</span>));</span><br><span class="line">  &#125;, [setValue2])</span><br><span class="line">  <span class="keyword">return</span> (</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&quot;grid grid-cols-2 gap-4&quot;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">label</span> <span class="attr">htmlFor</span>=<span class="string">&quot;value1&quot;</span>&gt;</span>Value1<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;number&quot;</span> <span class="attr">id</span>=<span class="string">&quot;value1&quot;</span> <span class="attr">onChange</span>=<span class="string">&#123;updateValue1&#125;/</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">label</span> <span class="attr">htmlFor</span>=<span class="string">&quot;value2&quot;</span>&gt;</span>Value2<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;number&quot;</span> <span class="attr">id</span>=<span class="string">&quot;value2&quot;</span> <span class="attr">onChange</span>=<span class="string">&#123;updateValue2&#125;/</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">label</span> <span class="attr">htmlFor</span>=<span class="string">&quot;sum&quot;</span>&gt;</span>Sum<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">output</span> <span class="attr">id</span>=<span class="string">&quot;sum&quot;</span>&gt;</span>&#123;value1 + value2&#125;<span class="tag">&lt;/<span class="name">output</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">label</span> <span class="attr">htmlFor</span>=<span class="string">&quot;mul&quot;</span>&gt;</span>Mul<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">output</span> <span class="attr">id</span>=<span class="string">&quot;mul&quot;</span>&gt;</span>&#123;value1 * value2&#125;<span class="tag">&lt;/<span class="name">output</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line">  )</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="title class_">App</span></span><br></pre></td></tr></table></figure><p>Playwrightで書いてみたテストは次の通りです。<code>&lt;output&gt;</code>タグについたラベルを使って取得できています。</p><figure class="highlight ts"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> &#123; test, expect &#125; <span class="keyword">from</span> <span class="string">&#x27;@playwright/test&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="title function_">test</span>(<span class="string">&#x27;calc&#x27;</span>, <span class="keyword">async</span> (&#123; page &#125;) =&gt; &#123;</span><br><span class="line">  <span class="keyword">await</span> page.<span class="title function_">goto</span>(<span class="string">&#x27;http://localhost:5173&#x27;</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">await</span> page.<span class="title function_">getByLabel</span>(<span class="string">&quot;Value1&quot;</span>).<span class="title function_">fill</span>(<span class="string">&quot;10&quot;</span>)</span><br><span class="line">  <span class="keyword">await</span> page.<span class="title function_">getByLabel</span>(<span class="string">&quot;Value2&quot;</span>).<span class="title function_">fill</span>(<span class="string">&quot;20&quot;</span>)</span><br><span class="line">  <span class="title function_">expect</span>(<span class="keyword">await</span> page.<span class="title function_">getByLabel</span>(<span class="string">&quot;Sum&quot;</span>)).<span class="title function_">toHaveText</span>(<span class="string">&quot;30&quot;</span>)</span><br><span class="line">  <span class="title function_">expect</span>(<span class="keyword">await</span> page.<span class="title function_">getByLabel</span>(<span class="string">&quot;Mul&quot;</span>)).<span class="title function_">toHaveText</span>(<span class="string">&quot;200&quot;</span>)</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><img src="/images/20231003a/スクリーンショット_2023-10-01_17.37.45.png" alt="test('calc', async ({ page }) => { にハイライトがあたったPlaywright画面" width="1200" height="535" loading="lazy"><h1 id="getByRole-‘status’-は現状使えなそう→1-39から使えます！"><a href="#getByRole-‘status’-は現状使えなそう→1-39から使えます！" class="headerlink" title="# getByRole(‘status’)は現状使えなそう→1.39から使えます！"></a># getByRole(‘status’)は現状使えなそう→1.39から使えます！</h1><p><del>ラベルの選択ができたし、<code>getByRole()</code>ではどうかな、と試してみましたがうまくいきません。これは見つけられませんでした。</del></p><figure class="highlight ts"><table><tr><td class="code"><pre><span class="line"><span class="title function_">expect</span>(<span class="keyword">await</span> page.<span class="title function_">getByRole</span>(<span class="string">&#x27;status&#x27;</span>, &#123; <span class="attr">name</span>: <span class="string">&#x27;Sum&#x27;</span> &#125;)).<span class="title function_">toBeVisible</span>()</span><br></pre></td></tr></table></figure><p><del>名前とロールは違うものだし、仕方ない気もしないでもないけど<code>&lt;input&gt;</code>タグの中にはラベルをnameで指定するのが普通の要素もあります。</del></p><figure class="highlight tsx"><table><tr><td class="code"><pre><span class="line">&#123;<span class="comment">/* ボタンのテキスト */</span>&#125;</span><br><span class="line">&lt;button&gt;<span class="title class_">Button</span> <span class="title class_">Sample</span>&lt;/button&gt;</span><br><span class="line"></span><br><span class="line">&#123;<span class="comment">/* labelで指定(checkbox) */</span>&#125;</span><br><span class="line">&lt;label&gt;</span><br><span class="line">  <span class="language-xml"><span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;checkbox&quot;</span> /&gt;</span></span> <span class="title class_">Subscribe</span></span><br><span class="line">&lt;/label&gt;</span><br><span class="line"></span><br><span class="line">&#123;<span class="comment">/* 同様の記法でlabelを付与したoutput */</span>&#125;</span><br><span class="line">&lt;label&gt;</span><br><span class="line">  <span class="title class_">Output</span> &lt;output&gt;test&lt;/output&gt;</span><br><span class="line">&lt;/label&gt;</span><br></pre></td></tr></table></figure><p>Playwrightで実験してみると次のようになりました。</p><figure class="highlight ts"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 成功</span></span><br><span class="line"><span class="title function_">expect</span>(<span class="keyword">await</span> page.<span class="title function_">getByRole</span>(<span class="string">&#x27;button&#x27;</span>, &#123;　<span class="attr">name</span>: <span class="string">&quot;Button Sample&quot;</span>　&#125;)).<span class="title function_">toBeVisible</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 成功</span></span><br><span class="line"><span class="title function_">expect</span>(<span class="keyword">await</span> page.<span class="title function_">getByRole</span>(<span class="string">&#x27;checkbox&#x27;</span>, &#123;　<span class="attr">name</span>: <span class="string">&#x27;Subscribe&#x27;</span> &#125;)).<span class="title function_">toBeVisible</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 失敗(1.38)</span></span><br><span class="line"><span class="title function_">expect</span>(<span class="keyword">await</span> page.<span class="title function_">getByRole</span>(<span class="string">&#x27;status&#x27;</span>, &#123; <span class="attr">name</span>: <span class="string">&#x27;Output&#x27;</span> &#125;)).<span class="title function_">toBeVisible</span>()</span><br></pre></td></tr></table></figure><p><del><code>&lt;output&gt;</code>はフォーム属性ではないせいか、ラベルをroleのnameとしては認識しないようです。checkboxはいけるんですけどね。</del></p><p><del>ARIA周りの仕様とかを完全に理解したわけではないので、これはissue報告すべきなのかどうなのか悩むところではありますが、現状 <code>getByLabel()</code>で情報が取れることはわかったので、一旦これでよしとしようかと思います。</del></p><p>→報告したところ修正されました。1.39で治るようです。</p><h1 id="まとめ"><a href="#まとめ" class="headerlink" title="まとめ"></a>まとめ</h1><p>数年前に発表した資料でもわからん、と書いていた、喉に使えた骨だった悩みが解決しました。一方でPlaywrightの挙動があるべきものなのか悩ましいのですが、今後は積極的に使ってみようと思います。</p><p>自分がスクリーンリーダー等を使っていなかったりもあって、アクセシビリティに関しては自信をもって「これだ！」とまではまだ言えないので、識者のフィードバックがあるといいな、と思いつつ技術ブログにしています。</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;&lt;strong&gt;10&amp;#x2F;4追記:&lt;/strong&gt; 本記事の中で不具合のような動作があると書いていたのですが、&lt;a</summary>
        
      
    
    
    
    <category term="Programming" scheme="https://future-architect.github.io/categories/Programming/"/>
    
    
    <category term="HTML" scheme="https://future-architect.github.io/tags/HTML/"/>
    
    <category term="accessibility" scheme="https://future-architect.github.io/tags/accessibility/"/>
    
    <category term="Playwright" scheme="https://future-architect.github.io/tags/Playwright/"/>
    
    <category term="E2E" scheme="https://future-architect.github.io/tags/E2E/"/>
    
  </entry>
  
  <entry>
    <title>ローカルでGoのHTTP/3サーバーを立てて接続テストを行う</title>
    <link href="https://future-architect.github.io/articles/20230927a/"/>
    <id>https://future-architect.github.io/articles/20230927a/</id>
    <published>2023-09-26T15:00:00.000Z</published>
    <updated>2023-10-02T00:07:27.513Z</updated>
    
    <content type="html"><![CDATA[<p>Go 1.21ではcrypto&#x2F;tlsパッケージでQUIC関連の更新が少しありましたが、QUICそのものは入りませんでした。QUICとかHTTP&#x2F;3周りをどうするかは<a href="https://github.com/golang/go/issues/58547">いろいろ議論があり</a>、次のことが決定しています。</p><ul><li>最終的にはnet&#x2F;quicが作られる</li><li>ただし、APIの安定化のために、まずは準標準パッケージとして golang.org&#x2F;x&#x2F;net&#x2F;quicを作っていく</li><li>github.com&#x2F;quic-go&#x2F;quic-goという実装はあるが、それをそのまま取り込むことはしない</li></ul><p>ということで、もう少ししばらくかかりそうです。</p><p>といっても、HTTP&#x2F;3のリクエストをエンドのアプリケーションサーバーが直接受けることはおそらく稀で、CDNとか、最前面にたつエンドポイントがHTTP&#x2F;2やHTTP&#x2F;3をしゃべって、その裏はHTTP&#x2F;1.1(非TLS)が多いと思いますし、より固くしようとしてもmTLSでHTTP&#x2F;2じゃないですかね。もともとHTTP&#x2F;3の強みはエラー率の高い回線でも速度が落ちにくいことなので、回線品質の安定したデータセンターとかクラウド内部はHTTP&#x2F;3にしてもうまみがあまりないといえるので、そんな悲観的になることもないかな、と思います。</p><p>とはいえ、HTTP&#x2F;3に触ってみたい方もいるかと思うので試してみました。</p><p>上記の議論の中でも出てきた github.com&#x2F;quic-go&#x2F;quic-go　は、このパッケージの作者のMarten SeemannはIETFのQUICワーキンググループの初期からのメンバーでもあり、このパッケージ自身もIETFの他のQUICエージェントとの相互接続テストを行っており、品質はばっちりだと思われます。なのでこれを試してみます。</p><h1 id="quic-goでのHTTPサーバー"><a href="#quic-goでのHTTPサーバー" class="headerlink" title="quic-goでのHTTPサーバー"></a>quic-goでのHTTPサーバー</h1><p>Goの標準ライブラリのサーバー実装と似たようなAPIでサーバーをたてられます。ハンドラ周りはnet&#x2F;httpの<code>http.Handler</code>インタフェースそのものなので、いろんなフレームワークをそのまま上で動かせます。</p><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">   <span class="string">&quot;fmt&quot;</span></span><br><span class="line">   <span class="string">&quot;log&quot;</span></span><br><span class="line">   <span class="string">&quot;net/http&quot;</span></span><br><span class="line"></span><br><span class="line">   <span class="string">&quot;github.com/quic-go/quic-go/http3&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">   mux := http.NewServeMux()</span><br><span class="line">   mux.HandleFunc(<span class="string">&quot;/&quot;</span>, <span class="function"><span class="keyword">func</span><span class="params">(w http.ResponseWriter, r *http.Request)</span></span> &#123;</span><br><span class="line">       fmt.Fprintf(w, <span class="string">&quot;Hello, %s&quot;</span>, r.Proto)</span><br><span class="line">   &#125;)</span><br><span class="line"></span><br><span class="line">   log.Println(<span class="string">&quot;start at https://localhost:8443&quot;</span>)</span><br><span class="line">   log.Println(http3.ListenAndServe(<span class="string">&quot;0.0.0.0:8443&quot;</span>, <span class="string">&quot;localhost.pem&quot;</span>, <span class="string">&quot;localhost-key.pem&quot;</span>, mux))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Goを書いたことがある人にはおなじみですね？HTTP&#x2F;2と同じく、TLS必須なので証明書を作成する必要があります。こちらは参考情報がいろいろあるので、お好きな文献などを参考に作ってみてください。Real World HTTPでも紹介しています。</p><p><code>localhost</code>のホスト名で証明書を作ったので、<code>localhost:8443</code>でアクセスするとバッチリ表示されます。Safariでアクセスしてみると、すぐに表示されて案外簡単？と思いつつ、ここから深くなってきます。</p><img src="/images/20230927a/スクリーンショット_2023-09-21_15.03.06.png" alt="スクリーンショット_2023-09-21_15.03.06.png" width="806" height="336" loading="lazy"><h1 id="quic-goの内部ではサーバーが2つ起動する"><a href="#quic-goの内部ではサーバーが2つ起動する" class="headerlink" title="quic-goの内部ではサーバーが2つ起動する"></a>quic-goの内部ではサーバーが2つ起動する</h1><p>http3パッケージには<code>ListenAndServeQUIC()</code>という関数もあります。どう違うのでしょうか？最初はこちらで実装してみたのですが動かず、上記の<code>ListenAndServe()</code>にしたら動きました。</p><p>こちらの方は内部的には、こんな感じのコードと同じような動きになります。よくよくみると、HTTP&#x2F;2のサーバーも起動していますね。<code>Alt-Svc</code>フィールドを付与しています。</p><p>QUICはUDPですが、現在のブラウザはまずTCPでサーバーアクセスしに行きます。しかし、HTTP&#x2F;3のみのサーバーがたっていても、そこにはTCPのサーバーはいません。そのため、HTTP&#x2F;2のサーバーを裏でたてて、そのレスポンスの <code>Alt-Svc</code>フィールドを返し「こちらでHTTP&#x2F;3のサーバーがいるよ」とブラウザをHTTP&#x2F;3の方に誘導しているというわけです。</p><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">   <span class="string">&quot;context&quot;</span></span><br><span class="line">   <span class="string">&quot;fmt&quot;</span></span><br><span class="line">   <span class="string">&quot;log&quot;</span></span><br><span class="line">   <span class="string">&quot;net/http&quot;</span></span><br><span class="line">   <span class="string">&quot;os&quot;</span></span><br><span class="line">   <span class="string">&quot;os/signal&quot;</span></span><br><span class="line">   <span class="string">&quot;sync&quot;</span></span><br><span class="line"></span><br><span class="line">   <span class="string">&quot;github.com/quic-go/quic-go/http3&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">   mux := http.NewServeMux()</span><br><span class="line">   mux.HandleFunc(<span class="string">&quot;/&quot;</span>, <span class="function"><span class="keyword">func</span><span class="params">(w http.ResponseWriter, r *http.Request)</span></span> &#123;</span><br><span class="line">       w.Header().Add(<span class="string">&quot;Alt-Svc&quot;</span>, <span class="string">`h3=&quot;:8443&quot;; ma=2592000`</span>)</span><br><span class="line">       fmt.Fprintf(w, <span class="string">&quot;Hello via %s&quot;</span>, r.Proto)</span><br><span class="line">   &#125;)</span><br><span class="line"></span><br><span class="line">   ctx, <span class="built_in">close</span> := signal.NotifyContext(context.Background(), os.Interrupt)</span><br><span class="line">   <span class="keyword">defer</span> <span class="built_in">close</span>()</span><br><span class="line"></span><br><span class="line">   h2server := &amp;http.Server&#123;</span><br><span class="line">       Addr:    <span class="string">&quot;0.0.0.0:8443&quot;</span>,</span><br><span class="line">       Handler: mux,</span><br><span class="line">   &#125;</span><br><span class="line">   h3server := &amp;http3.Server&#123;</span><br><span class="line">       Addr:    <span class="string">&quot;0.0.0.0:8443&quot;</span>,</span><br><span class="line">      Handler: mux,</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   wg := &amp;sync.WaitGroup&#123;&#125;</span><br><span class="line">   wg.Add(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">   <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">       log.Println(<span class="string">&quot;start at http/2 server at (TCP)https://localhost:8443&quot;</span>)</span><br><span class="line">       log.Println(h2server.ListenAndServeTLS(<span class="string">&quot;localhost.pem&quot;</span>, <span class="string">&quot;localhost-key.pem&quot;</span>))</span><br><span class="line">       wg.Done()</span><br><span class="line">   &#125;()</span><br><span class="line"></span><br><span class="line">   <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">       log.Println(<span class="string">&quot;start at http/3 server at (UDP)https://localhost:8443&quot;</span>)</span><br><span class="line">       log.Println(h3server.ListenAndServeTLS(<span class="string">&quot;localhost.pem&quot;</span>, <span class="string">&quot;localhost-key.pem&quot;</span>))</span><br><span class="line">       wg.Done()</span><br><span class="line">   &#125;()</span><br><span class="line"></span><br><span class="line">   &lt;-ctx.Done()</span><br><span class="line">   h2server.Shutdown(ctx)</span><br><span class="line">   h3server.Close()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="プロトコル選択"><a href="#プロトコル選択" class="headerlink" title="プロトコル選択"></a>プロトコル選択</h1><p>HTTP&#x2F;3ではいくつかの箇所でプロトコル選択をさせるようになっています。</p><ul><li>DNSのHTTPSレコード</li><li>TLSのハンドシェイクのALPN(Application-Layer Protocol Negotiation)</li><li>上記で紹介したAlt-Svcフィールド</li></ul><p>上から順番に実行されます。DNSであれば、最初のサーバーアクセスの前に情報を得ることができます。TLSのハンドシェイクはTCP&#x2F;UDPを決めた後に行えるため、最初のTCPのアクセスの空撃ちは必要です。Alt-Svcフィールドのタイミングはさらに遅く、一度HTTP&#x2F;2のサーバーがリクエストを処理するまで、ブラウザはHTTP&#x2F;3のサーバーの存在を知ることはできません。</p><p>個人的には103 Early HintsでAlt-Svcフィールドを返せば僅かばかりAlt-Svcをレスポンスで返すよりも効率的かな、と思いましたが、103 Early Hintsはサンプル見てもプリロードの用途しか見ませんね。</p><h1 id="CoreDNSをたててみた"><a href="#CoreDNSをたててみた" class="headerlink" title="CoreDNSをたててみた"></a>CoreDNSをたててみた</h1><p>さて、上記のHTTP&#x2F;3サーバーですが、Safariからはばっちり3の方につながるのですが、ChromeとFirefoxは2ばかり。たまに開発者ツールを開いてリロードしたタイミングだけ3でつながったりといまいち安定しません。そんな中、Twitter(X)で、まえかわさんという方から、HTTPSレコードでばっちりいけるというお話を伺い、ちょっと試してみることにしました。</p><blockquote class="twitter-tweet"><p lang="ja" dir="ltr">allt-svcに加えてHTTPSレコードをつけたらchromeは確実に3でfirefoxは半々ぐらいの確率になりますね<br>自分も壊れてるのかと思いました</p>&mdash; まえかわ (@kiwithe2027) <a href="https://twitter.com/kiwithe2027/status/1703264967510954453?ref_src=twsrc%5Etfw">September 17, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script><p>ちなみに、現在出ている<a href="https://gihyo.jp/magazine/SD/archive/2023/202310">Software Design 2023年10月号</a>がたまたまHTTP&#x2F;3特集でしたが、HTTPSレコードはCDN上の設定で付与していました。</p><p>今回あつかった<a href="https://coredns.io/">CoreDNS</a>は、CNCFの傘下にいるプロジェクトで、Kubernetesでもよく使われています。もっとも、その理由がetcdでエントリーの管理ができて、そちらの情報を元に情報を返せるため管理が楽、というところがあるのだと思いますが、今回はetcdは使いません。</p><p><a href="https://brendanthompson.com/posts/2021/12/coredns-on-macos-for-local-development">こちら</a>をみながらmacOSでやってみた例になりますが、サービスの起動部分以外はポータブルなはずです。<a href="https://hnakamur.github.io/blog/2019/10/30/coredns-wrapper-for-runnning-as-windows-service/">hnakamurさんがWindowsでサービス化するラッパー</a>を作られているのでこちらに変えればWindowsでも動くかと思います。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># インストール</span></span><br><span class="line">$ brew install coredns</span><br><span class="line"></span><br><span class="line"><span class="comment"># 起動</span></span><br><span class="line">$ sudo brew services start coredns</span><br></pre></td></tr></table></figure><p><code>http3.test</code>というホスト名だけ特別扱いしてHTTPSレコードをつけてあげたいので、<code>/opt/homebrew/etc/coredns/Corefile</code>ファイルを次のようにしました</p><figure class="highlight sh"><figcaption><span>/opt/homebrew/etc/coredns/Corefile</span></figcaption><table><tr><td class="code"><pre><span class="line">. &#123;</span><br><span class="line">    forward . 8.8.8.8</span><br><span class="line">    <span class="built_in">log</span></span><br><span class="line">    errors</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">http3.test &#123;</span><br><span class="line">  file /Users/shibu/.config/coredns/test</span><br><span class="line">  <span class="built_in">log</span></span><br><span class="line">  errors</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上記の設定からインポートされる自分のホーム以下に追加の設定ファイル(&#x2F;Users&#x2F;shibu&#x2F;.config&#x2F;coredns&#x2F;test)をおきます。こんな感じにしてみました。</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="variable">$ORIGIN</span> <span class="built_in">test</span>.</span><br><span class="line"><span class="variable">$TTL</span> 1m</span><br><span class="line"></span><br><span class="line">@                 IN  SOA     ns.test. admin.test. (</span><br><span class="line">                                   2020010510     ; Serial</span><br><span class="line">                                   1m             ; Refresh</span><br><span class="line">                                   2m             ; Retry</span><br><span class="line">                                   4m             ; Expire</span><br><span class="line">                                   1m)            ; Minimum TTL</span><br><span class="line">@                 IN  A       127.0.0.1</span><br><span class="line">@                 IN  NS      <span class="built_in">test</span>.</span><br><span class="line">ns                IN  CNAME   @</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">http3   IN A     127.0.0.1</span><br><span class="line">        IN AAAA  ::1</span><br><span class="line">        INHTTPS 1 . alpn=h3 port=8443</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 再起動</span></span><br><span class="line">$ sudo brew services restart coredns</span><br></pre></td></tr></table></figure><p>最後にネットワーク設定でDNSに127.0.0.1を追加してあげれば完了です。</p><p>これでSafariでアクセスしてみると、無事に <code>https://http3.test</code>というURLでアクセスできました。HTTPSレコードはプロトコル以外にもポートを設定できるのでポート番号を省略できるようになります。いいですね。</p><img src="/images/20230927a/スクリーンショット_2023-09-21_15.02.30.png" alt="" width="699" height="336" loading="lazy"><p>しかし、実はChromeとFirefox、EdgeはこのDNSサーバーを見に行ってくれませんでした。昔はDNS設定があったと思いますが、いまはDNS over HTTPSのみです。ChromeでHTTP&#x2F;3に繋ぎたくてCoreDNSを入れてみたのですが、ここはうまく行っていません。DNS over HTTPSをCoreDNSで建ててみてもそこにアクセスしてくれなかったり、設定を拒否されたり。ここはぼちぼちやっていこうと思います。dnsmasqを入れた時はアクセスはしてくれたものの、HTTPSレコードの追加が分からずCoreDNSでやりましたが、別の方法も試そうかと。</p><h1 id="まとめ"><a href="#まとめ" class="headerlink" title="まとめ"></a>まとめ</h1><p>というわけで、HTTP&#x2F;3のサーバーを起動してブラウザでアクセスしてみました。Safariからはうまくつながりました。しかし、実際に試す時間の90%はDNS周りを操作する時間だったりして、ちょっと敷居が高い気がしました。</p><p>将来的にはもう開発体験がちょっと改善されたらいいな、と思いました。</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;Go 1.21ではcrypto&amp;#x2F;tlsパッケージでQUIC関連の更新が少しありましたが、QUICそのものは入りませんでした。QUICとかHTTP&amp;#x2F;3周りをどうするかは&lt;a</summary>
        
      
    
    
    
    <category term="Infrastructure" scheme="https://future-architect.github.io/categories/Infrastructure/"/>
    
    
    <category term="Go" scheme="https://future-architect.github.io/tags/Go/"/>
    
    <category term="Go1.21" scheme="https://future-architect.github.io/tags/Go1-21/"/>
    
    <category term="HTTP3" scheme="https://future-architect.github.io/tags/HTTP3/"/>
    
    <category term="QUIC" scheme="https://future-architect.github.io/tags/QUIC/"/>
    
    <category term="CoreDNS" scheme="https://future-architect.github.io/tags/CoreDNS/"/>
    
  </entry>
  
  <entry>
    <title>stree：S3バケットをtreeするCLIコマンド</title>
    <link href="https://future-architect.github.io/articles/20230926a/"/>
    <id>https://future-architect.github.io/articles/20230926a/</id>
    <published>2023-09-25T15:00:00.000Z</published>
    <updated>2023-10-02T00:07:27.513Z</updated>
    
    <content type="html"><![CDATA[<img src="/images/20230926a/stree-display.png" alt="" width="1200" height="600" loading="lazy"><h1 id="はじめに"><a href="#はじめに" class="headerlink" title="はじめに"></a>はじめに</h1><p>こんにちは。TIG&#x2F;EXユニット所属の宮永です。</p><p>本記事ではS3バケットをtreeするCLIコマンドを紹介します。</p><p>クラスメソッドさんの記事(<a href="https://dev.classmethod.jp/articles/s3-tree-aws-s3-ls/">S3 バケットの中身を tree 形式で表示してくれる s3-tree を Amazon Linux 2 にインストールして使ってみた</a>)を拝見して、<a href="https://pypi.org/project/s3-tree/">s3-tree</a>というツールの存在を知ったのですが、profileを指定できなかったり、バケット単位でしか指定できなかったりと細かな部分で不自由さを感じたためGoでCLIツールを作成しました。</p><p>作成したツールは以下リンク先で公開しています。</p><p><a href="https://github.com/orangekame3/stree"><img src="https://gh-card.dev/repos/orangekame3/stree.svg" alt="orangekame3/stree - GitHub"></a></p><blockquote><p>streeは「エスツリー」と読みます。先に語感の良い名称を思いついたため、衝動に身を任せて開発しました。</p></blockquote><h1 id="機能概要"><a href="#機能概要" class="headerlink" title="機能概要"></a>機能概要</h1><p>まずは利用画面を見ていただいたほうがイメージ付きやすいかと思いますのでgif画像を添付します。</p><img src="/images/20230926a/demo.gif" alt="demo" width="1200" height="686" loading="lazy"><p>streeは以下の機能をサポートしています。</p><ul><li>バケット名、プレフィックス名指定によるtree表示</li><li>プロファイル、リージョンの指定</li><li>LocalStack上のS3バケットのtree表示</li><li>カラー表示（オプションで無効化も可能です）</li></ul><h1 id="インストール方法"><a href="#インストール方法" class="headerlink" title="インストール方法"></a>インストール方法</h1><p>GoとHomebrew経由でインストール可能です。</p><p>各種ビルド済みのバイナリも公開しているので<a href="https://github.com/orangekame3/stree/releases">Release</a>から手動インストールもできます。</p><h2 id="Goによるインストール"><a href="#Goによるインストール" class="headerlink" title="Goによるインストール"></a>Goによるインストール</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">go install github.com/orangekame3/stree@latest</span><br></pre></td></tr></table></figure><h2 id="Homebrewによるインストール"><a href="#Homebrewによるインストール" class="headerlink" title="Homebrewによるインストール"></a>Homebrewによるインストール</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">brew install orangekame3/tap/stree</span><br></pre></td></tr></table></figure><h1 id="使い方"><a href="#使い方" class="headerlink" title="使い方"></a>使い方</h1><div class="note warn" style="background: #fdf9e2; padding:16px; margin:24px 12px; border-radius:8px;">  <span class="fa fa-fw fa-check-circle"></span><p><strong>前提</strong><br>aws cliで利用するconfig及びcredentialsは事前に設定しておく必要があります。</p></div><p>以降、configとcredentialsが以下の通り設定されているものとします。</p><figure class="highlight ini"><figcaption><span>~/.aws/config</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="section">[my_profile]</span></span><br><span class="line"><span class="attr">region</span> = ap-northeast-<span class="number">1</span></span><br><span class="line"><span class="attr">output</span> = json</span><br></pre></td></tr></table></figure><figure class="highlight ini"><figcaption><span>~/.aws/credentials</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="section">[my_profile]</span></span><br><span class="line"><span class="attr">aws_access_key_id</span>=XXXXXXXXXXXXXXXXXXXXX</span><br><span class="line"><span class="attr">aws_secret_access_key</span>=XXXXXXXXXXXXXXXXX</span><br></pre></td></tr></table></figure><h2 id="基本的なコマンド"><a href="#基本的なコマンド" class="headerlink" title="基本的なコマンド"></a>基本的なコマンド</h2><p>バケット名とprofileを指定して、以下のコマンドを実行します。</p><p>プロファイルは<code>--profile(-p)</code>で指定します。</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">stree my-bucket -p my_profile</span><br></pre></td></tr></table></figure><p>以下のような出力が得られます。</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">my-bucket</span><br><span class="line">└── <span class="built_in">test</span></span><br><span class="line">    ├── dir1</span><br><span class="line">    │   ├── dir1_1</span><br><span class="line">    │   │   └── dir1_1_1</span><br><span class="line">    │   │       ├── file1.csv</span><br><span class="line">    │   │       └── file2.csv</span><br><span class="line">    │   └── dir1_2</span><br><span class="line">    │       ├── file1.csv</span><br><span class="line">    │       ├── file2.csv</span><br><span class="line">    │       └── file3.csv</span><br><span class="line">    ├── dir2</span><br><span class="line">    │   └── dir2_1</span><br><span class="line">    │       └── dir2_1_1</span><br><span class="line">    │           ├── file1.csv</span><br><span class="line">    │           ├── file2.csv</span><br><span class="line">    │           └── file3.csv</span><br><span class="line">    └── dir3</span><br><span class="line">        ├── file1.csv</span><br><span class="line">        └── file2.csv</span><br><span class="line"></span><br><span class="line">9 directories, 10 files</span><br></pre></td></tr></table></figure><h2 id="プレフィックスを指定"><a href="#プレフィックスを指定" class="headerlink" title="プレフィックスを指定"></a>プレフィックスを指定</h2><p>通常のユースケースを考えると、バケットの中には大量のオブジェクトが存在していることが予想されます。</p><p>そのため、バケット指定しかできない状況では使い物になりません。バケット名に続けてprefixを指定することで、ユーザーが確認したいパスの情報のみを確認することができます。</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">stree my-bucket/test/dir2 -p my_profile</span><br></pre></td></tr></table></figure><p>このコマンドの実行結果は以下のようになります。</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">my-bucket</span><br><span class="line">└── <span class="built_in">test</span></span><br><span class="line">    └── dir2</span><br><span class="line">        └── dir2_1</span><br><span class="line">            └── dir2_1_1</span><br><span class="line">                ├── file1.csv</span><br><span class="line">                ├── file2.csv</span><br><span class="line">                └── file3.csv</span><br><span class="line"></span><br><span class="line">4 directories, 3 files</span><br></pre></td></tr></table></figure><h2 id="リージョンのオーバーライド"><a href="#リージョンのオーバーライド" class="headerlink" title="リージョンのオーバーライド"></a>リージョンのオーバーライド</h2><p><code>--region(-r)</code>でリージョンを指定できます。</p><p>profileに記載しているリージョンとは別のリージョンを指定したいときなどは<code>--region</code>フラグを利用してオーバーライドしてください。</p><h2 id="Localstackでの利用"><a href="#Localstackでの利用" class="headerlink" title="Localstackでの利用"></a>Localstackでの利用</h2><p>Localstackでも利用できます。</p><p>ローカルスタックで利用する場合、endpointとregionはデフォルトで以下の通り設定していると思います。</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">endpoint = http://localhost:4566</span><br><span class="line">region = us-east-1</span><br></pre></td></tr></table></figure><p>大多数の場合は↑の設定で利用しているかと思いますのでLocalstack用のフラグを追加しています。<code>--local(-l)</code>がそれです。</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">stree my-bucket/test/dir2 -l</span><br></pre></td></tr></table></figure><p>特別な事情でエンドポイントやリージョンを変更する場合もあるかと思いますので、<code>--region(-r)</code> フラグと<code>--endpoint(-e)</code>でオーバーライドすることもできます。</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">stree my-bucket/test/dir2 -r us-east-1 -e http://localhost:4537</span><br></pre></td></tr></table></figure><p>出力は同じであるため省略します。</p><h2 id="カラー出力を無効化"><a href="#カラー出力を無効化" class="headerlink" title="カラー出力を無効化"></a>カラー出力を無効化</h2><p><code>--no-color(-n)</code>でカラー出力を無効化できます。</p><p>▼カラーつき<br><img src="/images/20230926a/color.png" alt="color.png" width="479" height="391" loading="lazy"></p><p>▼カラーなし<br><img src="/images/20230926a/no-color.png" alt="no-color.png" width="504" height="391" loading="lazy"></p><h1 id="さいごに"><a href="#さいごに" class="headerlink" title="さいごに"></a>さいごに</h1><p>実装に取り掛かるうえでtreeは骨が折れそうだなと思ったのですが、既にgteeというパッケージがGitHubで公開されていました。</p><p><a href="https://github.com/ddddddO/gtree"><img src="https://gh-card.dev/repos/ddddddO/gtree.svg" alt="ddddddO/gtree - GitHub"></a></p><p>パッケージの利用方法なども記事で公開されていて実装に困ることはありませんでした。</p><p>▼参考</p><ul><li><a href="https://zenn.dev/ddddddo/articles/ad97623a004496">Markdown形式の入力からtreeを出力するCLI</a></li><li><a href="https://zenn.dev/ddddddo/articles/8cd85c68763f2e">Goでtreeを表現する</a></li><li><a href="https://zenn.dev/ddddddo/articles/460d12e8c07763">Markdown形式の入力からファイル&#x2F;ディレクトリを生成するCLI&#x2F;Goパッケージ</a></li></ul><p>また、gtreeの作者である<a href="https://twitter.com/ddddddOpppppp">@ddddddO</a>さんにはstreeに<a href="https://github.com/orangekame3/stree/issues/9">issue</a>を起票いただいており、本記事公開前に致命的なバグを修正することができました。ありがとうございます。</p><p>gtreeでstreeの機能の核は難なく実装することができたため、着想から実装完了まで１日もかかりませんでした。</p><p>S3をtreeしてみたくなったらぜひstreeを利用してみてください。</p><p>本記事をお読みいただきありがとうございました。</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;img src=&quot;/images/20230926a/stree-display.png&quot; alt=&quot;&quot; width=&quot;1200&quot; height=&quot;600&quot; loading=&quot;lazy&quot;&gt;

&lt;h1 id=&quot;はじめに&quot;&gt;&lt;a href=&quot;#はじめに&quot;</summary>
        
      
    
    
    
    <category term="Programming" scheme="https://future-architect.github.io/categories/Programming/"/>
    
    
    <category term="AWS" scheme="https://future-architect.github.io/tags/AWS/"/>
    
    <category term="OSS" scheme="https://future-architect.github.io/tags/OSS/"/>
    
    <category term="Go" scheme="https://future-architect.github.io/tags/Go/"/>
    
    <category term="S3" scheme="https://future-architect.github.io/tags/S3/"/>
    
    <category term="CLI" scheme="https://future-architect.github.io/tags/CLI/"/>
    
  </entry>
  
  <entry>
    <title>ChatGPTでE2Eテストコード自動作成</title>
    <link href="https://future-architect.github.io/articles/20230925a/"/>
    <id>https://future-architect.github.io/articles/20230925a/</id>
    <published>2023-09-24T15:00:00.000Z</published>
    <updated>2023-10-02T00:07:27.512Z</updated>
    
    <content type="html"><![CDATA[<img src="/images/20230925a/mv_logo.png" alt="" width="510" height="210"><p>9&#x2F;7に行われた技育CAMPアカデミアというイベントでPlaywrightについて話をしてきました。テストというと、設計手法であるところのテスト駆動開発は別としてちょっと業務っぽい感じがして学生さんにはちょっと響かないかな、というのも心配でしたが、アンケートを見る限り、わかりやすかったという声も多くてほっとしました。</p><p>次のスライドが今回の資料です。スライドの内容の多くは<a href="https://future-architect.github.io/articles/20230821a/">Playwright連載始まります</a>に掲載されている記事にもぼつぼつある内容も多い（APIテストはないですが）のですが、本エントリーでは発表の最後に触れたChatGPTなどの生成AIを使ったE2Eテストの生成について説明していきます。</p><iframe src="https://docs.google.com/presentation/d/e/2PACX-1vTHcJ_bPEFpogd1hOy16uhOUOwEupUcKopM9kRYXFBJ4MUbfIbCmBbGsjd-_EyBkw/embed?start=false&loop=false&delayms=3000" frameborder="0" width="100%" height="569" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe><p>ChatGPTが話題を席巻してしばらく経ちます。とはいえ、内製開発での利用以外はソースコード開発にばりばり使う、みたいな宣言はあまり聞かない気がします。利用を制限している会社も数多くあります。</p><ul><li><a href="https://japan.zdnet.com/article/35207866/">ZDNET: 企業の75％が「ChatGPT」利用を禁止する方向–BlackBerry調査</a></li></ul><p>生成AIを使うかどうか判断の分かれ目になりそうな問題としては大きく３つあるように思います。これ以外にも書かれた内容の品質担保もありますが、利用側の努力だけでは厳しい内容がこの3つかな、と。このあたり、業界団体か法律の専門家がバシッと白黒つけてくれれば利用は進みそうな気がしますが、もうちょっと待ちですかね。</p><ul><li>生成した著作物の著作権</li><li>生成の過程で機密情報をアップロードする問題</li><li>生成したものが既存の著作物に似てしまって問題になる可能性</li></ul><p>現在の著作権法では、生成AIの成果物には著作権が及ばないため、納品物として出して対価をもらうものに対して使うのは厳しいですね。自分の著作物じゃないものですからね。OSSの開発も基本的にソースコードの著作権が自分にある前提でその利用の自由を決めるものなのでOSS開発にも使えなそうです。そうなると内製開発ぐらいしか残らないのかな、と。</p><p>2つめは学習データに使うオプションのオプトアウトとかAPI利用とかでだいぶ緩和された感じがありますが、無料版のChatGPTとかBing Chatを使うと問題がありそうなので企業のガイドライン整備みたいな話でまとまりそうな気はします。</p><p>3つめに関しては、GitHubは損害が発生したら保証するというライセンスになっていますが、しかし実際に訴訟が起きてどれぐらいで保証されるのかなど、実際に裁判が起こってみないとこには、どれぐらい裁判に時間がかかるのかなどビジネスのダメージわからないことが多いですよね。</p><p>プログラム以外だと特化AIの学習素材の権利侵害とか、他者著作物をアップロードする問題とかありますがプログラムにはあまりない気がします。このあたりは素人判断は危ないので、専門家が書いてくれたブログとかが参考になります。</p><ul><li><a href="https://storialaw.jp/blog/category/bigdata">STORIA法律事務所: ブログ&#x2F;人工知能（ＡＩ）、ビッグデータ法務</a></li></ul><p>そんなこんなで、生成AIの利用としては、現状は成果物を作るためのアドバイスをもらう用途が無難と言えます。そうなると、テストコードなら良さそうです。ソフトウェアの品質はテストコードに宿るのではなく、あくまでもコードに宿るものであり、テストは品質の悪化を見つけるための手段です。実際の成果物のソースコードには生成結果は含まれません。</p><p>まあテストのうち、設計ドキュメントも兼ねているようなアジャイル開発のユニットテストコードは使わない方が良いかもしれません。火事になったら製品コードではなくテストコードを持って逃げろ、というぐらいテストコードそのものが大事という文化なので。</p><p>生成されたものは自分の著作物ではないので、テストコードには「ChatGPTで生成しました」みたいな引用元を書いて引用として扱うとさらに安全なのではないかと思います。他者著作物の利用の手段として。</p><h1 id="PlaywrightのE2Eテストを生成してみる"><a href="#PlaywrightのE2Eテストを生成してみる" class="headerlink" title="PlaywrightのE2Eテストを生成してみる"></a>PlaywrightのE2Eテストを生成してみる</h1><p>本ブログでもすでにCypressの記事が何本かあったり、<a href="https://future-architect.github.io/articles/20211218a/">Software DesignでCypress連載</a>をしたり、<a href="https://future-architect.github.io/articles/20230821a/">Playwright連載</a>をおこなったり、E2Eテストについてはかなり触れています。</p><p>E2EテストはEnd to Endの意味です。まあAPIで提供するサービスであればEはAPIになるとは思いますが、ここでは最終的にできあがったウェブアプリケーションをブラウザで操作するテストのことをE2Eと呼んでいます。早速やってみましょう。pageオブジェクトについての文がないとテストコード形式ではないものが出てくるので追加しました。</p><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">次のHTMLに対してPlaywrightでフォームを埋めて送信ボタンを押すテストコードを書いてください。pageオブジェクトはtestの第二引数から取得してください。</span><br><span class="line"></span><br><span class="line">```</span><br><span class="line">&lt;form action=&quot;login.php&quot; method=&quot;post&quot;&gt;</span><br><span class="line">    &lt;label for=&quot;username&quot;&gt;Username:&lt;/label&gt;</span><br><span class="line">    &lt;input type=&quot;text&quot; id=&quot;username&quot; name=&quot;username&quot; required&gt;</span><br><span class="line"></span><br><span class="line">    &lt;label for=&quot;password&quot;&gt;Password:&lt;/label&gt;</span><br><span class="line">    &lt;input type=&quot;password&quot; id=&quot;password&quot; name=&quot;password&quot; required&gt;</span><br><span class="line">    &lt;input type=&quot;submit&quot; value=&quot;Login&quot;&gt;</span><br><span class="line">&lt;/form&gt;</span><br><span class="line">```</span><br></pre></td></tr></table></figure><p>このHTMLは実際の本物のフォームである必要はなく、セマンティック要素(aタグ、buttonタグ、formタグ、labelタグ、mainタグ、navタグ、articleタグ)ぐらいだけに整理して、id属性とかCSSとか全部とっぱらったシンプルなHTMLを作って入力にする方が良いでしょう。</p><p>生成されたコードは以下の通りです。</p><figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> &#123; test, expect &#125; = <span class="built_in">require</span>(<span class="string">&#x27;@playwright/test&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="title function_">test</span>(<span class="string">&#x27;フォーム送信テスト&#x27;</span>, <span class="keyword">async</span> (&#123; page &#125;) =&gt; &#123;</span><br><span class="line">  <span class="comment">// テスト対象のURLに移動</span></span><br><span class="line">  <span class="keyword">await</span> page.<span class="title function_">goto</span>(<span class="string">&#x27;URLをここに入力&#x27;</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// フォームの入力フィールドを埋める</span></span><br><span class="line">  <span class="keyword">await</span> page.<span class="title function_">fill</span>(<span class="string">&#x27;input[name=&quot;username&quot;]&#x27;</span>, <span class="string">&#x27;ユーザー名をここに入力&#x27;</span>);</span><br><span class="line">  <span class="keyword">await</span> page.<span class="title function_">fill</span>(<span class="string">&#x27;input[name=&quot;password&quot;]&#x27;</span>, <span class="string">&#x27;パスワードをここに入力&#x27;</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 送信ボタンをクリック</span></span><br><span class="line">  <span class="keyword">await</span> page.<span class="title function_">click</span>(<span class="string">&#x27;input[type=&quot;submit&quot;]&#x27;</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 送信後のページで特定の条件を確認する（例: ログイン成功のメッセージ）</span></span><br><span class="line">  <span class="keyword">await</span> <span class="title function_">expect</span>(page).<span class="title function_">toHaveText</span>(<span class="string">&#x27;ログイン成功のメッセージをここに入力&#x27;</span>);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>CSSセレクターを使ってしまっているのがいまいちですね。</p><p>「ブラウザを操作」といっても、ある程度HTMLを理解した上でテストコードを書く必要があります。Playwrightは標準で、<code>getByLabel()</code>とか<code>getByRole()</code>というAPIを持っています。Cypressは<a href="https://testing-library.com/docs/cypress-testing-library/intro/">@testing-library&#x2F;cypress</a>という追加ライブラリがあります。過去のブログで書いたように、これらを使うとHTMLのセレクターではなく、「ユーザーから見た見た目」に近いテストコードが書けるようになり、より抽象度が高くなって壊れにくくなります。</p><ul><li><a href="https://future-architect.github.io/articles/20210226/">アクセシビリティ情報を使った壊れにくいE2Eテスト</a></li></ul><p>とはいうものの、 “要素選択はCSSセレクタを使わずにgetByRole、getByLabelなどをなるべく使って書き換えてください” というのを書いても、5回に1回ぐらいしかなかなか書いてくれないですね。うまく行った時のコードはこんな感じです。</p><figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> usernameInput = <span class="keyword">await</span> page.<span class="title function_">getByLabel</span>(<span class="string">&#x27;Username:&#x27;</span>);</span><br><span class="line"><span class="keyword">await</span> usernameInput.<span class="title function_">fill</span>(<span class="string">&#x27;your_username&#x27;</span>); <span class="comment">// Replace with the actual username</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> passwordInput = <span class="keyword">await</span> page.<span class="title function_">getByLabel</span>(<span class="string">&#x27;Password:&#x27;</span>);</span><br><span class="line"><span class="keyword">await</span> passwordInput.<span class="title function_">fill</span>(<span class="string">&#x27;your_password&#x27;</span>); <span class="comment">// Replace with the actual password</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Submit the form</span></span><br><span class="line"><span class="keyword">const</span> submitButton = <span class="keyword">await</span> page.<span class="title function_">getByRole</span>(<span class="string">&#x27;button&#x27;</span>, &#123; <span class="attr">name</span>: <span class="string">&#x27;Login&#x27;</span> &#125;);</span><br><span class="line"><span class="keyword">await</span> submitButton.<span class="title function_">click</span>()</span><br></pre></td></tr></table></figure><p>ここは手修正する必要がありそうです。BardとかBing Chatを使ってもだいたい同じでしたが、Bing Chatは「getByRole、getByLabelを使って書き換えてください」というと、そこそこの打率で書き換えてくれましたが、たまに公式の1.27から提供されたAPIではなく<a href="https://github.com/testing-library/playwright-testing-library">@testing-library&#x2F;playwright</a>ベースのコードを出力することもありました。独創的、バランス、安定問わず。</p><h1 id="Cypress向けはどうか？"><a href="#Cypress向けはどうか？" class="headerlink" title="Cypress向けはどうか？"></a>Cypress向けはどうか？</h1><p>実はCypress向けだとばっちり決まります。</p><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">次のHTMLに対してCypressでフォームを埋めて送信ボタンを押すテストコードを書いてください。testing-library/cypressを使ってください</span><br></pre></td></tr></table></figure><figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">&#x27;@testing-library/cypress/add-commands&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="title function_">describe</span>(<span class="string">&#x27;Login Form&#x27;</span>, <span class="function">() =&gt;</span> &#123;</span><br><span class="line">  <span class="title function_">it</span>(<span class="string">&#x27;should fill out the form and submit&#x27;</span>, <span class="function">() =&gt;</span> &#123;</span><br><span class="line">    cy.<span class="title function_">visit</span>(<span class="string">&#x27;/&#x27;</span>); <span class="comment">// Replace with the actual URL</span></span><br><span class="line"></span><br><span class="line">    cy.<span class="title function_">findByLabelText</span>(<span class="string">&#x27;Username:&#x27;</span>).<span class="title function_">type</span>(<span class="string">&#x27;your-username&#x27;</span>);</span><br><span class="line">    cy.<span class="title function_">findByLabelText</span>(<span class="string">&#x27;Password:&#x27;</span>).<span class="title function_">type</span>(<span class="string">&#x27;your-password&#x27;</span>);</span><br><span class="line"></span><br><span class="line">    cy.<span class="title function_">findByText</span>(<span class="string">&#x27;Login&#x27;</span>).<span class="title function_">click</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// You can add assertions or further testing logic here</span></span><br><span class="line">  &#125;);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>いい感じですね。このまま使えそうな勢い。Cypressはずっと安定したAPIを提供し、Playwrightはアクティブに機能追加したりしている印象がありますが、これが生成AI経由に使い勝手に影響を与えるというのはなかなか興味深い結果です。</p><h1 id="まとめ"><a href="#まとめ" class="headerlink" title="まとめ"></a>まとめ</h1><p>Playwrightの方がちょっとイマイチでしたが、将来性は感じる結果は得られました。HTMLを渡すだけでそれを操作するコードを書いてくれました。Cypressはばっちりでしたので、いっそのことPlaywrightでテストを書く場合に、Cypress向けに生成したコードを何かしらのスクリプトで書き換えて使う方が良いかもしれません。</p><p>今回はログインフォームだけですが、より複雑なフォームやメニュー選択なども作ってくれるでしょうし、入力パラメータをテーブルにしておいて、複数のケースをまとめて生成とかもやってくれそうです。「こうしたい」という自然言語で書かれた仕様書とHTMLを渡せばある程度作ってくれる見込みはありそうなので、うまく使えばテストコードを量産する手間は少し減らせそうです。</p><p>もちろん、知識ゼロでいきなりできるかというと、やはりある程度知識がある人じゃないと使いこなせない感じはありました。</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;img src=&quot;/images/20230925a/mv_logo.png&quot; alt=&quot;&quot; width=&quot;510&quot;</summary>
        
      
    
    
    
    <category term="Programming" scheme="https://future-architect.github.io/categories/Programming/"/>
    
    
    <category term="Cypress" scheme="https://future-architect.github.io/tags/Cypress/"/>
    
    <category term="ChatGPT" scheme="https://future-architect.github.io/tags/ChatGPT/"/>
    
    <category term="Playwright" scheme="https://future-architect.github.io/tags/Playwright/"/>
    
    <category term="プロンプト" scheme="https://future-architect.github.io/tags/%E3%83%97%E3%83%AD%E3%83%B3%E3%83%97%E3%83%88/"/>
    
    <category term="E2E" scheme="https://future-architect.github.io/tags/E2E/"/>
    
    <category term="技育CAMPアカデミア" scheme="https://future-architect.github.io/tags/%E6%8A%80%E8%82%B2CAMP%E3%82%A2%E3%82%AB%E3%83%87%E3%83%9F%E3%82%A2/"/>
    
    <category term="登壇資料" scheme="https://future-architect.github.io/tags/%E7%99%BB%E5%A3%87%E8%B3%87%E6%96%99/"/>
    
  </entry>
  
  <entry>
    <title>新入社員が「リーダブルコード」を読んでみた</title>
    <link href="https://future-architect.github.io/articles/20230922a/"/>
    <id>https://future-architect.github.io/articles/20230922a/</id>
    <published>2023-09-21T15:00:00.000Z</published>
    <updated>2023-10-02T00:07:27.512Z</updated>
    
    <content type="html"><![CDATA[<img src="/images/20230922a/top.jpeg" alt="top" width="400" height="567" loading="lazy"><p><a href="https://www.oreilly.co.jp/books/9784873115658/">O’Reilly Japan リーダブルコード</a></p><h1 id="はじめに"><a href="#はじめに" class="headerlink" title="はじめに"></a>はじめに</h1><p>はじめまして。フューチャーに2023年4月に新卒入社した関根です。今回の投稿が初の投稿となります。</p><p>最初の記事は何が良いか？と考えたのですが、業務の事を考えるとまずは可読性の高いコードを書けた方が良いと考え、教材に「<a href="https://www.oreilly.co.jp/books/9784873115658/">リーダブルコード</a>」を選びました。名著ですね。超有名な本なのに入社するまで読んだことがありませんでした。という事でこれを機に学んでいきます。</p><p>しかし、ただ本の内容をまとめていても面白く無いなーと感じたため、私が初めてプログラミングを触った大学1年性の時のC言語のコードを取り出してきて、それを修正しながら学ぶ形式にします。内容はかなり初歩的ですが、焦らず基本からです。</p><p>今回の内容は<a href="https://www.oreilly.co.jp/books/9784873115658/">リーダブルコード</a>の第一部「表面上の改善」を参考にしています。本の詳しい章立てなどは<a href="https://www.oreilly.co.jp/books/9784873115658/">こちら</a>の目次をご確認ください。</p><h1 id="最大照度を発見するコード"><a href="#最大照度を発見するコード" class="headerlink" title="最大照度を発見するコード"></a>最大照度を発見するコード</h1><p>こちらのコードは照度センサーから最大照度を発見するためのコードです。<br>6年前の当時のコードをほぼそのまま取り出しています(一部省略はしています)。</p><div class="note warn" style="background: #fdf9e2; padding:16px; margin:24px 12px; border-radius:8px;">  <span class="fa fa-fw fa-check-circle"></span><p>可読性の低い箇所を修正してください。</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">float</span> a[<span class="number">20</span>];</span><br><span class="line">    <span class="type">float</span> max = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">20</span>; ++i) &#123;</span><br><span class="line">        a[i] = lum.lux();  <span class="comment">//センサーから照度を取得</span></span><br><span class="line">        <span class="keyword">if</span>(max &lt; a[i])&#123;</span><br><span class="line">            max = a[i];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%7.1f[lux]\r\n&quot;</span>,a[i]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><h2 id="変数名などを可読性の高いものに変えよう"><a href="#変数名などを可読性の高いものに変えよう" class="headerlink" title="変数名などを可読性の高いものに変えよう"></a>変数名などを可読性の高いものに変えよう</h2><p>上から順に見てみましょう。</p><p>まず<code>a</code>が何を指しているのかが全くわかりませんね。コード全体を見れば、<strong>センサーから取得された照度を格納する配列</strong>と理解できますが、コード全体を読まなくてはならない時点で不親切です。</p><p>ここでの照度の単位は<code>Lux</code>であるため<code>luxValues</code>や、照度の英語がilluminanceであることから、illuminanceを格納するarrayという事で<code>illuminanceArray</code>も良いかもしれませんね。こう書くことにより、この名前を見るだけでも、「これには照度の値が複数格納されているのだな」というのが誰が見ても分かるようになります。親切ですね。</p><p>それで言うと、float型の変数、maxというのも不親切です。先ほどの<code>a</code>よりは、この変数には最大値が含まれるのだな、と分かりますが、何の最大値なのか？は変数名から全く分かりません。これも同じように<code>maxIlluminance</code>や、<code>maxLuxValue</code>などがあるでしょうか。これであれば一目見れば何の最大値なのかが分かるようになります。</p><p>まだ2つしか修正していませんが、先ほどのコードに反映させてみましょう。</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">float</span> illuminanceArray[<span class="number">20</span>];</span><br><span class="line">    <span class="type">float</span> maxIlluminance = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">20</span>; ++i) &#123;</span><br><span class="line">        illuminanceArray[i] = lum.lux();  <span class="comment">//センサーから照度を取得</span></span><br><span class="line">        <span class="keyword">if</span>(maxIlluminance &lt; illuminanceArray[i])&#123;</span><br><span class="line">            maxIlluminance = illuminanceArray[i];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%7.1f[lux]\r\n&quot;</span>,illuminanceArray[i]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>文字数は多くなりましたが、各行で何をしているのかが分かりやすくなりました。</p><p>使用する英単語等は「照度　英語」や「照度　翻訳」のようにすれば出てきます。</p><p>まとめますと、変数の命名をする際は以下に注意すればいいでしょうか。</p><div class="note alert" style="background: #feebee; padding:16px; margin:24px 12px; border-radius:8px;">  <span class="fa fa-fw fa-check-circle"></span><ul><li>その変数に必要な情報を入れる。何に使う変数なのか？(今回なら照度だからilluminance)</li><li>面倒だからとローマ字で書かない。(shodoArrayとかは良くない)</li><li>変数を書くときはローワーキャメルケースで。<br>(単語を繋げる際に、2単語目以降の頭文字を大文字にする。<code>lowerCamelCase</code>, <code>firstName</code>、<code>maxLuxValue</code>など)</li></ul></div><h3 id="補足説明-命名する際は全てローワーキャメルケースにするべき？"><a href="#補足説明-命名する際は全てローワーキャメルケースにするべき？" class="headerlink" title="補足説明 　命名する際は全てローワーキャメルケースにするべき？"></a>補足説明 　命名する際は全てローワーキャメルケースにするべき？</h3><p>変数を命名する際によく使う形式がいくつかあります。</p><ul><li><strong>アッパーキャメルケース</strong><ul><li>単語を繋げる際に、全ての単語の頭文字を大文字にする</li><li><code>UpperCamelCase</code>, <code>UpdateEmployee</code>, <code>EditEmployee</code>など</li></ul></li><li><strong>スネークケース</strong><ul><li>単語を繋げる際に、<code>_</code>(アンダーバー)でつなげる</li><li><code>local_file</code>, <code>employee_id</code>など</li></ul></li><li><strong>アッパースネークケース&#x2F;コンスタントケース</strong><ul><li>単語を繋げる際に、<code>_</code>(アンダーバー)でつなげつつ、全ての文字を大文字にする</li><li><code>ARRAY_SIZE</code>, <code>DEFAULT_ID</code>など</li></ul></li></ul><p>リーダブルコードの2.6節「名前のフォーマットで情報を伝える」ではこの名前の書き方で変数や関数に情報を持たせる方法が記載されていました。</p><p>例えば、</p><ul><li>クラス名やメソッド名にはアッパーキャメルケース</li><li>ローカル変数にはスネークケース</li><li>定数にはアッパースネークケース</li></ul><p>などです。</p><p>こうする事で、コードを読んでいる際に「この<code>UpdateEmployee</code>はアッパーキャメルケースだな。つまりクラス名かメソッドだ」などと名前とは別に情報を簡単に付加出来ます。</p><p>しかしこのあたりのルールは開発チームが採用する、言語や開発規約に依存すると思います。これについては勝手に変更するのではなく、チームの方針に従いましょう。</p><div class="note info" style="background: #e5f8e2; padding:16px; margin:24px 12px; border-radius:8px;">  <span class="fa fa-fw fa-check-circle"></span><ul><li>全てキャメルケースにするのが良いとも限らない</li><li>命名規則は使い分けると情報量を付加できる</li></ul></div><h2 id="マジックナンバー"><a href="#マジックナンバー" class="headerlink" title="マジックナンバー"></a>マジックナンバー</h2><p>次に気になるのは何でしょうか。</p><p>可読性、というよりは再利用性を高める部分になりますが、コードの中に<code>20</code>という数値が2回出ているのが気になりますね。今回は小さいコードなので、問題にはなっていませんが、より大規模なコードになり、<code>20</code>という数値が100回出てきたとしたらどうしましょう。全て一々修正していたら日が暮れますね。</p><p>こういった<strong>直に記述された数値</strong>のことを<strong>マジックナンバー</strong>と呼びます。</p><p>20という数値には一見情報がありそうで、何も情報はありません。</p><p>例えば</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">20</span>; ++i) &#123;</span><br></pre></td></tr></table></figure><p>これだけ急に見せられても何のコードか全く想像ができませんね。</p><p>20回何かを表示するためなのか、配列の中身を表示するためなのか。</p><p>そこで定数の出番です(C言語の場合は配列のサイズ指定をする際にconstは使えず、マクロを使用する必要があります)。この<code>20</code>という数値は<strong>照度が格納された配列のサイズ</strong>を表すため、<code>ILLUMINANCE_ARRAY_SIZE</code>などが良いでしょうか。</p><div class="note info" style="background: #e5f8e2; padding:16px; margin:24px 12px; border-radius:8px;">  <span class="fa fa-fw fa-check-circle"></span><p>C言語のマクロでは、全て大文字で単語間を<code>_</code>で繋ぐのが一般的です(アッパースネークケース)。</p></div><p>これをコードに反映させると、</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> ILLUMINANCE_ARRAY_SIZE 20</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">float</span> illuminanceArray[ILLUMINANCE_ARRAY_SIZE];</span><br><span class="line">    <span class="type">float</span> maxIlluminance = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; ILLUMINANCE_ARRAY_SIZE; ++i) &#123;</span><br><span class="line">        illuminanceArray[i] = lum.lux();  <span class="comment">//センサーから照度を取得</span></span><br><span class="line">        <span class="keyword">if</span>(maxIlluminance &lt; illuminanceArray[i])&#123;</span><br><span class="line">            maxIlluminance = illuminanceArray[i];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%7.1f[lux]\r\n&quot;</span>,illuminanceArray[i]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>これで配列のサイズを変更したい！となった場合は1行目の定数(マクロ)の数値を変更するだけで、まとめて2か所変更が出来ますね。可読性を向上させながら、再利用性を高める事が出来ました。</p><h2 id="ループイテレータ「-i-」をどうするか？"><a href="#ループイテレータ「-i-」をどうするか？" class="headerlink" title="ループイテレータ「 i 」をどうするか？"></a>ループイテレータ「 i 」をどうするか？</h2><p>上記の調子で行くと、for文の繰り返しで使われている<code>i</code>の名前も変えた方が良いと感じますね。</p><p><code>i</code>は<code>illuminanceArray</code>のインデックスを表しているため、<code>illumIdx</code>(illuminance Indexの略)などが良いでしょうか。では反映させてみましょう。</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> ILLUMINANCE_ARRAY_SIZE 20</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">float</span> illuminanceArray[ILLUMINANCE_ARRAY_SIZE];</span><br><span class="line">    <span class="type">float</span> maxIlluminance = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> illumIdx = <span class="number">0</span>; illumIdx &lt; ILLUMINANCE_ARRAY_SIZE; ++illumIdx) &#123;</span><br><span class="line">        illuminanceArray[illumIdx] = lum.lux();  <span class="comment">//センサーから照度を取得</span></span><br><span class="line">        <span class="keyword">if</span>(maxIlluminance &lt; illuminanceArray[illumIdx])&#123;</span><br><span class="line">            maxIlluminance = illuminanceArray[illumIdx];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%7.1f[lux]\r\n&quot;</span>,illuminanceArray[illumIdx]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>確かにコードの可読性は上がったような気がします。</p><p>しかしコードが1行1行長くなってしまいましたね。今回は小さいコードであるため、これでも読めないことはないですが、やり過ぎには注意です。一般的に<code>i</code>はfor文の繰り返しで使用される変数名として浸透しています。(iはindexから来ているみたいです)そのため、何でもかんでも変数名を長いものにするのが良い、という訳でも無いみたいです。</p><p>読みやすいコードを書く最大の意義は<strong>次に読む人が、読むのに(理解するのに)時間を要さないコード</strong>です。丁寧に書こう！という気持ちが先走り、コードの長さが10倍になってしまったら本末転倒です。</p><p>分かりやすく書くことも大事ですが、同時に行き過ぎて無いだろうか？と考えるのも同じぐらい大事そうですね。</p><h2 id="処理をまとめる"><a href="#処理をまとめる" class="headerlink" title="処理をまとめる"></a>処理をまとめる</h2><p>ここでは前節の<code>i</code>を<code>illumIdx</code>に変更するのは取り消しておきましょう。</p><p>以下の状態ですね。</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> ILLUMINANCE_ARRAY_SIZE 20</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">float</span> illuminanceArray[ILLUMINANCE_ARRAY_SIZE];</span><br><span class="line">    <span class="type">float</span> maxIlluminance = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; ILLUMINANCE_ARRAY_SIZE; ++i) &#123;</span><br><span class="line">        illuminanceArray[i] = lum.lux();  <span class="comment">//センサーから照度を取得</span></span><br><span class="line">        <span class="keyword">if</span>(maxIlluminance &lt; illuminanceArray[i])&#123;</span><br><span class="line">            maxIlluminance = illuminanceArray[i];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%7.1f[lux]\r\n&quot;</span>,illuminanceArray[i]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>あと修正を加えるとしたらなんでしょうか。</p><p>最後の<code>printf</code>文が気になりますね。この<code>printf</code>ではセンサーから取得した照度の値を表示するために書かれています。であれば、最後に書く必要はないでしょう。</p><p>照度を取得した段階で表示しても問題ないはずです。</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> ILLUMINANCE_ARRAY_SIZE 20</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">float</span> illuminanceArray[ILLUMINANCE_ARRAY_SIZE];</span><br><span class="line">    <span class="type">float</span> maxIlluminance = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; ILLUMINANCE_ARRAY_SIZE; ++i) &#123;</span><br><span class="line">        <span class="comment">//センサーから照度を取得</span></span><br><span class="line">        illuminanceArray[i] = lum.lux();</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%7.1f[lux]\r\n&quot;</span>,illuminanceArray[i]);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//最大値を探す</span></span><br><span class="line">        <span class="keyword">if</span>(maxIlluminance &lt; illuminanceArray[i])&#123;</span><br><span class="line">            maxIlluminance = illuminanceArray[i];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以下はリーダブルコードからの引用になります(4.6節、4.7節)。</p><blockquote><p>人間の脳はグループや改装を1つの単位として考える。<strong>コードの概要をすばやく把握してもらうには、このような「単位」を作ればよい。</strong><br>(中略)<br>文章は複数の段落に分割されている。それは、</p></blockquote><ul><li><strong>似ている考えをグループにまとめて、他の考えと分けるためだ。</strong></li><li>視覚的な「踏み石」を提供できるからだ。これがなければ、ページのなかで自分の場所を見失ってしまう。</li><li>段落単位で移動ができるようになるからだ。</li></ul><p>これと同じ理由で、<strong>コードも「段落」に分けるべきだ。</strong></p><p>つまり、コードの流し読みが出来るかどうか？というのが一つの観点になるかなと思いました。<strong>パッとコードを見た時に、どれだけ内容を把握できるか。</strong></p><p>今回ぐらいのコード量であればわざわざ分ける必要も無いかもしれませんが、分けたことにより、<strong>for文の中には2つの処理があるんだな</strong>というのが分かりやすくなります。2つの塊としてfor文内を認識できるという事。</p><p>上の塊は照度の値を取得、下の塊は最大値を探す、と瞬時に分かります。</p><p>この書き方は大規模な開発になるほど有用になりそうです。</p><h2 id="before-after"><a href="#before-after" class="headerlink" title="before after"></a>before after</h2><p>今回加えられる修正はこのくらいでしょうか。</p><p>最後に修正前と修正後を比べてみようと思います。</p><figure class="highlight c"><figcaption><span>before</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">float</span> a[<span class="number">20</span>];</span><br><span class="line">    <span class="type">float</span> max = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">20</span>; ++i) &#123;</span><br><span class="line">        a[i] = lum.lux();  <span class="comment">//センサーから照度を取得</span></span><br><span class="line">        <span class="keyword">if</span>(max &lt; a[i])&#123;</span><br><span class="line">            max = a[i];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%7.1f[lux]\r\n&quot;</span>,a[i]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c"><figcaption><span>after</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> ILLUMINANCE_ARRAY_SIZE 20</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">float</span> illuminanceArray[ILLUMINANCE_ARRAY_SIZE];</span><br><span class="line">    <span class="type">float</span> maxIlluminance = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; ILLUMINANCE_ARRAY_SIZE; ++i) &#123;</span><br><span class="line">        <span class="comment">//センサーから照度を取得</span></span><br><span class="line">        illuminanceArray[i] = lum.lux();</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%7.1f[lux]\r\n&quot;</span>,illuminanceArray[i]);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//最大値を探す</span></span><br><span class="line">        <span class="keyword">if</span>(maxIlluminance &lt; illuminanceArray[i])&#123;</span><br><span class="line">            maxIlluminance = illuminanceArray[i];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>全体的にコードの情報量が増えて読みやすくなりました。</p><p>beforeのコードはコードの途中から読み始めると、「aってなんだ？」となってしまいます。また、コメントで「センサーから照度を取得」という文字が無ければ、このコードが何に使われるコードなのかも殆ど分からなくなってしまいます。</p><p>対してafterのコードはどこから読んでも、このコードがどんな場所で使われるのか？が分かりやすくなっています。</p><p>またコードを読むだけで、照度を取得してその中から最大値を取得するコードだ、というのが分かります。</p><p>可読性をかなり向上させる事が出来たのではないでしょうか。</p><h1 id="まとめと感想"><a href="#まとめと感想" class="headerlink" title="まとめと感想"></a>まとめと感想</h1><p>今回はかなり短いコードでしたが、基本的な事とは言え結構色んな事を学べました。</p><p><strong>命名規則</strong>、<strong>命名規則の使い分け</strong>、<strong>マジックナンバー</strong>、<strong>ループイテレータの命名</strong>、<strong>処理をまとめて書く</strong>、など。<br>基本的とは言え、これが出来ていたか？というと、うむーという感じです。これを機に意識していきます。</p><p>まだまだ可読性を上げるための技術は沢山ありました。コメントの書き方や制御フローの書き方など。今後も自分が過去に書いたコードでいい感じの教材になりそうなものがあったらとりあげて、今回のような記事を書いてみようかな、と考えております。</p><p>最後に、技術記事を書くのが本当に初めてなのでどう書くのが自分にとって書きやすいか？また、他の人にも有益になるか？というのは考えていかないとな、と思いました。まずは場数を踏むため、色んな記事があげられるように頑張ります。</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;img src=&quot;/images/20230922a/top.jpeg&quot; alt=&quot;top&quot; width=&quot;400&quot; height=&quot;567&quot; loading=&quot;lazy&quot;&gt;

&lt;p&gt;&lt;a</summary>
        
      
    
    
    
    <category term="Programming" scheme="https://future-architect.github.io/categories/Programming/"/>
    
    
    <category term="可読性" scheme="https://future-architect.github.io/tags/%E5%8F%AF%E8%AA%AD%E6%80%A7/"/>
    
    <category term="書評" scheme="https://future-architect.github.io/tags/%E6%9B%B8%E8%A9%95/"/>
    
    <category term="リーダブルコード" scheme="https://future-architect.github.io/tags/%E3%83%AA%E3%83%BC%E3%83%80%E3%83%96%E3%83%AB%E3%82%B3%E3%83%BC%E3%83%89/"/>
    
    <category term="新人教育" scheme="https://future-architect.github.io/tags/%E6%96%B0%E4%BA%BA%E6%95%99%E8%82%B2/"/>
    
  </entry>
  
  <entry>
    <title>【合格記】Google Cloud Professional Cloud Security Engineer認定資格を振り返る</title>
    <link href="https://future-architect.github.io/articles/20230921a/"/>
    <id>https://future-architect.github.io/articles/20230921a/</id>
    <published>2023-09-20T15:00:00.000Z</published>
    <updated>2023-10-02T00:07:27.511Z</updated>
    
    <content type="html"><![CDATA[<img src="/images/20230921a/image.png" alt="" width="611" height="593" loading="lazy"><h2 id="はじめに"><a href="#はじめに" class="headerlink" title="はじめに"></a>はじめに</h2><p>TIG 岸下です。</p><p>これまでのプロジェクトでは組織全体のGoogle Cloudプロジェクトを包括的に見る業務に携わっており、主にIAMやネットワークを含むGoogle Cloud環境上の治安維持のような仕事を担ってきました。今回はその経験値を測るべくProfessional Cloud Security Engineer認定資格を受けてきました。</p><p>無事に合格を果たすことができたので、本記事では学習内容などの過程を書いていこうと思います。</p><p>また本試験はGoogle Cloudパートナー企業向けのバウチャーを活用して受験しました。大変感謝しております！</p><p>Google Cloud 認定資格関連の過去記事：</p><ul><li><a href="/articles/20211013a/">【合格記】Google Cloud Professional Data Engineer認定資格を振り返る</a></li><li><a href="/articles/20220930a/">【合格記】Google Cloud Professional Machine Learning Engineer認定資格を振り返る</a></li><li><a href="/articles/20220411a/">Google Cloud Professional Cloud Architectの再認定に合格しました</a></li><li><a href="/articles/20200902/">GCP Professional Cloud Network Engineer に合格しました</a></li><li><a href="/articles/20210625a/">GCP Associate Cloud Engineer 合格記</a></li></ul><h2 id="試験と出題範囲"><a href="#試験と出題範囲" class="headerlink" title="試験と出題範囲"></a>試験と出題範囲</h2><p><a href="https://cloud.google.com/learn/certification/cloud-security-engineer?hl=ja">公式</a>の出題範囲と、実際に自分が受けた際の所感は以下になります。</p><h3 id="クラウド-ソリューション環境内のアクセスの構成"><a href="#クラウド-ソリューション環境内のアクセスの構成" class="headerlink" title="クラウド ソリューション環境内のアクセスの構成"></a>クラウド ソリューション環境内のアクセスの構成</h3><ul><li>IAMによるサービスへのアクセス制御<ul><li>組織IAM・フォルダIAM・プロジェクトIAM・リソースIAMのすみわけ</li><li>継承の理解<ul><li>どの階層のIAMが適用されるのか？</li></ul></li></ul></li><li>組織ポリシーの理解<ul><li>Service Account作成の制限やCloud Storage Bucketの公開制限など、プロジェクト全体のリソースを制御</li></ul></li><li>プロジェクトやフォルダの分け方のベストプラクティス<ul><li>例：部署ごとにフォルダ分けをして、その中にプロジェクトを作成するなど<ul><li><a href="https://cloud.google.com/docs/enterprise/best-practices-for-enterprise-organizations?hl=ja">エンタープライズ企業のベスト プラクティス</a></li></ul></li></ul></li><li>Cloud Identityによるユーザー管理<ul><li>グループを利用したユーザーの管理</li><li>Google Cloud Directory Syncを利用したADサーバーとGoogle Cloudの統合</li></ul></li></ul><h3 id="ネットワーク-セキュリティの構成"><a href="#ネットワーク-セキュリティの構成" class="headerlink" title="ネットワーク セキュリティの構成"></a>ネットワーク セキュリティの構成</h3><ul><li>以下のGoogle Cloudネットワークの<a href="https://cloud.google.com/firewall/docs/firewalls?hl=ja#default_firewall_rules">暗黙のFirewallルール</a>は絶対に覚えておきましょう<ul><li><strong>INGRESSは全て拒否</strong></li><li><strong>EGRESSは全て許可</strong></li></ul></li><li>Firewall全般<ul><li><a href="https://cloud.google.com/firewall/docs/firewalls?hl=ja#priority_order_for_firewall_rules">Priority値の高低と優先度の関係</a></li><li>ネットワークタグ・サービスアカウントを活用したFirewallルール</li></ul></li><li>VPC Peering&#x2F;Cloud VPN&#x2F;Cloud Interconnectの使い分け<ul><li>Cloud InterconnectはさらにPartner&#x2F;Dedicatedで用途が分かれる</li></ul></li></ul><h3 id="データ保護の確保"><a href="#データ保護の確保" class="headerlink" title="データ保護の確保"></a>データ保護の確保</h3><ul><li><a href="https://cloud.google.com/vpc-service-controls/docs/overview?hl=ja">VPC Service Control</a>によるデータ保護<ul><li>プロジェクトに対して各種サービスのAPI実行を制限し、データの持ち出し・持ち込みを防ぐ</li><li>拙著も参考にしてみて下さい：<a href="https://future-architect.github.io/articles/20230119a/">VPC Service ControlでGoogle Cloud環境をガッチリ守る</a></li></ul></li><li>Cloud DLP(Data Loss Prevention)の活用<ul><li>個人情報に対する適切な暗号化</li><li>暗号化は復元する必要があるのか否かによって手法が変わる<ul><li>決定的暗号化 or 完全なマスキング</li></ul></li></ul></li></ul><h3 id="クラウド-ソリューション環境内のオペレーションの管理"><a href="#クラウド-ソリューション環境内のオペレーションの管理" class="headerlink" title="クラウド ソリューション環境内のオペレーションの管理"></a>クラウド ソリューション環境内のオペレーションの管理</h3><ul><li>Cloud KMSを利用した暗号鍵の保管<ul><li><a href="https://cloud.google.com/kms/docs/envelope-encryption?hl=ja">Envelop encryption</a>は勿論、それに関わる以下の用語は説明できるようにしておきましょう<ul><li>CMEK</li><li>CSEK</li><li>DEK</li><li>KEK</li></ul></li><li>どうやって暗号鍵を保管しておきたいのか？</li></ul></li><li>Secret Managerの活用<ul><li>API keyなどはSecret Managerに保存しておきましょう</li></ul></li></ul><h3 id="コンプライアンスの確保"><a href="#コンプライアンスの確保" class="headerlink" title="コンプライアンスの確保"></a>コンプライアンスの確保</h3><ul><li>各種ログで何の情報が得られるのか？<ul><li>Audit log</li><li>Data Access log</li></ul></li><li>Googleの<code>_Default</code>&#x2F;<code>_Required</code>のログバケットとは？<ul><li><a href="https://cloud.google.com/logging/docs/buckets?hl=ja">ログバケットの構成</a></li><li>保存期間や料金体系も異なる</li></ul></li><li>監査ログの保管方法<ul><li>長期間保管したい場合はLog SinkとCloud Storageを活用してコストカット</li></ul></li></ul><h2 id="受験までの過程"><a href="#受験までの過程" class="headerlink" title="受験までの過程"></a>受験までの過程</h2><p>試験範囲の内容はある程度実務として経験済みだったので、勉強期間は約2週間ほどで済みました。<br>実務の経験として主に役立った内容は、</p><ul><li>IAMの基礎知識（継承など）</li><li>IAMを最小権限に留める、IAMをグループで管理するなどのIAMのベストプラクティス</li><li>組織ポリシーいろいろ</li><li>組織・フォルダ・プロジェクトの分け方</li><li>Google Cloudのネットワーク関連<ul><li>Shared VPC</li><li>Cloud VPN</li><li>VPC Peering</li><li>Dedicated&#x2F;Partner Interconnect</li></ul></li><li>Secret Mangerによる機密情報管理やCloud KMSによる暗号鍵管理</li><li>Cloud Identityの利用</li></ul><p>などが挙げられます。</p><h3 id="利用した教材"><a href="#利用した教材" class="headerlink" title="利用した教材"></a>利用した教材</h3><p>最初に<a href="https://docs.google.com/forms/d/e/1FAIpQLSf4ADmZr8WnDZjIK6dWvRTel2VmsP0fJtONy6UOFjWZHe-MpQ/viewform?hl=ja">模擬試験</a>をやってみたところある程度いけそうな感があったので、今回はUdemyの問題集のみ利用しました。</p><ul><li><a href="https://www.udemy.com/course/google-professional-cloud-security-engineer-jp/learn/quiz/5813440/results?expanded=1040233892#reviews">Google Professional Cloud Security Engineer | 模擬試験2023年版</a></li></ul><h2 id="まとめ"><a href="#まとめ" class="headerlink" title="まとめ"></a>まとめ</h2><p>今回受験してみて、中身の仕組みをあまり理解していない状態で実務で使っていたんだなーと実感しました。特にCloud KMSはよく使っていましたが、<a href="https://cloud.google.com/kms/docs/envelope-encryption?hl=ja">Envelop encryption</a>という言葉自体を知らずに使っていました。</p><p>本受験を通して、Google CloudのCloud Securityに関する網羅的な知見を得ることができたので、業務の振り返りとしてちょうどよかったです。</p><p>Google CloudのCloud Securityに取っ掛かりを得たい方、振り返りをしたい方はぜひ受けてみてください！</p><p>アイキャッチ画像は<a href="https://cloud.google.com/learn/certification?hl=ja">Google Cloud Certification</a>から付与されたものになります。</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;img src=&quot;/images/20230921a/image.png&quot; alt=&quot;&quot; width=&quot;611&quot; height=&quot;593&quot; loading=&quot;lazy&quot;&gt;

&lt;h2 id=&quot;はじめに&quot;&gt;&lt;a href=&quot;#はじめに&quot; class=&quot;headerlink&quot;</summary>
        
      
    
    
    
    <category term="Infrastructure" scheme="https://future-architect.github.io/categories/Infrastructure/"/>
    
    
    <category term="GCP" scheme="https://future-architect.github.io/tags/GCP/"/>
    
    <category term="合格記" scheme="https://future-architect.github.io/tags/%E5%90%88%E6%A0%BC%E8%A8%98/"/>
    
    <category term="資格" scheme="https://future-architect.github.io/tags/%E8%B3%87%E6%A0%BC/"/>
    
    <category term="Udemy" scheme="https://future-architect.github.io/tags/Udemy/"/>
    
    <category term="PCSE" scheme="https://future-architect.github.io/tags/PCSE/"/>
    
  </entry>
  
  <entry>
    <title>Summer Enginner Camp 2023 参加記</title>
    <link href="https://future-architect.github.io/articles/20230920a/"/>
    <id>https://future-architect.github.io/articles/20230920a/</id>
    <published>2023-09-19T15:00:00.000Z</published>
    <updated>2023-10-02T00:07:27.510Z</updated>
    
    <content type="html"><![CDATA[<img src="/images/20230920a/computer-8037837_640.jpg" alt="" width="640" height="479"><p>こんにちは、フューチャーのサマーインターン2023 Summer Enginner Camp に参加させて頂いた高橋大翔です！</p><p>私は今回、「<strong>Goとサーバレスアーキテクチャで体験。100万台超えの大規模スマートセンサーloTプラットフォームに関わってみませんか？</strong>」というプロジェクトに参加させていただきました。</p><p>インターン生でも技術ブログに入稿出来るということで、今回のインターンに参加した経緯や参加した上で得られたことや感想等を書いていこうと思います。</p><h2 id="参加動機"><a href="#参加動機" class="headerlink" title="参加動機"></a>参加動機</h2><p>学年が上がってプログラミングも少し出来るようになってきた為実務経験を積んでみたい、という思いが強くなりインターンを考え始めました。その上で、</p><ol><li>データサイエンス or サーバーサイド の開発をしたい</li><li>個人的に Golang や Rust の開発に興味あり</li><li>実際のプロジェクトのインフラ周りを見てみたい</li><li>田舎在住なので、フルでは無くてもある程度リモートで行いたい</li></ol><p>という願望がありました。そこでインターンを探している時に、競技プログラミングで有名な AtCoder さんのサービスである AtCoder Jobs にて今回のインターンを知りました。インターンの詳細を見て、自分の願望にぴったりなプロジェクトだと思い、今回のインターンに応募させていただきました。</p><h2 id="参加前のスキル・経験"><a href="#参加前のスキル・経験" class="headerlink" title="参加前のスキル・経験"></a>参加前のスキル・経験</h2><ul><li>学部3年 工学部情報工学科</li><li>主要言語 : C++, Python, TypeScript</li><li>プログラミング歴 : 2年 (大学入学後~)</li><li>実務経験 : 無し</li></ul><p>C++ は私がはまっている競技プログラミングで使用しており、Python はデータサイエンス系で使用しており、TypeScriptは自分のwebサイトを作る時に使用した程度です。今回のインターンで主に用いる Golang は自分のwebサイトのサーバーサイドで使用した以外は経験がありませんでした。</p><p>プログラムは書けるけど、実務での開発を経験したことが無い典型的な大学生のスキルセットだったと思います。</p><p>インターンの選考は、1. ES提出, 2. コーディング試験, 3.面接 の順で行われ、競技プログラミングで培ってきた実装力でコーディング試験を結構解くことが出来たのが功を奏した気がします。AtCoderの難易度で言うと茶~緑程度 (最終問題はもっと難しかった) だったと思います。</p><h2 id="インターン概要"><a href="#インターン概要" class="headerlink" title="インターン概要"></a>インターン概要</h2><p>今回参加させていただいたプロジェクトは題の通り、100万台以上の普及されたIoTデバイスからリアルタイムで送られてくる様々な情報をさばくプラットフォームを構築するのが主な内容です。<br><a href="/articles/20230616b/">Enginner Camp 詳細</a></p><p>今回のインターンでは、<strong>ロジックからインフラ、CI&#x2F;CD等の開発環境まで幅広く触りたい</strong>という要望を取り入れてくださり、全体的に触らせて頂くことが出来ました。</p><h3 id="1週目"><a href="#1週目" class="headerlink" title="1週目"></a>1週目</h3><p>1週目は環境構築で半分以上つぶれてしまいました。というのも、Futureがセキュリティ対策がしっかりされている為、個人開発で行う時の環境構築手順に加えて、プロキシの設定だったり権限周りの設定だったりをしなくてはいけないので、とても大変でした。(ただ初めての経験だったのでそれはそれで良い経験でした。)</p><p>初のタスクは、テストの関数のロジックが良くないのでそれを直す、というシンプルなものをやらせていただきました。初めから自分が経験したことの無い「テストを回す」という環境に新鮮味を抱きながら楽しく開発をさせていただきました。</p><h3 id="2・3週目"><a href="#2・3週目" class="headerlink" title="2・3週目"></a>2・3週目</h3><p>2・3週目は実際に AWS サービスを触り、本番環境にあるデータを必要な場所に移動させるというようなタスクに携わりました。実際にAWSのコンソールに入ると、凄い量のデータやインスタンスが立ち上がっており、これが本物のサービスかと驚かされました。</p><p>実際に lambdaの処理を書いて、terraformでインスタンスの設定を書いてロジックからインフラ構築まで一通り経験させて頂き、サーバーサイドの開発として貴重な経験になりました。</p><h3 id="4週目"><a href="#4週目" class="headerlink" title="4週目"></a>4週目</h3><p>最終週は、インターン生の成果発表会があり2・3週目程は時間が取れませんでした。タスクとしては CI&#x2F;CD 周りを触らせていただき、チーム開発で負担になる review の補助をするツールの導入を行ったりしました。CI&#x2F;CDは完全に触ったことが無く、知識も疎かったのでキャッチアップするだけでかなりの時間を要してしまいました。しかし、ここから得られる知識も個人開発では到底経験出来ない新しいものが多くてとても勉強になりました。</p><h2 id="インターン中の1日"><a href="#インターン中の1日" class="headerlink" title="インターン中の1日"></a>インターン中の1日</h2><h3 id="10-00-朝会"><a href="#10-00-朝会" class="headerlink" title="10:00 ~ 朝会"></a>10:00 ~ 朝会</h3><p>私のプロジェクトでは、業務開始前に「朝会」というものがあり、ここでは前日の進捗・今日やること・その他共有しておきたいこと等を簡単に言い合う場があります。<br>これに参加することで、すべきことが浮き彫りになる &amp; 周りの状況を把握出来る のでとても仕事効率が良くなる会だなと思いました。</p><h3 id="10-30-業務開始"><a href="#10-30-業務開始" class="headerlink" title="10:30 ~ 業務開始"></a>10:30 ~ 業務開始</h3><p>Slack に作業スレッドを貼り、そこに今現在行っていることを書きつつ作業を進めます。たまに他の人のスレッドを見に行ってみると、他の人の状況が伺えて少し面白いです。</p><h3 id="昼休憩-適宜"><a href="#昼休憩-適宜" class="headerlink" title="昼休憩 (適宜)"></a>昼休憩 (適宜)</h3><p>私のプロジェクトでは、特にこの時間帯が休憩時間という決まりは無く、全体で1時間分の休憩がある感じでした。自分は昼休憩以外にもこまめに休憩を取る方が生産性が高かったのでそうしていました。</p><h3 id="休憩後-業務再開"><a href="#休憩後-業務再開" class="headerlink" title="休憩後 業務再開"></a>休憩後 業務再開</h3><p>タスクの続きを頑張ります。</p><h3 id="19-00-業務終了"><a href="#19-00-業務終了" class="headerlink" title="~19:00 業務終了"></a>~19:00 業務終了</h3><p>日報と勤怠関係を登録して一日の終了です。<br>(2,3週目は完全にリモートで行っていましたが、退勤の入力を済ませたらすぐに自分のことに取り組めるのでとても快適で最高でした。)</p><h2 id="インターンで学べたこと"><a href="#インターンで学べたこと" class="headerlink" title="インターンで学べたこと"></a>インターンで学べたこと</h2><h3 id="チーム開発のフロー"><a href="#チーム開発のフロー" class="headerlink" title="チーム開発のフロー"></a>チーム開発のフロー</h3><p>私はチーム開発の経験が、大学のプログラミングサークルで少々やっている程度しかなく、実務でのチーム開発経験が無かったので色々なことが初めてで学びになりました。</p><p>例えば moduleやwrapperの作成・運用を積極的に行ったり、命名規則に注意を払ったりと、<strong>可読性・再利用性・保守性の高いプログラムの作成</strong>の重要性を理解することが出来ました。<br>また、Githubでの開発フロー (issue,branch,pull request,…) にもなれることが出来たり、CI&#x2F;CD 周りを触らせてもらってそこらへんに対する理解も深めることが出来ました。</p><h3 id="AWS-主に-lambda-S3-dynamoDB-terraform"><a href="#AWS-主に-lambda-S3-dynamoDB-terraform" class="headerlink" title="AWS (主に lambda,S3,dynamoDB), terraform"></a>AWS (主に lambda,S3,dynamoDB), terraform</h3><p>インフラ関連の学びも多々ありました。インフラ周りはちっぽけな個人開発で少し触れたことのある程度で、実際のプロジェクトではどのように運用されているかを見たいというのが自分の願望の1つだったのでとても貴重な経験でした。</p><p>実際にlambdaのロジックをGolangで書いてterraformでインスタンスの設定をして…というインフラ周りの一連の流れを触らせていただいたので、今まであまり浮かばなかったイメージを鮮明にすることが出来ました。</p><h3 id="業務の共有-表現力"><a href="#業務の共有-表現力" class="headerlink" title="業務の共有 (表現力)"></a>業務の共有 (表現力)</h3><p>私はインターン中に何回か社員の方から頂いたタスクの認識がずれてしまうことがありました。その為タスクを頂いた時は、ずれが起きないようにタスクを貰った直後に自分の言い換え表現で確認を取るようにしていました。</p><p>また、疑問点を社員の方に聞く際も、初めは業務の妨げになってしまうのではと思い少し躊躇っていましたが、最終的には分からなかったら聞くことが一番効率的であり同時に自分の認識のずれも抑えられる為、積極的に聞くようにしていました。</p><p>自分の頭の中の認識を他者に分かりやすく伝えることの重要性を学ぶことが出来ました。</p><h2 id="終わりに"><a href="#終わりに" class="headerlink" title="終わりに"></a>終わりに</h2><p>今回のインターンは私にとって初めての実務経験ということで、非常に貴重な経験になったと同時に、インフラ周りや開発のフロー等、様々な学びを得ることが出来ました。また他のインターン生も向上心が高く、プログラミングといっても色々な分野に秀でている方が沢山いてそれも刺激になり、一回り成長することが出来た機会となりました。</p><p>今回インターンとして受け入れてくださったフューチャーさん、受け入れ先で支えていただいた社員の方々、共に1カ月間を過ごしたインターンの同期の方々、ありがとうございました！</p><p>アイキャッチは<a href="https://pixabay.com/ja/users/thedigitalartist-202249/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=8037837">Pete Linforth</a>による<a href="https://pixabay.com/ja//?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=8037837">Pixabay</a>からの画像です。</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;img src=&quot;/images/20230920a/computer-8037837_640.jpg&quot; alt=&quot;&quot; width=&quot;640&quot; height=&quot;479&quot;&gt;

&lt;p&gt;こんにちは、フューチャーのサマーインターン2023 Summer Enginner Camp</summary>
        
      
    
    
    
    <category term="Programming" scheme="https://future-architect.github.io/categories/Programming/"/>
    
    
    <category term="インターン" scheme="https://future-architect.github.io/tags/%E3%82%A4%E3%83%B3%E3%82%BF%E3%83%BC%E3%83%B3/"/>
    
    <category term="インターン2023" scheme="https://future-architect.github.io/tags/%E3%82%A4%E3%83%B3%E3%82%BF%E3%83%BC%E3%83%B32023/"/>
    
    <category term="エンジニア" scheme="https://future-architect.github.io/tags/%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2/"/>
    
  </entry>
  
  <entry>
    <title>Prompt Flowでプロンプト評価の管理を行う</title>
    <link href="https://future-architect.github.io/articles/20230919a/"/>
    <id>https://future-architect.github.io/articles/20230919a/</id>
    <published>2023-09-18T15:00:00.000Z</published>
    <updated>2023-10-02T00:07:27.510Z</updated>
    
    <content type="html"><![CDATA[<h1 id="はじめに"><a href="#はじめに" class="headerlink" title="はじめに"></a>はじめに</h1><div class="note warn" style="background: #fdf9e2; padding:16px; margin:24px 12px; border-radius:8px;">  <span class="fa fa-fw fa-check-circle"></span><p>本記事は、プレビュー版のAzure Prompt Flowを扱っています。</p><p>操作画面等の内容は2023年9月13日現在の内容であることにご注意ください。</p></div><p>こんにちは、SAIG&#x2F;MLOpsチームでアルバイトをしている板野です。</p><p>今回は、AzureのPrompt Flowを使ってLLMに入力するプロンプト評価の管理を行います。</p><p>プロンプト評価の管理を行いたい背景として、以下のような状況が考えられます。</p><ul><li>チーム内で我流のプロンプトがはびこっている</li><li>プロンプト・出力・評価値をスプレッドシートに手入力するのが煩わしくなってきた</li><li>良いプロンプトとその評価結果が結びついておらず、「あのプロンプト良かったけどどこ行った？」となる</li></ul><p>このような状況を改善するため、客観的・定量的なプロンプト評価を行い、管理していきたいところです。</p><p>すなわち、 <strong>プロンプトの実験管理</strong> が行いたいのです。</p><p>例えば、複数の評価指標を自動で算出し、以下のような表形式にして任意の評価指標に対してソートできればプロンプトの実験管理の効率が向上します。</p><div class="scroll"><table><thead><tr><th>プロンプト</th><th>評価指標A</th><th>評価指標B</th><th>評価指標C</th></tr></thead><tbody><tr><td>プロンプト01</td><td>9.6</td><td>8.9</td><td>1</td></tr><tr><td>プロンプト02</td><td>8.5</td><td>7.8</td><td>1</td></tr><tr><td>プロンプト03</td><td>6.3</td><td>7.7</td><td>0</td></tr></tbody></table></div><p>今回はこのような表を自動で得られるようにすることを目標とします。</p><p>LLMには、追加学習による精度の改善だけでなく、入力するプロンプトの改善による精度向上の余地があります。</p><p>今回は、通常の機械学習の実験管理とは異なり、LLM, プロンプトの2変数のうち、LLMを固定します。仮に精度が向上した場合、それが「LLMを改善したから」なのか「プロンプトを改善したから」なのかが分からなくなってしまうからです。</p><div class="note info" style="background: #e5f8e2; padding:16px; margin:24px 12px; border-radius:8px;">  <span class="fa fa-fw fa-check-circle"></span><p>本記事ではプロンプトという用語を「システムプロンプト」の意味で使っています。すなわち、（ユーザーからの）質問文は最終的にはプロンプトに含まれることにはなりますが、ここでは質問文をプロンプトとは別の要素として扱います。</p></div><h1 id="プロンプトの評価"><a href="#プロンプトの評価" class="headerlink" title="プロンプトの評価"></a>プロンプトの評価</h1><h2 id="プロンプトの評価に必要なもの"><a href="#プロンプトの評価に必要なもの" class="headerlink" title="プロンプトの評価に必要なもの"></a>プロンプトの評価に必要なもの</h2><p>以下の4つが全て揃えば大体どんな評価もできます。</p><p>最低限*印の項目があればそれなりの評価ができます。</p><ul><li>質問文*</li><li>LLMの回答*</li><li>理想の回答</li><li>コンテキスト</li></ul><h2 id="プロンプトの評価指標例"><a href="#プロンプトの評価指標例" class="headerlink" title="プロンプトの評価指標例"></a>プロンプトの評価指標例</h2><p>プロンプトの評価指標は、原則「プロジェクト・タスクによりけり」です。</p><p>ここでは評価指標を定めるための参考として、いくつか事例を集めたので以下にご紹介します。</p><h3 id="事例①-Prompt-Flowの組み込み評価指標"><a href="#事例①-Prompt-Flowの組み込み評価指標" class="headerlink" title="事例①: Prompt Flowの組み込み評価指標"></a>事例①: Prompt Flowの組み込み評価指標</h3><p>AzureのPrompt Flowにはいくつか組み込みの評価指標が用意されています。</p><p>このうちの大半はLLMが評価を下す仕組みとなっています。</p><img src="/images/20230919a/Alt_text.png" alt="Alt_text" width="1200" height="540" loading="lazy"><p><a href="https://speakerdeck.com/nohanaga/azure-machine-learning-prompt-flow-ping-jia-metorikusujie-shuo?slide=8">Source</a></p><p>例えば、「以下に質問と回答の対を示します。回答は質問の内容に沿っているか10段階で評価してください」といったプロンプトを入力するとLLMが評価値を返してくれます。</p><p>LLMベースの評価は、プロンプト次第であらゆる評価結果を数値として出力してくれるでしょう。</p><p>しかし、LLMは確率モデルであるという特性上、同じ入力をすると必ず同じ評価値が返ってくる保証はありません。何度か同じ入力をして得られた評価値の統計（平均値や中央値など）を取ることで、多少はLLMのばらつきを抑えられる可能性があります。</p><p>[参考]</p><ul><li><a href="https://speakerdeck.com/nohanaga/azure-machine-learning-prompt-flow-ping-jia-metorikusujie-shuo">Azure Machine Learning Prompt flow 評価メトリクス解説</a></li><li><a href="https://qiita.com/nohanaga/items/b68bf5a65142c5af7969">Azure Machine Learning の Prompt flow の評価メトリクス紹介 ― ChatGPT どう評価する？</a></li></ul><h3 id="事例②-Pythonのみで実装できる独自定義の評価指標"><a href="#事例②-Pythonのみで実装できる独自定義の評価指標" class="headerlink" title="事例②: Pythonのみで実装できる独自定義の評価指標"></a>事例②: Pythonのみで実装できる独自定義の評価指標</h3><p>こちらの事例では、Prompt Flowを使ってPythonのみで実装できる評価指標を実装しています。</p><p>「決算書のPDFから必要なデータをJSON形式で抽出する」タスクに対し、以下の2つの評価指標を定めています。</p><ul><li><code>correct_keys_percentage</code>: 正しく抽出できたキーの割合</li><li><code>correct_values_percentage</code>: 抽出したキーのうち、正しく抽出できた値の割合</li></ul><p>[参考]</p><ul><li><a href="https://qiita.com/sakue_103/items/41d14e96a253a820bc0f">Prompt Flowでプロンプトを定量的に評価する</a></li></ul><h1 id="Prompt-Flowでプロンプト評価の管理を行う"><a href="#Prompt-Flowでプロンプト評価の管理を行う" class="headerlink" title="Prompt Flowでプロンプト評価の管理を行う"></a>Prompt Flowでプロンプト評価の管理を行う</h1><h2 id="取り扱うタスク"><a href="#取り扱うタスク" class="headerlink" title="取り扱うタスク"></a>取り扱うタスク</h2><p>今回は文書検索を伴う質疑応答タスクを扱います。</p><p>文書検索を伴う質疑応答用のフロー（標準フロー）は実装済みであるとします。文書検索を伴う質疑応答用のフローを作るには<a href="https://qiita.com/nohanaga/items/7c8b797f20ab8a3d5c92">こちらの記事</a>が参考になりますので、ご参照ください。</p><p>どんな内容であれ、「質問文」に対する「LLMの回答」が得られる標準フローが作成できていればOKです。</p><p>この標準フローのプロンプトを評価するために、評価フローと呼ばれるフローを別途実装していきます。</p><h2 id="評価指標"><a href="#評価指標" class="headerlink" title="評価指標"></a>評価指標</h2><p>文書検索を伴う質疑応答フローの評価指標として以下の3点を定めます。</p><ul><li>(A)<code>consistency</code>: 質問の内容に沿った回答ができているか（1~10の整数値）</li><li>(B)<code>easiness</code>: 簡単な表現で分かりやすいか（1~10の整数値）</li><li>(C)<code>has_source</code>: ソースの参照を行っているか（2値）</li></ul><p>(A)(B)は、先の事例①を参考にLLMベースの評価指標を作成します。</p><p>(C)については、先の事例②を参考にPythonのみで実装できるものを作成します。</p><h2 id="Prompt-Flowでプロンプト評価の管理を行う-1"><a href="#Prompt-Flowでプロンプト評価の管理を行う-1" class="headerlink" title="Prompt Flowでプロンプト評価の管理を行う"></a>Prompt Flowでプロンプト評価の管理を行う</h2><h3 id="①評価フローを実装する"><a href="#①評価フローを実装する" class="headerlink" title="①評価フローを実装する"></a>①評価フローを実装する</h3><p>ここからは実際にPrompt Flowを使ってプロンプト自動評価の仕組みを実装していきます。</p><p>Prompt Flowでは標準フローではなく、評価フローと呼ばれるフローを実装していきます。</p><img src="/images/20230919a/01.png" alt="" width="1200" height="346" loading="lazy"><p>今回実装した評価フローの概略です。</p><img src="/images/20230919a/image.png" alt="" width="1200" height="725" loading="lazy"><p>以下、入出力および各要素について説明します。</p><h4 id="入力-inputs"><a href="#入力-inputs" class="headerlink" title="入力(inputs)"></a>入力(inputs)</h4><p>入力は以下のように設定します。値は任意の値でOKです。</p><p><code>question</code>は質問文、<code>answer</code>はLLMの回答を表します。</p><img src="/images/20230919a/image-2.png" alt="" width="1200" height="311" loading="lazy"><p><code>line_number</code>と<code>variant_id</code>についてはAzureのドキュメントに以下のような記載がありました。</p><p>標準フローと違い評価フローは特殊なので、これらの入力もを用意する必要があるようです。</p><p>長くなるのでlineとvariantについての説明は省略しますが、詳細は以下のソースをご覧ください。</p><blockquote><p>標準フローとは異なり、評価方法はテストされているフローの後で実行され、複数のバリアントが含まれる場合があります。<br> したがって、評価では、出力の生成元になったデータ サンプルやバリアントなど、一括テストで受け取ったフロー出力のソースを区別する必要があります。<br>一括テストで使用できる評価方法を構築するには、line_number と variant_id(s) の 2 つの追加入力が必要です。</p></blockquote><p><a href="https://learn.microsoft.com/ja-jp/azure/machine-learning/prompt-flow/how-to-develop-an-evaluation-flow?view=azureml-api-2">Source</a></p><h4 id="calc-consistency"><a href="#calc-consistency" class="headerlink" title="calc_consistency"></a>calc_consistency</h4><p>LLMを使って「質問に対する回答の一貫性」を評価する部分です。<code>質問文</code>と<code>LLMの回答</code>を入力として受け取り、評価値を1から10の10段階で返します。</p><p>プロンプトの中では、いくつか例示(Few-shot Learning)をしています。</p><p>実装は以下画像の通りです。</p><img src="/images/20230919a/image-3.png" alt="image" width="1200" height="822" loading="lazy"><details><summary>プロンプト例</summary><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">system:</span><br><span class="line">質問と回答の対を受け取り、質問の内容に沿った回答ができているかを10段階で評価してください。</span><br><span class="line">評価の値が低いほど質問の内容に沿っていない回答であり、高いほど質問に沿った回答であるとする。</span><br><span class="line">評価は必ず1,2,3,4,5,6,7,8,9,10のいずれかであること。</span><br><span class="line"></span><br><span class="line">質問：明日の天気は？</span><br><span class="line">回答：明日は晴れです。</span><br><span class="line">評価：10</span><br><span class="line"></span><br><span class="line">質問：日本の首都は？</span><br><span class="line">回答：東京にはビルがたくさんあります。</span><br><span class="line">評価：4</span><br><span class="line"></span><br><span class="line">質問：今日の天気は？</span><br><span class="line">回答：映画館でポップコーンが食べられます。</span><br><span class="line">評価：1</span><br><span class="line"></span><br><span class="line">user:</span><br><span class="line">質問：&#123;&#123;question&#125;&#125;</span><br><span class="line">回答：&#123;&#123;answer&#125;&#125;</span><br><span class="line">評価：</span><br></pre></td></tr></table></figure></details><h4 id="calc-easiness"><a href="#calc-easiness" class="headerlink" title="calc_easiness"></a>calc_easiness</h4><p>LLMを使って「回答の分かりやすさ」を評価する部分です。<code>質問文</code>と<code>LLMの回答</code>を入力として受け取り、評価値を1から10の10段階で返します。</p><p>実装は<code>calc_consistency</code>と同様です。</p><img src="/images/20230919a/image_(1).png" alt="" width="1200" height="699" loading="lazy"><details><summary>プロンプト例</summary><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">system:</span><br><span class="line">質問と回答の対を受け取り、回答の分かりやすさを10段階で評価してください。</span><br><span class="line">評価の値が低いほど分かりにくい難解な回答であり、高いほど分かりやすい回答であるとする。</span><br><span class="line">評価は必ず1,2,3,4,5,6,7,8,9,10のいずれかであること。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">質問：東京とは？</span><br><span class="line">回答：日本の首都です。東京にはネオンに照らされた超高層ビルから歴史的な寺院まで、超現代的なものと伝統的なものが混在しています。</span><br><span class="line">評価：3</span><br><span class="line"></span><br><span class="line">質問：東京とは？</span><br><span class="line">回答：東京は、江戸幕府の所在地であった江戸（えど）という都市が1868年9月（慶応4年7月）に名称変更されたものである。</span><br><span class="line">評価：2</span><br><span class="line"></span><br><span class="line">質問：東京とは？</span><br><span class="line">回答：日本の首都です。たくさんのビルが立ち並んでいますが、昔のお寺などもたくさんあって面白い場所です。</span><br><span class="line">評価：10</span><br><span class="line"></span><br><span class="line">user:</span><br><span class="line">質問：&#123;&#123;question&#125;&#125;</span><br><span class="line">回答：&#123;&#123;answer&#125;&#125;</span><br><span class="line">評価：</span><br></pre></td></tr></table></figure></details><h4 id="has-source"><a href="#has-source" class="headerlink" title="has_source"></a>has_source</h4><p>「回答がソース(文書)を参照できているか」を評価する部分です。<code>質問文</code>と<code>LLMの回答</code>を入力として受け取り、できていれば<code>1</code>, できていなければ<code>0</code>を返します。</p><p>アルゴリズムは非常に簡単で、回答に”source”という文字列が含まれていればソース参照できていると判定します。</p><p>以下のようにPythonコードのみで実装しています。</p><p>※手順解説のため、サンプルとして簡易なロジックを実装</p><img src="/images/20230919a/image_(2).png" alt="" width="1200" height="466" loading="lazy"><details><summary>コード例</summary><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> promptflow <span class="keyword">import</span> tool</span><br><span class="line"></span><br><span class="line"><span class="meta">@tool</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">check_source</span>(<span class="params">question: <span class="built_in">str</span>, answer: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line"></span><br><span class="line">  <span class="comment"># &#x27;source&#x27;という文字列がanswerに含まれていれば1,含まれていなければ0を返す</span></span><br><span class="line"></span><br><span class="line">  result = <span class="number">0</span></span><br><span class="line">  <span class="keyword">if</span> <span class="string">&#x27;source&#x27;</span> <span class="keyword">in</span> answer.lower():</span><br><span class="line">    result = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure></details><h4 id="line-process"><a href="#line-process" class="headerlink" title="line_process"></a>line_process</h4><p><code>calc_consistency</code>, <code>calc_easiness</code>, <code>has_source</code>の各出力を集約し、1つの辞書型として出力するPythonコードです。</p><img src="/images/20230919a/image_(3).png" alt="image_(3).png" width="1200" height="509" loading="lazy"><details><summary>コード例</summary><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> promptflow <span class="keyword">import</span> tool</span><br><span class="line"></span><br><span class="line"><span class="meta">@tool</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">line_process</span>(<span class="params">consistency: <span class="built_in">str</span>, easiness: <span class="built_in">str</span>, has_source: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line"></span><br><span class="line">  result_dic = &#123;&#125;</span><br><span class="line">  result_dic[<span class="string">&#x27;consistency&#x27;</span>] = <span class="built_in">int</span>(consistency)</span><br><span class="line">  result_dic[<span class="string">&#x27;easiness&#x27;</span>] = <span class="built_in">int</span>(easiness)</span><br><span class="line">  result_dic[<span class="string">&#x27;has_source&#x27;</span>] = <span class="built_in">int</span>(has_source)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> result_dic</span><br></pre></td></tr></table></figure></details><h4 id="aggregate-variants-results"><a href="#aggregate-variants-results" class="headerlink" title="aggregate_variants_results"></a>aggregate_variants_results</h4><p>Variant毎に結果を集約するPythonコードです。</p><p>今回はVariant機能を使っていませんが、評価フローでは、集約（Aggregation）を行うための特別なPythonコードを定義する必要があるので<a href="https://learn.microsoft.com/en-us/azure/machine-learning/prompt-flow/how-to-develop-an-evaluation-flow?view=azureml-api-2#metrics-logging-and-aggregation-node">公式ドキュメント(英語)</a>を参考に、以下のように実装しました。</p><img src="/images/20230919a/image_(4).png" alt="" width="1200" height="862" loading="lazy"><details><summary>コード例</summary><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span></span><br><span class="line"><span class="keyword">from</span> promptflow <span class="keyword">import</span> tool, log_metric</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@tool</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">aggregate_variants_results</span>(<span class="params">variant_ids: <span class="type">List</span>[<span class="built_in">int</span>], line_numbers: <span class="type">List</span>[<span class="built_in">int</span>], result_dics: <span class="type">List</span>[<span class="built_in">dict</span>]</span>):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># バリアント毎にlinesを集約する</span></span><br><span class="line">    results_on_each_variant = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(result_dics)):</span><br><span class="line">        result_dic = result_dics[i]</span><br><span class="line">        variant_id = variant_ids[i]</span><br><span class="line">        <span class="keyword">if</span> variant_id <span class="keyword">not</span> <span class="keyword">in</span> results_on_each_variant.keys():</span><br><span class="line">            results_on_each_variant[variant_id] = []</span><br><span class="line">        results_on_each_variant[variant_id].append(result_dic)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 各バリアントについてlinesを集約する</span></span><br><span class="line">    <span class="keyword">for</span> variant_id, result_dics <span class="keyword">in</span> results_on_each_variant.items():</span><br><span class="line"></span><br><span class="line">        avg_result_dic = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(result_dics)):</span><br><span class="line">            <span class="keyword">for</span> score_name, score <span class="keyword">in</span> result_dics[i].items():</span><br><span class="line">                <span class="keyword">if</span> score_name <span class="keyword">not</span> <span class="keyword">in</span> avg_result_dic:</span><br><span class="line">                    avg_result_dic[score_name] = score</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    avg_result_dic[score_name] += score</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 平均を取る</span></span><br><span class="line">        <span class="keyword">for</span> score_name, sum_score <span class="keyword">in</span> avg_result_dic.items():</span><br><span class="line">            avg_score = <span class="built_in">round</span>((sum_score / <span class="built_in">len</span>(result_dics)), <span class="number">2</span>)</span><br><span class="line">            avg_result_dic [score_name] = avg_score</span><br><span class="line"></span><br><span class="line">        <span class="comment"># log_metricを呼び出す</span></span><br><span class="line">        <span class="keyword">for</span> score_name, avg_score <span class="keyword">in</span> avg_result_dic.items():</span><br><span class="line">            log_metric(score_name, avg_score, variant_id=variant_id)</span><br><span class="line"></span><br><span class="line">        results_on_each_variant[variant_id] = avg_result_dic</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> results_on_each_variant</span><br></pre></td></tr></table></figure></details><h4 id="出力-outputs"><a href="#出力-outputs" class="headerlink" title="出力(outputs)"></a>出力(outputs)</h4><p>出力は以下のように設定します。</p><img src="/images/20230919a/image-4.png" alt="" width="1200" height="223" loading="lazy"><p>最後に右上の「保存」を押して評価フローの作成は完了です。</p><p>この時点で、「質問文」と「LLMの回答」を入力した際、<code>consistency</code>, <code>easiness</code>, <code>has_source</code>の3つの評価指標の値を出してくれる評価フローが出来上がりました。</p><h3 id="②評価フローを実行する"><a href="#②評価フローを実行する" class="headerlink" title="②評価フローを実行する"></a>②評価フローを実行する</h3><p>それでは、実際に評価を行っていきます。</p><p>文書検索を伴う質疑応答用のフロー（標準フロー）の編集画面に入り、「一括テスト」を押します。</p><p>以下の画面では一括テストの設定を編集します。一括テストとは、複数の質問文を一括で受けつけて回答を出力してくれる機能です。</p><img src="/images/20230919a/image-6.png" alt="image-6.png" width="1200" height="701" loading="lazy"><p>データは自分で以下のようなCSVファイルを作成し、アップロードします。<br>下例のようにあらゆるケースの質問文を用意したり、同じ質問文を複数記載して結果（評価値）の平均をとってLLMによるばらつきに対処したりもできます。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">question</span><br><span class="line">北条政子って何をした人？</span><br><span class="line">源頼朝って何をした人？</span><br><span class="line">源義経って何をした人？</span><br><span class="line">徳川家康って何をした人？</span><br><span class="line">小泉純一郎って何をした人？</span><br></pre></td></tr></table></figure><p>続いて、評価の設定を編集します。</p><p>評価方法の選択では、先程作成した評価フローを選択します。</p><p>評価入力マッピングの部分について、<code>question</code>のデータソースは<code>data.question</code>を選択します。これは一括テストの設定でアップロードしたCSVファイルのquestion列のデータに相当します。<code>answer</code>のデータソースは<code>output.answer</code>を選択します。これはLLMからの出力に相当します。</p><img src="/images/20230919a/02.png" alt="" width="1200" height="710" loading="lazy"><p>「次へ」を押すとレビューの画面が出ますが、最終確認の画面なので問題なければ「送信」を押します。</p><p>別のプロンプトで実行したい場合は、プロンプトを変えて以上の操作を繰り返します。</p><p>フロー編集画面上部の「一括実行の表示」を押すと過去の実行が見られます。</p><img src="/images/20230919a/image-8.png" alt="" width="473" height="74" loading="lazy"><p>過去の実行は以下のようにリスト化されています。</p><p>ここで、いくつかの実行をチェックボックスで選択し、「メトリックの比較」を押してみましょう。</p><img src="/images/20230919a/03.png" alt="" width="1200" height="415" loading="lazy"><p>すると、以下のように各実行に対する評価指標を比較することができます。</p><p>もちろん、任意の評価指標についてソートすることもできます。</p><img src="/images/20230919a/04.png" alt="" width="1200" height="268" loading="lazy"><p>以上で今回目標としていたことが達成できました。</p><h3 id="補足"><a href="#補足" class="headerlink" title="補足"></a>補足</h3><p>本来であればVariant機能を使って複数のプロンプトを一括で評価したいところです。</p><p>しかし、Variant機能を使って実行しようとしたところ、記事執筆当時(2023年9月13日)では下図のように列方向に展開されてしまい、結果の比較が行いにくいと感じました。</p><img src="/images/20230919a/image-10.png" alt="image-10.png" width="1200" height="210" loading="lazy"><p>このため今回はVariant機能を使わず、プロンプトを変える毎に逐一実行する方法を取りました。</p><p>Prompt Flowのプレビュー版が終わり完成版が登場する頃には改善されているかもしれないので、今後に期待です。</p><h1 id="おわりに"><a href="#おわりに" class="headerlink" title="おわりに"></a>おわりに</h1><p>本記事ではPrompt Flowでプロンプトの実験管理を行う方法をご紹介しました。</p><p>LLMの開発や運用に携わっている方々の参考となれば幸いです。</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h1 id=&quot;はじめに&quot;&gt;&lt;a href=&quot;#はじめに&quot; class=&quot;headerlink&quot; title=&quot;はじめに&quot;&gt;&lt;/a&gt;はじめに&lt;/h1&gt;&lt;div class=&quot;note warn&quot; style=&quot;background: #fdf9e2; padding:16px;</summary>
        
      
    
    
    
    <category term="DataScience" scheme="https://future-architect.github.io/categories/DataScience/"/>
    
    
    <category term="Azure" scheme="https://future-architect.github.io/tags/Azure/"/>
    
    <category term="LLM" scheme="https://future-architect.github.io/tags/LLM/"/>
    
    <category term="LLMOps" scheme="https://future-architect.github.io/tags/LLMOps/"/>
    
    <category term="Prompt Flow" scheme="https://future-architect.github.io/tags/Prompt-Flow/"/>
    
  </entry>
  
  <entry>
    <title>【合格記】Google Cloud Professional Data Engineer認定資格を振り返る【2023年度版】</title>
    <link href="https://future-architect.github.io/articles/20230915a/"/>
    <id>https://future-architect.github.io/articles/20230915a/</id>
    <published>2023-09-14T15:00:00.000Z</published>
    <updated>2023-10-02T00:07:27.509Z</updated>
    
    <content type="html"><![CDATA[<img src="/images/20230915a/image.png" alt="" width="599" height="586" loading="lazy"><h2 id="はじめに"><a href="#はじめに" class="headerlink" title="はじめに"></a>はじめに</h2><p>TIG 岸下です。</p><p>最近Data Engineeringを扱うプロジェクトへ異動したこともあり、Google CloudにおけるData Engineeringを網羅的に学びたく、Professional Data Engineer認定資格を受けてきました。結果として、無事に合格を果たすことができました。</p><p>本記事では学習内容などの過程を書いていこうと思います。</p><p>また本試験はGoogle Cloudパートナー企業向けのバウチャーを活用して受験しました。大変感謝しております！</p><p>過去記事：</p><ul><li><a href="https/articles/20211013a/">【合格記】Google Cloud Professional Data Engineer認定資格を振り返る</a></li></ul><p>Google Cloud 認定資格関連の過去記事：</p><ul><li><a href="/articles/20220930a/">【合格記】Google Cloud Professional Machine Learning Engineer認定資格を振り返る</a></li><li><a href="/articles/20220411a/">Google Cloud Professional Cloud Architectの再認定に合格しました</a></li><li><a href="/articles/20200902/">GCP Professional Cloud Network Engineer に合格しました</a></li><li><a href="/articles/20210625a/">GCP Associate Cloud Engineer 合格記</a></li></ul><h2 id="試験と出題範囲"><a href="#試験と出題範囲" class="headerlink" title="試験と出題範囲"></a>試験と出題範囲</h2><p><a href="https://cloud.google.com/certification/data-engineer?hl=ja">公式</a>の出題範囲と、実際の試験内容の所感は以下になります。</p><h3 id="データ処理システムの設計"><a href="#データ処理システムの設計" class="headerlink" title="データ処理システムの設計"></a>データ処理システムの設計</h3><ul><li>データの前処理を行ううえでどのようなアーキテクチャ・サービスが推奨されるか？<ul><li>ローコード・ノーコードで前処理したい<ul><li>DataprepやData Fusion</li></ul></li><li>Kubernetesを利用したオーケストレーションの活用<ul><li>Cloud Composer</li></ul></li></ul></li><li>データの受け口にキューイングシステムであるPubSubを構えておくのが鉄板</li><li>データベースの用途は何なのか？取り扱うデータは？時系列？トランザクション？<ul><li>用途によって、DBのサービスを選ぶ</li><li>Cloud SQL&#x2F;Bigtable&#x2F;Firestore&#x2F;Spannerどれを選ぶべきか</li></ul></li><li>サーバーレスでSQL使いたい？データウェアハウスを構築したい？<ul><li>BigQuery使おう</li></ul></li><li>BigQueryとPubSubが優秀<ul><li>回答に困ったらとりあえずBigQueryかPubSubが入っている選択肢を選ぶというくらいにBigQueryとPubSubが強すぎる感（主観）</li><li>特にBigQueryは別格感ありますね。実務でも使い倒されてます。</li></ul></li></ul><h3 id="機械学習モデルの運用化"><a href="#機械学習モデルの運用化" class="headerlink" title="機械学習モデルの運用化"></a>機械学習モデルの運用化</h3><ul><li>モデルが過学習している場合はどうするか？<ul><li>データを増やす</li><li>正規化する</li><li>学習パラメータを減らす</li></ul></li><li>欠損値を含む場合はどうするか？<ul><li>ノーコードで除去したい場合はDataprep</li><li>DataflowでBigQueryを前処理として組み込む手もある</li></ul></li><li>機械学習モデルの学習処理を早く終わらせたい場合はどうするか？<ul><li>GPUが使えるフレームワークであれば、GPU搭載インスタンスの利用</li></ul></li><li>クライアントが解決したい課題はどのモデルを使うべきか<ul><li>回帰問題&#x2F;分類問題を理解しておく</li></ul></li><li>機械学習モデルの運用方法<ul><li>学習の自動化</li><li>データセットの監視・管理</li></ul></li></ul><h3 id="ソリューションの品質の確保"><a href="#ソリューションの品質の確保" class="headerlink" title="ソリューションの品質の確保"></a>ソリューションの品質の確保</h3><ul><li>適切なアラート設計<ul><li>何を指標としたアラートを設計すべきか？</li></ul></li><li>システムの可用性はどうあるべきか<ul><li>ゾーナル&#x2F;リージョナル&#x2F;マルチリージョナル</li><li>レプリカの活用</li></ul></li><li>Dataflowなどにおける処理遅延に対するトラブルシューティング<ul><li>適切なノードのスケールアップ</li></ul></li><li>法規制に対応するためのデータの置き方<ul><li>1プロジェクトにデータを集約させるデータレイクのような形をとっておく</li></ul></li><li>適切なログの集約・保管<ul><li>Log sinkやログバケットの活用</li><li>検索性を高めたいのであればBigQueryへシンク</li></ul></li></ul><h3 id="データ処理システムの構築と運用化"><a href="#データ処理システムの構築と運用化" class="headerlink" title="データ処理システムの構築と運用化"></a>データ処理システムの構築と運用化</h3><ul><li>複数のリソースからデータを参照したい場合のDB・ストレージの選択</li><li>IAMを利用したデータのアクセス制限<ul><li>プロジェクトレベルのIAM</li><li>データセットレベルのIAM</li><li>テーブルの列レベルのIAM</li></ul></li><li>Cloud DLPを利用した機密情報の保護<ul><li>暗号化した情報は復元できるようにしておく必要がある or Not?</li></ul></li></ul><h2 id="受験までの過程"><a href="#受験までの過程" class="headerlink" title="受験までの過程"></a>受験までの過程</h2><p>勉強期間は約1か月ほどで、主に以下2つの教材を利用しました。</p><ul><li>Google Cloud Skills Boost for Partners<ul><li><a href="https://go.cloudplatformonline.com/ODA4LUdKVy0zMTQAAAGLnYP9oegPUvBCNvLo78WmEQiM_CnVxjPXmx9ZG9q4pL9Bk0xJ1_vowa60C6W4Qm_6JFo07i8=">Create and Manage Cloud Resources</a></li><li><a href="https://go.cloudplatformonline.com/ODA4LUdKVy0zMTQAAAGLnYP9oUG5zPOW9QIHqa1spOv9I4AzHhHRS34gabCSyuSdn6Aa3zIPRpEex1uthLSuBtNJiSM=">Perform Foundational Data, ML and AI Tasks in Google Cloud</a></li><li><a href="https://go.cloudplatformonline.com/ODA4LUdKVy0zMTQAAAGLnYP9oZY0kQV0dpn8ANn8j0ArOZiyxYzkn_yNbnbe_Av40gu0nqSxLYUw7WT_K-QYO8_De6I=">Engineer Data in Google Cloud</a></li></ul></li><li>Udemy<ul><li><a href="https://www.udemy.com/share/109eq23@8q8wUTalxAxhRgFfWbEgH1c3mbjL7aXRRw7dpbqd0PHnoLq-HnSq5UGeaHyEwA0e/">GCP : Google Cloud Professional Data Engineer Practice Tests</a></li></ul></li></ul><h3 id="Google-Cloud-Skills-Boost-for-Partners"><a href="#Google-Cloud-Skills-Boost-for-Partners" class="headerlink" title="Google Cloud Skills Boost for Partners"></a>Google Cloud Skills Boost for Partners</h3><p>こちらの教材は、Google CloudにおけるData Engineeringをハンズオン形式で構築しながら学ぶことができます。<br>例えば、</p><ul><li>CSV形式のデータセットに対して、欠損値や外れ値などをDataprepやDataFusionを利用してデータクレンジングを行う</li><li>BigQueryを利用して前処理を施した後に、BigQuery MLを利用して機械学習モデルを構築する</li><li>Cloud Dataflowを利用した機械学習パイプラインの構築</li></ul><p>などを、実際のGoogle Cloud環境を利用して構築することができます。<br>やはり、手を動かしながら学ぶ方法が一番頭に入ってくると思います。</p><h4 id="Udemy"><a href="#Udemy" class="headerlink" title="Udemy"></a>Udemy</h4><p>認定資格には実技試験はないので、やはり仕上げはUdemyの模擬試験で慣らします。</p><p>Udemyの模擬試験は色々あって迷うと思いますが、Google Cloudは日々アップデートされておりますので、できるだけ最新の情報が反映された模擬試験（教材が公開されて日が浅いもの）を利用したほうがよいです。</p><p>今回利用した模擬試験は英語試験用でしたが、DeepLなどの翻訳機を併用することで難なくこなすことができます。</p><p>模擬試験を2～3周やっておけば、自信をもって試験に臨むことができると思います。</p><h2 id="終わりに"><a href="#終わりに" class="headerlink" title="終わりに"></a>終わりに</h2><p>本試験はML Engineer認定資格と学習範囲が被っている部分もあり、自分にとってはサクサク学習を進めることができました。ただ、より込み入ったデータ処理の技術、特にCloud ComposerやDataproc周りの知識が浅く、そこの学習を重点的に行いました。これらの範囲は実務でも必要だったのでちょうどよかったです。</p><p>資格試験は目標が立てやすく、ラーニングパスも多く公開されており、学習のとっかかりには非常によいと思うので皆さんもぜひ受けてみてください。</p><p>アイキャッチ画像は<a href="https://cloud.google.com/learn/certification?hl=ja">Google Cloud Certification</a>から付与されたものになります。</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;img src=&quot;/images/20230915a/image.png&quot; alt=&quot;&quot; width=&quot;599&quot; height=&quot;586&quot; loading=&quot;lazy&quot;&gt;

&lt;h2 id=&quot;はじめに&quot;&gt;&lt;a href=&quot;#はじめに&quot; class=&quot;headerlink&quot;</summary>
        
      
    
    
    
    <category term="Infrastructure" scheme="https://future-architect.github.io/categories/Infrastructure/"/>
    
    
    <category term="GCP" scheme="https://future-architect.github.io/tags/GCP/"/>
    
    <category term="合格記" scheme="https://future-architect.github.io/tags/%E5%90%88%E6%A0%BC%E8%A8%98/"/>
    
    <category term="資格" scheme="https://future-architect.github.io/tags/%E8%B3%87%E6%A0%BC/"/>
    
    <category term="PDE" scheme="https://future-architect.github.io/tags/PDE/"/>
    
    <category term="DataEngineer" scheme="https://future-architect.github.io/tags/DataEngineer/"/>
    
    <category term="Udemy" scheme="https://future-architect.github.io/tags/Udemy/"/>
    
  </entry>
  
  <entry>
    <title>【LLMOps】LLMの実験管理にTruLens-Evalを使ってみた</title>
    <link href="https://future-architect.github.io/articles/20230914a/"/>
    <id>https://future-architect.github.io/articles/20230914a/</id>
    <published>2023-09-13T15:00:00.000Z</published>
    <updated>2023-10-02T00:07:27.508Z</updated>
    
    <content type="html"><![CDATA[<img src="/images/20230914a/top.png" alt="" width="800" height="418" loading="lazy"><h2 id="はじめに"><a href="#はじめに" class="headerlink" title="はじめに"></a>はじめに</h2><p>こんにちは、SAIG&#x2F;MLOpsチームでインターンをしている吉田です。</p><p>LLMの実験管理ツール候補として、TruLens-Evalを検証しました。合わせて、LLMの実験管理についてまとめてみました。</p><h2 id="背景と目的"><a href="#背景と目的" class="headerlink" title="背景と目的"></a>背景と目的</h2><h3 id="LLMOpsとは"><a href="#LLMOpsとは" class="headerlink" title="LLMOpsとは"></a>LLMOpsとは</h3><p>近年、大規模言語モデル(LLM)の性能が飛躍的に向上し、その高度な自然言語処理能力によって様々な領域での課題解決が期待されています。LLMは文章生成、翻訳、要約、質問応答など多岐にわたるタスクにおいて驚異的な成果を示しており、その応用範囲はますます広がっています。</p><p>LLMOpsは、LLMを組み込んだアプリケーション開発・運用の効率化を目指すプラクティスです。アプリケーションの種類や開発規模などによってLLMOpsのワークフローは大きく変わりますが、いずれの場合もLLMの性能評価や挙動の解析のために度重なる実験が必要となります。開発過程で行われる実験を適切に管理することは、LLMアプリケーションの開発を効率化させます。</p><img src="/images/20230914a/68747470733a2f2.png" alt="" width="960" height="540" loading="lazy"><p>引用：<a href="/articles/20230912a/">LLM開発のフロー</a></p><h3 id="LLMの実験管理"><a href="#LLMの実験管理" class="headerlink" title="LLMの実験管理"></a>LLMの実験管理</h3><p>LLMに対してタスクを実行させるためには、その処理結果を適切に評価し、モデルの性能や振る舞いについて理解する必要があります。そのため、<strong>何度も実験を繰り返すこと</strong>が想定されます。しかし、<strong>LLMの性能評価や挙動解析は複雑</strong>であり、多くの要因が絡み合うことから、適切な実験管理が必要です。実験管理により、過去の実験設計や結果を簡単にアクセスできるようにすることで、アプリケーション開発の効率を上げることを目指します。</p><p>実験管理はこれまでのMLでも実施されてきましたが、MLの実験管理とLLMの実験管理は下記のように異なるため、あらためてやるべきことを整理する必要があります。</p><ul><li>プロンプトエンジニアリングやファインチューニングが主な性能向上方法となること。</li><li>モデル性能の定量的評価が難しく、用いる評価指標の検討や人間による評価が必要となること。</li></ul><p>本記事では、<strong>プロンプトエンジニアリング</strong>における実験管理を想定します。</p><p>プロンプトとはLLMに与える指示や要求のことを指します。タスクに合ったプロンプトを使用することで、LLMアプリケーションの質の向上が期待できます。タスクに特化したプロンプトの例は<a href="https://www.promptingguide.ai/jp/introduction/examples">こちら</a>にまとめられています。</p><p>以下の図は、プロンプトエンジニアリングにおける主な実験の流れです。</p><img src="/images/20230914a/image.png" alt="" width="1200" height="548" loading="lazy"><p>プロンプトエンジニアリングのための実験管理は以下の項目を中心に管理することになると考えます。</p><p>(〇：TruLens-Evalで実現可能、△：LangChainと組み合わせることにより実現可能、×：現状単独では対応していないと思われる)</p><ul><li>再現可能性<ul><li>入力テキスト(〇)</li><li>出力テキスト(〇)</li><li>システムプロンプト(△)</li><li>モデルのパラメータ(〇)</li><li>コードのバージョン管理(×)</li></ul></li><li>実験詳細<ul><li>実行ユーザ(×)</li><li>タイムスタンプ(〇)</li><li>実行時間(〇)</li><li>エラー文(〇)</li></ul></li><li>精度の評価<ul><li>ルールベースの評価スコア(〇)</li><li>LLMによる評価スコア(〇)</li><li>人間による評価スコア(〇)</li><li>人間によるテキストレビュー(×)</li></ul></li></ul><h2 id="検証概要"><a href="#検証概要" class="headerlink" title="検証概要"></a>検証概要</h2><p>Python向けのOSSであるTruLens-Evalを使ってみました。TruLens-Evalを導入することで、LLMの実験管理に必要な情報を自動的にトラッキングし、ブラウザを通して簡単に閲覧できるようになります。また、実験ごとに評価方法を設定することで、実行と同時に評価処理を行い結果を保存してくれます。</p><h2 id="TruLens-Eval"><a href="#TruLens-Eval" class="headerlink" title="TruLens-Eval"></a>TruLens-Eval</h2><p>TruLensは大規模言語モデルを含むニューラルネットの開発およびモニタリングを行うためのツールセットを提供しています。TruLensは、LLMベースのアプリケーションを評価するTruLens-Evalと、ディープラーニングモデルの説明可能性を実現するTruLens-Explainの2つのツールから構成されます。今回はLLM実験管理を目的とするため、TruLens-Evalについて調査しました。</p><p>図はTruLens-Evalの概要について説明したものです。</p><img src="/images/20230914a/68747470733a2f2_2.png" alt="" width="1200" height="551" loading="lazy"><p>引用：<a href="https://medium.com/trulens/evaluate-and-track-your-llm-experiments-introducing-trulens-86028fe9b59a">Evaluate and Track your LLM Experiments: Introducing TruLens</a></p><ol><li>LLMアプリケーションを作成する。</li><li>LLMアプリケーションをTruLensに接続し、ロギングを行う。</li><li>feedback関数をログに追加し、LLMアプリケーションの性能を評価する。</li><li>TruLens dashboardを使ってレコードや評価結果LLM chainのバージョンなどを確認する。</li><li>一番性能の良いLLM chainを得る。</li></ol><p>昨今LLM開発が注目を集めているため、TruLens-EvalのGitHubリポジトリのスター数は現在急増しています。</p><img src="/images/20230914a/star-history-202391.png" alt="star-history-202391.png" width="1200" height="836" loading="lazy"><h3 id="なぜTruLens-Evalか"><a href="#なぜTruLens-Evalか" class="headerlink" title="なぜTruLens-Evalか"></a>なぜTruLens-Evalか</h3><p>TruLens-EvalはUIの見やすさやシステムの軽量さ、GitHubのスターが増加傾向にあるOSSである点などの特徴から調査の対象としました。</p><p>TruLens-Evalは、LLMアプリケーションの性能に対する評価をサポートし、実験管理の一部として保存します。<strong>プロンプトエンジニアリングに必要と考えられる実験管理</strong>に主な焦点を置いたツールです。</p><p>タスクによって最適な評価指標は変化します。また、最適な評価指標は定まっておらず、どのような指標を用いればよいのかという検討も必要になります。TruLens-Evalは実験評価について整理されたシステムを提供しているため、<strong>評価指標の検討も円滑に進めながらより質の高いアプリケーション開発を目指す</strong>ことができると考えられます。</p><h3 id="TruLens-Evalでできること"><a href="#TruLens-Evalでできること" class="headerlink" title="TruLens-Evalでできること"></a>TruLens-Evalでできること</h3><ul><li>feedback関数を利用することにより、実験の評価を円滑に実行することができます。feedback関数とは、LLMアプリケーションが生成するテキストを分析し、LLMアプリケーションの性能をスコアリングします。</li><li>LLMアプリケーションを実行するだけで、feedback関数の実行やLLMの利用状況の<strong>トラッキングを自動で行い</strong>、データベースに保存することができます。</li><li>ブラウザから実験結果を閲覧することができ、実験結果の分析をサポートします。</li><li>データベースには後から情報を追加することができるため、人による評価などを管理することができます。</li></ul><p>ブラウザから閲覧できる情報について説明します。</p><ul><li>LLMをアプリケーションとして扱い、アプリケーション毎に実験管理をすることができます。一覧できる情報は次の通りです。<ul><li>実験回数</li><li>実行時間の平均</li><li>実行によるコスト(OpenAIモデルのような従量課金の場合)</li><li>合計トークン数</li><li>評価スコア</li></ul></li></ul><img src="/images/20230914a/コメント_2023-09-01_144334.png" alt="" width="1200" height="578" loading="lazy"><ul><li>実験の詳細をテーブルとして表示できます。アプリケーション名によるフィルタリングや評価スコアによる並び替え機能などが用意されています。比較できる情報は次の通りです。<ul><li>入力プロンプト（現在日本語(Unicode)に未対応）</li><li>出力結果（現在日本語(Unicode)に未対応）</li><li>実行時間</li><li>タイムスタンプ</li><li>合計トークン数</li><li>タグ</li><li>評価スコア（色付き）　など</li></ul></li></ul><img src="/images/20230914a/コメント_2023-09-01_144410.png" alt="" width="1200" height="579" loading="lazy"><ul><li>実験毎に詳細を確認できます。<ul><li>入力プロンプト</li><li>出力結果</li><li>コンポーネント毎の実行時間</li><li>評価スコア　など</li></ul></li></ul><img src="/images/20230914a/コメント_2023-09-01_144443.png" alt="" width="1200" height="580" loading="lazy"><p>また、LangChainを用いた場合は、モデル毎の入出力とハイパーパラメータを確認できます。（未検証）</p><img src="/images/20230914a/Leaderboard.png" alt="Leaderboard.png" width="1200" height="568" loading="lazy"><img src="/images/20230914a/Chain_Explore.png" alt="Chain_Explore.png" width="1200" height="605" loading="lazy"><h3 id="TruLens-Eval-amp-LangChain（未検証）"><a href="#TruLens-Eval-amp-LangChain（未検証）" class="headerlink" title="TruLens-Eval &amp; LangChain（未検証）"></a>TruLens-Eval &amp; LangChain（未検証）</h3><p>TruLens-EvalはLangChainの利用をサポートしているため、複数のモデルにより構成されるLLMアプリケーションについてもトラッキングが可能となります。</p><p>LangChainを導入することで、<strong>モデルパラメータやシステムプロンプトの保存</strong>だけでなく、<strong>各LLMコンポーネントの評価についても同時に処理を行う</strong>ことができます。単一のLLMのみを用いる場合においても、システムプロンプトを管理できることからLangChainの利用が推奨されると考えられます。</p><h2 id="TruLens-Evalの利用手順"><a href="#TruLens-Evalの利用手順" class="headerlink" title="TruLens-Evalの利用手順"></a>TruLens-Evalの利用手順</h2><p>TruLens-Evalの利用手順の説明します。ここでは、システムプロンプトを含めたLLMアプリケーションの評価のため、実験を行う状況を想定します。</p><p>LLMアプリ(fix) → システムプロンプト(fix) → 入力プロンプト → 実行&amp;評価 → 入力プロンプト → …</p><h3 id="LLMアプリの関数化"><a href="#LLMアプリの関数化" class="headerlink" title="LLMアプリの関数化"></a>LLMアプリの関数化</h3><p>はじめにLLMアプリの定義を行います。文字列を引数とする、文字列を返す関数を定義します。</p><p>例) OpenAIのモデルを使った簡単なアプリケーション</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">llm_standalone</span>(<span class="params">prompt</span>):</span><br><span class="line">    <span class="keyword">return</span> openai.ChatCompletion.create(</span><br><span class="line">    engine=<span class="string">&quot;モデル名&quot;</span>,</span><br><span class="line">    messages=[</span><br><span class="line">            &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;system promptの入力&quot;</span>&#125;,</span><br><span class="line">            &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: prompt&#125;</span><br><span class="line">        ]</span><br><span class="line">    )[<span class="string">&quot;choices&quot;</span>][<span class="number">0</span>][<span class="string">&quot;message&quot;</span>][<span class="string">&quot;content&quot;</span>]</span><br></pre></td></tr></table></figure><h3 id="LLMアプリのラッピング化と実行"><a href="#LLMアプリのラッピング化と実行" class="headerlink" title="LLMアプリのラッピング化と実行"></a>LLMアプリのラッピング化と実行</h3><p>定義したLLMアプリにアプリ名やフィードバック関数の情報を付与する形でラッピング化します。その後作成したインスタンスでLLMアプリの実行を行い、結果を取得します。このとき、実験管理に必要な情報はトラッキングされ、データベースに保存されます。</p><p>例) 定義したllm_standaloneのラッピング化と実行</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">prompt_input=<span class="string">&quot;テストするプロンプトを入力&quot;</span></span><br><span class="line">basic_app = TruBasicApp(llm_standalone, app_id=<span class="string">&quot;アプリ名&quot;</span>, feedbacks=[フィードバック関数を選択])</span><br><span class="line">response, record = basic_app.call_with_record(prompt_input) <span class="comment"># response: 出力結果、record: データベースのレコードID</span></span><br></pre></td></tr></table></figure><h3 id="ブラウザから閲覧"><a href="#ブラウザから閲覧" class="headerlink" title="ブラウザから閲覧"></a>ブラウザから閲覧</h3><p>シェルで以下のコマンドを実行すると、Webサーバが立ち上がりブラウザから実験結果を閲覧することができます。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">trulens-eval</span><br></pre></td></tr></table></figure><h3 id="人による評価について"><a href="#人による評価について" class="headerlink" title="人による評価について"></a>人による評価について</h3><p>Truクラスを利用することで、データベースに任意の情報を追加・削除したり、Webサーバの起動などができます。そのため、後から評価の追加が可能です。これを応用することで、人による評価について検討することができます。以下は考えられる運用例です。</p><ul><li>開発者毎に実験結果に対する評価を行い、チームによるレビューとして管理する。</li><li>評価指標（根拠性、関連性、毒性など）毎に開発者が評価を行い、統計する。</li></ul><h2 id="feedback関数"><a href="#feedback関数" class="headerlink" title="feedback関数"></a>feedback関数</h2><p>入力プロンプトや出力結果に対して評価を行うfeedback関数を定義することで、実験の評価を自動的に行うことができます。TruLensはOpenAIやHuggingFaceのモデルを用いたfeedback関数を既に用意しているため、基礎的な評価については簡単に導入することができます。</p><h3 id="feedback関数の実装"><a href="#feedback関数の実装" class="headerlink" title="feedback関数の実装"></a>feedback関数の実装</h3><p>まず、Providerクラスを継承する形で、feedback関数の定義を保持するクラスを作成します。Providerクラスのメンバメソッドとしてfeedback関数を定義します。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> trulens_eval <span class="keyword">import</span> Provider, Feedback</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyFeedbacks</span>(<span class="title class_ inherited__">Provider</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">input_length</span>(<span class="params">self, <span class="built_in">input</span>: <span class="built_in">str</span></span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1.0</span> / (<span class="number">1.0</span> + <span class="built_in">len</span>(<span class="built_in">input</span>))</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">output_length</span>(<span class="params">self, output: <span class="built_in">str</span></span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1.0</span> / (<span class="number">1.0</span> + <span class="built_in">len</span>(output))</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">inout_length</span>(<span class="params">self, <span class="built_in">input</span>: <span class="built_in">str</span>, output: <span class="built_in">str</span></span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1.0</span> / (<span class="number">1.0</span> + <span class="built_in">len</span>(<span class="built_in">input</span>) + <span class="built_in">len</span>(output))</span><br></pre></td></tr></table></figure><p>feedback関数は以下の形式で実装します。str型の引数を1つまたは2つとり、戻り値として0.0～1.0のfloat型で返します。ここで関数定義に使われる関数名および引数名は内部的に保存されています。特に、関数名が評価カテゴリの識別名として用いられます。また、多出力に関してもサポートされています(<a href="https://www.trulens.org/trulens_eval/custom_feedback_functions/#multi-output-feedback-functions">参考</a>)。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">my_feedback</span>(<span class="params">self, text1: <span class="built_in">str</span>, ...</span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">    <span class="comment">## 評価のための処理を書く ##</span></span><br><span class="line">    <span class="keyword">return</span> <span class="comment"># 0.0～1.0の値を返す</span></span><br></pre></td></tr></table></figure><p>feedback関数が実装されたProviderクラスをインスタンス化します。その後、引数に関する情報を付与する形で、feedback関数をラッピングします。また、多出力の場合はここで統計処理方法を設定できます(<a href="https://www.trulens.org/trulens_eval/api/feedback/">詳細</a>)。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">my_feedbacks = MyFeedbacks()</span><br><span class="line"></span><br><span class="line">output_function = Feedback(my_feedbacks.input_length).on_output()</span><br><span class="line">input_function = Feedback(my_feedbacks.output_length).on_input()</span><br><span class="line">inout_function = Feedback(my_feedbacks.inout_length).on_input_output()</span><br></pre></td></tr></table></figure><p>前述の「LLMアプリのラッピング化と実行」に加える形で、feedback関数を複数設定することができます。これにより、実行時に自動的にfeedback関数も実行され、結果が記録されます。また、後から実験結果に対してfeedback関数を実行することも可能です（<a href="https://www.trulens.org/trulens_eval/custom_feedback_functions/">詳細</a>）。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">basic_app = TruBasicApp(llm_standalone, app_id=<span class="string">&quot;my_function&quot;</span>, feedbacks=[input_function, output_function, inout_function])</span><br><span class="line">response, record = basic_app.call_with_record(prompt_input) <span class="comment"># response: 出力結果、record: データベースのレコードID</span></span><br></pre></td></tr></table></figure><h3 id="用意されているfeedback関数"><a href="#用意されているfeedback関数" class="headerlink" title="用意されているfeedback関数"></a>用意されているfeedback関数</h3><p>TruLens-EvalはいくつかのOpenAIやHuggingFaceが提供しているモデルやサービスを利用したfeedback関数をいくつか用意しています。（<a href="https://www.trulens.org/trulens_eval/function_definitions/#model-agreement">詳細</a>）</p><p>ここではfeedback関数の例としていくつか紹介したいと思います。</p><ul><li>Relevance（関連性）</li></ul><p>OpenAIのChatCompletionを用いて、2つのテキスト（入力と出力）の関連性を数値評価します（スモークテストは<a href="https://www.trulens.org/trulens_eval/pr_relevance_smoke_tests/">こちら</a>）。また、与えられたコンテキストとユーザの質問文がどの程度関連しているか判定するfeedback関数も用意されています（<a href="https://www.trulens.org/trulens_eval/qs_relevance_smoke_tests/">qs_relevance</a>）。</p><p>以下はRelevanceがChatCompletionに与えるシステムプロンプトです。</p><figure class="highlight md"><table><tr><td class="code"><pre><span class="line">You are a RELEVANCE grader; providing the relevance of the given RESPONSE to the given PROMPT.</span><br><span class="line">Respond only as a number from 1 to 10 where 1 is the least relevant and 10 is the most relevant.</span><br><span class="line"></span><br><span class="line">A few additional scoring guidelines:</span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> Long RESPONSES should score equally well as short RESPONSES.</span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> Answers that intentionally do not answer the question, such as &#x27;I don&#x27;t know&#x27; and model refusals, should also be counted as the most RELEVANT.</span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> RESPONSE must be relevant to the entire PROMPT to get a score of 10.</span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> RELEVANCE score should increase as the RESPONSE provides RELEVANT context to more parts of the PROMPT.</span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> RESPONSE that is RELEVANT to none of the PROMPT should get a score of 1.</span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> RESPONSE that is RELEVANT to some of the PROMPT should get as score of 2, 3, or 4. Higher score indicates more RELEVANCE.</span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> RESPONSE that is RELEVANT to most of the PROMPT should get a score between a 5, 6, 7 or 8. Higher score indicates more RELEVANCE.</span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> RESPONSE that is RELEVANT to the entire PROMPT should get a score of 9 or 10.</span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> RESPONSE that is RELEVANT and answers the entire PROMPT completely should get a score of 10.</span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> RESPONSE that confidently FALSE should get a score of 1.</span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> RESPONSE that is only seemingly RELEVANT should get a score of 1.</span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> Never elaborate.</span><br><span class="line"></span><br><span class="line">PROMPT: &#123;prompt&#125;</span><br><span class="line"></span><br><span class="line">RESPONSE: &#123;response&#125;</span><br><span class="line"></span><br><span class="line">RELEVANCE:</span><br></pre></td></tr></table></figure><ul><li>Moderation（節度）</li></ul><p>ModerationはOpenAIが提供しているAPIである<a href="https://platform.openai.com/docs/guides/moderation/overview">openai.Moderation</a>をラッピングしたものになります。これを用いることで、差別的、暴力的、性的などの評価軸で、テキストを数値評価することができます。</p><h2 id="ユースケース"><a href="#ユースケース" class="headerlink" title="ユースケース"></a>ユースケース</h2><p>以上の機能を踏まえて、実験管理の使用例について検討しました。</p><h3 id="良いプロンプトの検討"><a href="#良いプロンプトの検討" class="headerlink" title="良いプロンプトの検討"></a>良いプロンプトの検討</h3><p>各評価指標における良いプロンプトは何か、整理して検討することに役立ちます。評価指標については、ルールベースなものからLLMを用いた評価、人による評価についても対応することができます。また、あらかじめ評価指標を決定する必要はなく、後から遡って実験結果を評価することもできます。</p><p>実験結果を各評価指標によって並べ替えることができます。<br><img src="/images/20230914a/コメント_2023-09-06_163018.png" alt="コメント_2023-09-06_163018.png" width="1200" height="586" loading="lazy"></p><p>各評価指標のヒストグラムを作成することができます。アプリケーション名によるフィルタリングができます。<br><img src="/images/20230914a/コメント_2023-09-06_163113.png" alt="コメント_2023-09-06_163113.png" width="1200" height="441" loading="lazy"></p><p>各アプリケーションの評価スコアの平均値を一覧できます。<br><img src="/images/20230914a/コメント_2023-09-06_163146.png" alt="コメント_2023-09-06_163146.png" width="1200" height="568" loading="lazy"></p><h3 id="新しい評価指標の検討"><a href="#新しい評価指標の検討" class="headerlink" title="新しい評価指標の検討"></a>新しい評価指標の検討</h3><ul><li>feedback関数の実装に関するテンプレートがあるため、検討したfeedback関数の確認や新たなfeedback関数の追加などが簡潔になると思われます。</li></ul><h2 id="今後に向けて"><a href="#今後に向けて" class="headerlink" title="今後に向けて"></a>今後に向けて</h2><h3 id="TruLens-Evalの懸念点"><a href="#TruLens-Evalの懸念点" class="headerlink" title="TruLens-Evalの懸念点"></a>TruLens-Evalの懸念点</h3><p>TruLens-Evalを本格導入する際は、下記懸念があるため、対応が必要かもしれません。</p><ul><li>実験結果のテーブル表示に関して、日本語(Unicode)対応していない部分がある。(ただし、issueが立っている)</li><li>階層的な管理ができない。<ul><li>Appの名前に工夫</li><li>モデル毎にデータベースを変える</li></ul></li><li>ドキュメントが少ない。公式ドキュメントの情報も十分とは言えない。(Slackのコミュニティがあるため、そこに情報があるかも)</li><li><strong>ブラウザUIによる情報追加がサポートされていない。</strong>（人による評価がやりづらい）</li><li>ユーザカスタムな実験情報を含める柔軟性がない。<ul><li>タグやfeedback関数を使った工夫が必要</li></ul></li><li>同一入力プロンプトでも揺らぎがあるため、複数回実行して統計を取りたいがサポートされていない。<ul><li>評価方法にLLMを利用している場合、feedback関数についても揺らぎが生じると考えられる。</li></ul></li></ul><h3 id="他の候補について"><a href="#他の候補について" class="headerlink" title="他の候補について"></a>他の候補について</h3><p>他にもLLMの実験管理として有力な候補があるので、検証していきたいです。</p><ul><li>MLflow<ul><li><a href="https://www.databricks.com/jp/blog/announcing-mlflow-24-llmops-tools-robust-model-evaluation">MLflow.evaluate()</a>を拡張することで、LLMOpsに対応（未調査）</li></ul></li><li>Weights &amp; Biases<ul><li>LLMOps用に<a href="https://docs.wandb.ai/ja/guides/prompts">W&amp;B prompt</a>を公開。</li><li>TruLensでサポートされているようなトラッキングシステムを利用できる。</li><li>MLOpsのシステムと組み合わせることでLLMのファインチューニングの管理も可能。</li></ul></li></ul><p>関連して <a href="/articles/20230919a/">Prompt Flowでプロンプト評価の管理を行う</a> という記事も公開しました。</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;img src=&quot;/images/20230914a/top.png&quot; alt=&quot;&quot; width=&quot;800&quot; height=&quot;418&quot; loading=&quot;lazy&quot;&gt;

&lt;h2 id=&quot;はじめに&quot;&gt;&lt;a href=&quot;#はじめに&quot; class=&quot;headerlink&quot;</summary>
        
      
    
    
    
    <category term="DataScience" scheme="https://future-architect.github.io/categories/DataScience/"/>
    
    
    <category term="MLOps" scheme="https://future-architect.github.io/tags/MLOps/"/>
    
    <category term="LLM" scheme="https://future-architect.github.io/tags/LLM/"/>
    
    <category term="LLMOps" scheme="https://future-architect.github.io/tags/LLMOps/"/>
    
    <category term="TruLens-Eval" scheme="https://future-architect.github.io/tags/TruLens-Eval/"/>
    
  </entry>
  
  <entry>
    <title>LLM開発のためにMLOpsチームがやるべきこと</title>
    <link href="https://future-architect.github.io/articles/20230913a/"/>
    <id>https://future-architect.github.io/articles/20230913a/</id>
    <published>2023-09-12T15:00:00.000Z</published>
    <updated>2023-10-02T00:07:27.507Z</updated>
    
    <content type="html"><![CDATA[<h2 id="はじめに"><a href="#はじめに" class="headerlink" title="はじめに"></a>はじめに</h2><p>こんにちは、SAIG&#x2F;MLOpsチームでアルバイトをしている板野・平野です。</p><p>今回は「LLM開発のためにMLOpsチームがやるべきこと」というテーマで、従来のMLOpsとの違い・ツール・構成例等について調査・整理しました。</p><p>LLMとはLarge Launguage Model（大規模言語モデル）の略であり、ここでのLLM開発とは、「LLM自体の開発」および「LLMを活用したシステム開発」の両方を含むものとします。LLM開発のフローについては以前に<a href="/articles/20230912a/">LLM開発のフロー</a>で詳細を説明しているので、ぜひ併せてご覧ください。</p><p>まず、MLOpsとは「機械学習モデルの実装から運用までを円滑に推進するための手法や考え方」のことです。AIの社会実装が増えるに伴い、MLOpsチームを設ける企業も増えてきました。また、最近ではLLMやその関連技術が急速に発達してきており、今後LLMを用いたアプリケーションが開発されていくと考えられます。</p><p>LLM自体やLLMを活用したシステムを開発していく場合、MLOpsチームからは「MLOpsチームは何をするべきか？」「既存のMLOpsの枠組みとの違いは？」といった疑問が生じます。</p><p>本記事ではこれらの疑問に答えられるよう、LLM自体やLLMを活用したシステムの開発の基本的な部分を踏まえてご説明します。</p><h2 id="従来のMLOpsとの違い"><a href="#従来のMLOpsとの違い" class="headerlink" title="従来のMLOpsとの違い"></a>従来のMLOpsとの違い</h2><p>まず、LLM開発の特徴を以下に整理します。</p><ul><li>パラメータ数が大きくて大規模（大量の計算リソースが必要）</li><li>汎用的なモデル</li><li>自然言語を扱う</li><li>生成AIである（出力が自然言語である）</li><li>人間による評価が必要</li><li>モデルの能力を引き出すための工夫が必要</li></ul><p>※従来のNLP開発の特徴も一部含む</p><p>特定のタスクに対応する小規模なモデルを学習＆デプロイするのみであれば既存のMLOpsで対応できましたが、上記の特徴に対応するため、MLOpsチームは新たに「LLMのためのMLOps（LLMOps）」を考えていく必要が出てきました。</p><h2 id="LLM開発の全体像"><a href="#LLM開発の全体像" class="headerlink" title="LLM開発の全体像"></a>LLM開発の全体像</h2><img src="/images/20230913a/LLM_system_dev_flow.png" alt="LLM_system_dev_flow" width="960" height="344" loading="lazy"><p>参考: <a href="https://note.com/wandb_jp/n/n1aa6d77f33cf">https://note.com/wandb_jp&#x2F;n&#x2F;n1aa6d77f33cf</a></p><p>ここでは、LLM開発の全体像を見ていくとともに、各段階において従来のMLOpsと異なる点をご説明していきます。</p><p>一般に、ML開発では「モデル開発」→「デプロイメント」→「インテグレーション」→「モニタリング」と進めていきます。LLM開発も同様の流れで開発していくことになるかと思います。</p><h3 id="1-モデル開発"><a href="#1-モデル開発" class="headerlink" title="1. モデル開発"></a>1. モデル開発</h3><p>以前に<a href="">LLM開発のフロー</a>で紹介した通り、LLM開発は大きく「モデルを用意する（学習）フェーズ」と「モデルの能力を引き出す（推論）フェーズ」に分けられます。モデル開発の段階は「モデルを用意する（学習）フェーズ」に相当します。</p><p>「モデルを用意する（学習）フェーズ」では、従来のML開発と同様、データ収集からモデル選定、様々なハイパーパラメータで実験・評価を行い、モデルを開発していきます。</p><p>モデルを用意する方法は大きく分けて</p><ul><li>ゼロからモデルを学習する</li><li>公開済みの基盤モデルから学習する</li><li>プロプライエタリモデルを利用する</li></ul><p>の3種類があります。詳細は<a href="/articles/20230912a/">LLM開発のフロー</a>をご参照ください。</p><p>モデル開発の段階では、lossの監視やメタデータの保存、各実験のハイパーパラメータの管理などの従来のMLOpsと同様の実験管理を行う必要がありますが、それに加えLLM開発特有の管理も必要となってきます。</p><p>モデル開発の段階における従来のMLとLLMの違いとして、まずモデルが巨大であることがあります。そのため、様々な分散学習の手法を利用して効率的に学習を進めていく必要があります。</p><p>また、モデルの出力に対し確立された評価手法が存在しないこともあります。そのため現時点では、モデルの出力を人間が評価する必要もあります。したがって複数モデルの出力を効率的に評価・比較できるような仕組みを作る必要があります。</p><h3 id="2-デプロイメント"><a href="#2-デプロイメント" class="headerlink" title="2. デプロイメント"></a>2. デプロイメント</h3><p>このフェーズでは、開発したLLMをサービス側で使えるようにするためにAPIを実装し、モデルを公開します。</p><p>この段階でも、LLMの「モデルが巨大である」という特性から、従来のMLOps以上にリソース管理に注意を払う必要があります。</p><p>また、OpenAI等のAPI経由でLLMを利用する場合にはレイテンシやトークン数にも注意を払う必要があります。</p><h3 id="3-インテグレーション"><a href="#3-インテグレーション" class="headerlink" title="3. インテグレーション"></a>3. インテグレーション</h3><p>このフェーズは、<a href="/articles/20230912a/">LLM開発のフロー</a>における「モデルの能力を引き出す（推論）フェーズ」に相当します。</p><p>「モデルの能力を引き出す（推論）フェーズ」では、モデル開発の段階で開発したモデルをプロンプトエンジニアリングにより対象タスクに特化させたり、外部データと統合することで学習段階ではモデルが得ていなかった知識を活用して回答を生成することができるようになります。こちらも詳細は<a href="">LLM開発のフロー</a>をご参照ください。</p><p>また、サービスを提供するための周辺機能（フロントエンドのUIや外部データのデータベース等）を実装・テストし、サービスの提供を開始します。</p><p>この段階では、ベクトルデータベース等の構築に加え、サービス開始後の継続的な改善のため、入力プロンプト、チェーンの過程、モデルの出力等を監視できるシステムを構築する必要があります。</p><h3 id="4-モニタリング"><a href="#4-モニタリング" class="headerlink" title="4. モニタリング"></a>4. モニタリング</h3><p>このフェーズでは、提供を開始したサービスが想定通り稼働しているかを監視し、問題があればサービスのアップデートを行う必要があります。</p><p>監視する項目はリソース使用率やデータ量、レイテンシ、モデルの入出力、入力トークン数など多岐にわたります。</p><h2 id="LLM開発の課題・検討事項"><a href="#LLM開発の課題・検討事項" class="headerlink" title="LLM開発の課題・検討事項"></a>LLM開発の課題・検討事項</h2><p>では、LLM開発に対してMLOpsチームはどのようなことをすれば良いのでしょうか？</p><p>MLOpsチームがやるべきことは、以下のような課題や検討事項を解決し、LLM開発を円滑に進めることです。</p><p>※課題の一部を羅列</p><h3 id="1-モデル開発における課題・検討事項"><a href="#1-モデル開発における課題・検討事項" class="headerlink" title="1. モデル開発における課題・検討事項"></a>1. モデル開発における課題・検討事項</h3><div class="scroll"><table><thead><tr><th>課題</th><th>やるべきこと</th><th>サービス・ツール候補</th></tr></thead><tbody><tr><td>LLMの学習では大規模なデータセットを扱う必要がある</td><td>「大量なデータの保管」や「効率良いデータの取り出し」ができるデータ基盤を用意する</td><td><a href="#1-%E3%82%AF%E3%83%A9%E3%82%A6%E3%83%89%E7%B3%BB%E3%83%87%E3%83%BC%E3%82%BF%E3%83%AC%E3%82%A4%E3%82%AF">[1] クラウド系データレイク</a></td></tr><tr><td>LLMの学習では大量のデータを集める必要がある</td><td>「指示文・参考情報・理想の回答を人力で集めたデータセット」を効率良く収集する</td><td><a href="#2-argilla">[2] Argilla</a></td></tr><tr><td>LLMの学習には大量の計算リソースが必要</td><td>学習時の膨大な計算コストに注意を払う（分散学習の基盤などを用意する）</td><td><a href="#3-%E3%82%AF%E3%83%A9%E3%82%A6%E3%83%89%E5%AD%A6%E7%BF%92%E5%9F%BA%E7%9B%A4">[3] クラウド学習基盤</a></td></tr><tr><td>LLMの学習は大量の計算リソースを消費するため、必要以上の学習はコストを増加させる</td><td>学習中に「どこで学習を終えるか」を判断するためにプロンプトに対する出力を適宜確認する</td><td><a href="#4-mlflow">[4] MLflow</a> <br><a href="#5-weight--biases">[5] Weights &amp; Biases</a> <br><a href="#6-aim">[6] aim</a></td></tr><tr><td>LLMの定量的評価は難しく、人間による評価が必要</td><td>複数の基盤モデルをファインチューニングする際、各モデルの出力を効率よく比較する</td><td><a href="#4-mlflow">[4] MLflow</a> <br><a href="#5-weight--biases">[5] Weights &amp; Biases</a> <br><a href="#6-aim">[6] aim</a></td></tr><tr><td>LLMは汎用的なモデルであるが故、学習時のタスクとダウンストリームのタスクが一致しない</td><td>「学習の評価時に行うタスク」と「推論時に行うタスク」が異なり、推論フェーズで想定通りに動かないという事態を避ける</td><td><a href="#2-argilla">[2] Argilla</a> <br><a href="#4-mlflow">[4] MLflow</a> <br><a href="#5-weight--biases">[5] Weights &amp; Biases</a> <br><a href="#6-aim">[6] aim</a></td></tr><tr><td>LLMの出力は自然言語であり、評価が難しい</td><td>評価指標を用意する（人間による評価基盤の構築等）</td><td><a href="#7-deepspeed-chat">[7] DeepSpeed Chat</a> <br><a href="#8-jglue">[8] JGLUE</a> <br><a href="#9-toxic-bert">[9] toxic-bert</a> <br><a href="#10-moderation">[10] Moderation</a> <br><a href="#11-prompt-flow">[11] Prompt Flow</a></td></tr><tr><td>形式的なプロンプト（タスクの説明や出力の形式など）を毎回入力するのは面倒</td><td>プロンプトのテンプレートを作成・管理する</td><td><a href="#20-langchain">[20] LangChain</a> <br><a href="#21-llamaindex">[21] LlamaIndex</a> <br><a href="#24-semantic-kernel">[24] Semantic Kernel</a></td></tr><tr><td>LLMはプロンプト次第で振る舞いが大きく変わってしまう</td><td>タスクに合わせてプロンプトを改良する。タスクが複数ある場合はそれぞれ独立で改良していく</td><td><a href="#20-langchain">[20] LangChain</a> <br><a href="#21-llamaindex">[21] LlamaIndex</a></td></tr></tbody></table></div><h3 id="2-デプロイメントにおける課題・検討事項"><a href="#2-デプロイメントにおける課題・検討事項" class="headerlink" title="2. デプロイメントにおける課題・検討事項"></a>2. デプロイメントにおける課題・検討事項</h3><div class="scroll"><table><thead><tr><th>課題</th><th>やるべきこと</th><th>サービス・ツール候補</th></tr></thead><tbody><tr><td>プロプライエタリモデル使用時特有のコスト管理が必要</td><td>プロプライエタリモデル使用の際、コストマネジメントのため、入力トークン数を監視する</td><td><a href="#12-datadog">[12] Datadog</a></td></tr><tr><td>プロプライエタリモデルの場合、レイテンシが発生してしまう</td><td>プロプライエタリモデル使用の際、サービス品質保証のため、レイテンシを監視する</td><td><a href="#12-datadog">[12] Datadog</a></td></tr></tbody></table></div><h3 id="3-インテグレーションにおける課題・検討事項"><a href="#3-インテグレーションにおける課題・検討事項" class="headerlink" title="3. インテグレーションにおける課題・検討事項"></a>3. インテグレーションにおける課題・検討事項</h3><div class="scroll"><table><thead><tr><th>課題</th><th>やるべきこと</th><th>サービス・ツール候補</th></tr></thead><tbody><tr><td>サービス開始前にテストを行う必要がある</td><td>チャット形式のUIを用意してLLMを試験的に試してみる</td><td><a href="#13-dify">[13] Dify</a> <br><a href="#14-fixie">[14] Fixie</a> <br><a href="#15-playground">[15] Playground</a></td></tr><tr><td>LLMの能力を最大限引き出すために、外部データを活用する必要がある</td><td>文書検索のためのベクトルデータベースを構築・運用する</td><td><a href="#16-chroma">[16] Chroma</a> <br><a href="#17-elasticsearch">[17] Elasticsearch</a> <br><a href="#18-faiss">[18] Faiss</a> <br><a href="#19-pinecone">[19] Pinecone</a></td></tr><tr><td>LLMの能力を最大限引き出すために、外部データを活用する必要がある</td><td>文書等をベクトルデータベースに保管する</td><td><a href="#20-langchain">[20] LangChain</a> <br><a href="#21-llamaindex">[21] LlamaIndex</a> <br><a href="#22-cosmos-db">[22] Cosmos DB</a> <br><a href="#23-azure-cache-for-redis">[23] Azure Cache for Redis</a></td></tr><tr><td>LLMに会話の流れを理解させる必要がある</td><td>チャットの履歴を管理する</td><td><a href="#20-langchain">[20] LangChain</a> <br><a href="#21-llamaindex">[21] LlamaIndex</a></td></tr></tbody></table></div><h3 id="4-モニタリングにおける課題・検討事項"><a href="#4-モニタリングにおける課題・検討事項" class="headerlink" title="4. モニタリングにおける課題・検討事項"></a>4. モニタリングにおける課題・検討事項</h3><div class="scroll"><table><thead><tr><th>課題</th><th>やるべきこと</th><th>サービス・ツール候補</th></tr></thead><tbody><tr><td>サービスの継続的な改善</td><td>過去のプロンプトを保持し、プロンプト改良に繋げる。苦手なプロンプトを見つけたらマークして保持</td><td><a href="#20-langchain">[20] LangChain</a> <br><a href="#21-llamaindex">[21] LlamaIndex</a></td></tr><tr><td>プロンプトインジェクションへの対策</td><td>不正な入力プロンプトを監視する</td><td>-</td></tr><tr><td>LLMが不適切な発言をしてしまう可能性がある</td><td>LLMの出力を定性的に評価・監視する（正確性、倫理性、バイアス、プライバシー等）</td><td><a href="#9-toxic-bert">[9] toxic-bert</a> <br><a href="#10-moderation">[10] Moderation</a> <br><a href="#25-guardrails-ai">[25] Guardrails AI</a></td></tr></tbody></table></div><h2 id="課題・検討事項をどう解決するか（ツール紹介）"><a href="#課題・検討事項をどう解決するか（ツール紹介）" class="headerlink" title="課題・検討事項をどう解決するか（ツール紹介）"></a>課題・検討事項をどう解決するか（ツール紹介）</h2><p>LLMの急速な発達に伴い、上記の課題や検討事項を解決するのに役立つサービスやツールが沢山出てきています。一方で、LLMはまだ新しい技術のため、サービスやツールを使っても解決しない場合やそもそもツールが無い場合もあります。</p><p>このような課題はMLOpsチームが独自に工夫して解決していく必要があります。MLOpsチームは、活用できるサービスやツールは活用し、サービス・ツールが無い or 使えない場合の解決策を考えることに注力したいところです。</p><p>ここからは、MLOpsの効率的な推進に活用できそうなLLMのためのサービスやツールを紹介し、読者の皆様に役立つことを期待します。LLMのためのサービス・ツールは数多くありますが、以下に課題・検討事項に対応するサービス・ツールの候補を一部抜粋してまとめました。</p><p>その他にも多くのツールがあり、<a href="https://github.com/tensorchord/Awesome-LLMOps">こちら</a>が参考になります。以下は表にまとめた各サービス・ツールの詳細です。やや無秩序な羅列となっていますがご紹介します。</p><h3 id="1-クラウド系データレイク"><a href="#1-クラウド系データレイク" class="headerlink" title="[1] クラウド系データレイク"></a>[1] クラウド系データレイク</h3><p>AWSやAzure、GCPなどのクラウドサービスでは、「大量なデータの保管」と「効率良いデータの取り出し」が可能なサービスが提供されています。</p><ul><li>AWS<ul><li>データレイク：<a href="https://aws.amazon.com/jp/s3/">Amazon S3</a></li><li>検索サービス：<a href="https://aws.amazon.com/jp/kendra/">Amazon Kendra</a></li></ul></li><li>Azure<ul><li>データレイク：<a href="https://learn.microsoft.com/ja-jp/azure/storage/blobs/storage-blobs-introduction">Azure Blob Storage</a></li><li>検索サービス：<a href="https://learn.microsoft.com/ja-jp/azure/search/search-what-is-azure-search">Azure Cognitive Search</a></li></ul></li><li>GCP<ul><li>データレイク：<a href="https://cloud.google.com/storage?hl=ja">Google Cloud Storage</a></li><li>検索サービス：<a href="https://cloud.google.com/vertex-ai/docs/matching-engine/overview?hl=ja">Vertex AI Matching Engine</a></li></ul></li></ul><h3 id="2-Argilla"><a href="#2-Argilla" class="headerlink" title="[2] Argilla"></a>[2] Argilla</h3><p><a href="https://docs.argilla.io/en/latest/">Argilla</a>は、RLHF用に「人力で集めるデータの入力・出力の評価」を円滑にするための管理を行ってくれるプラットフォームです。\</p><p>例えば、人力で集めるデータとは、<a href="https://huggingface.co/datasets/kunishou/databricks-dolly-15k-ja">こちら</a>にあるような指示文(instruction)、参考情報(input)、理想の回答(output)がセットになったものや、複数のLLMからの出力にランク付けをした結果等です。</p><p>このようなデータを収集する際、分かりやすいUIを提供し、集めたデータを管理してくれます。</p><details><summary>詳細</summary><img src="/images/20230913a/image.png" alt="image" width="1200" height="672" loading="lazy"></details><h3 id="3-クラウド学習基盤"><a href="#3-クラウド学習基盤" class="headerlink" title="[3] クラウド学習基盤"></a>[3] クラウド学習基盤</h3><p>AWSやGCPなどのクラウドサービスでは、LLM開発のための学習基盤が用意されています。</p><ul><li>AWS<ul><li>Amazon SageMaker上でLLMの分散学習が可能です（<a href="https://aws.amazon.com/jp/blogs/news/training-large-language-models-on-amazon-sagemaker-best-practices/">参考</a>）</li></ul></li><li>GCP<ul><li><a href="https://t5x.readthedocs.io/en/latest/">T5X</a>とVertex AIを用いてLLMを学習させることができます（<a href="https://github.com/GoogleCloudPlatform/t5x-on-vertex-ai">参考</a>）</li></ul></li><li>Azure<ul><li>Azure Machine LearningでLLMの学習が可能です（<a href="https://learn.microsoft.com/ja-jp/azure/machine-learning/overview-what-is-azure-machine-learning">参考</a>）。<a href="https://learn.microsoft.com/ja-jp/azure/machine-learning/prompt-flow/get-started-prompt-flow">Prompt Flow</a>（後述）を利用することで、LLM自体の開発を含めたLLMを用いたサービスの開発を行うことができます</li></ul></li></ul><h3 id="4-MLflow"><a href="#4-MLflow" class="headerlink" title="[4] MLflow"></a>[4] MLflow</h3><p><a href="https://mlflow.org/docs/latest/index.html">MLflow</a>は、従来のMLOpsにおいても広く使われてきたツールですが、MLflowはバージョン2.3からLLMに対応し、<br>HuggingfaceのトランスフォーマーやLangChainのロギング機能が追加されました。</p><p>また、バージョン2.4からはLLMの評価のための機能も追加され、複数のモデルの入力、出力、中間結果を簡単に比較することができます。</p><details><summary>参考</summary><img src="/images/20230913a/mlflow_3.png" alt="mlflow_3" width="1200" height="621" loading="lazy"></details><h3 id="5-Weight-amp-Biases"><a href="#5-Weight-amp-Biases" class="headerlink" title="[5] Weight &amp; Biases"></a>[5] Weight &amp; Biases</h3><p><a href="https://wandb.ai/site/jp-home">Weight &amp; Biases</a>も有名なMLOpsツールです。Weight &amp; Biasesでは<a href="https://docs.wandb.ai/guides/prompts">W&amp;B Prompts</a>というツールが提供されています。</p><p>LangChainの処理の可視化、各実行における入出力、中間結果の比較、チェーン構造やパラメータの確認が簡単に行えます。</p><p><a href="https://www.youtube.com/watch?v=gU6Ew-Rscw8">YouTube動画</a>にて、W&amp;B Promptsでどのようなことができるのかが分かりやすく紹介されているのでぜひご覧ください。</p><h3 id="6-aim"><a href="#6-aim" class="headerlink" title="[6] aim"></a>[6] aim</h3><p><a href="https://aimstack.readthedocs.io/en/latest/">aim</a>では、LLMの学習における各種パラメータやメトリクスのロギング、出力の確認、比較をすることができます。</p><p>LangChainの公式Docsに、<a href="https://python.langchain.com/docs/ecosystem/integrations/aim_tracking">Aimを用いたLangChainのトラッキングの例</a>が記載されており、具体的な導入方法も分かりく紹介されています。加えて<a href="https://github.com/aimhubio/aimlflow">MLflowと組み合わせて使うことも可能</a>なため、MLflowを現在使われている場合にも、導入を考えることができます。</p><details><summary>参考</summary><img src="/images/20230913a/aim.gif" alt="aim" width="1200" height="675" loading="lazy"><p>引用元: <a href="https://twitter.com/aimstackio/status/1653836833586024449">AimStack on Twitter</a></p></details><h3 id="7-DeepSpeed-Chat"><a href="#7-DeepSpeed-Chat" class="headerlink" title="[7] DeepSpeed Chat"></a>[7] DeepSpeed Chat</h3><p><a href="https://github.com/microsoft/DeepSpeed/blob/master/blogs/deepspeed-chat/japanese/README.md">DeepSpeed Chat</a>は、人間のフィードバックによる強化学習（RLHF）に必要なパイプラインをサポートするツールです。</p><p>通常、RLHFには複雑なパイプラインが必要で、多大なコストと時間が掛かりますが、DeepSpeed Chatを利用すると以下のような恩恵が得られます。</p><ul><li>簡単なコードで複雑なRLHFのパイプラインを実行できる</li><li>ZeROやLoRAベースの多数のメモリ最適化技術を利用することで計算リソースを大幅に削減できる</li></ul><details><summary>詳細</summary><img src="/images/20230913a/image_2.png" alt="image" width="1200" height="675" loading="lazy"></details><h3 id="8-JGLUE"><a href="#8-JGLUE" class="headerlink" title="[8] JGLUE"></a>[8] JGLUE</h3><p><a href="https://github.com/yahoojapan/JGLUE">JGLUE</a>は早稲田大学とYahoo! JAPAN研究所によって作成された日本語理解能力を測るためのベンチマークです。文章分類、文ペア分類、質疑応答のタスクの能力を測ることができ、そのためのデータセットも用意されています。</p><p>注意点として、JGLUEは一般的な日本語理解能力を測るためのベンチマークであるため、JGLUEのスコアが良いからと言って目的タスクの精度も良いとは言えません。JGLUEのスコアはあくまで参考程度とするべきでしょう。結局、現状では目的タスクの精度を測るには独自でテスト用データセットを作成する必要があるかと思います。</p><h3 id="9-toxic-bert"><a href="#9-toxic-bert" class="headerlink" title="[9] toxic-bert"></a>[9] toxic-bert</h3><p><a href="https://huggingface.co/unitary/toxic-bert">toxic-bert</a>はコメントの有害レベルの分類や有害なコメントの分類（どのような有害さを持っているか）が可能なモデルです。LLMの出力の監視に利用することができます。</p><p>複数言語で学習済みのモデルが公開されていますが、日本語での学習済みモデルはないようです。しかし、学習用のコードは公開されているため、データセットを用意すれば日本語に対応したモデルも作成することもできるでしょう。</p><h3 id="10-Moderation"><a href="#10-Moderation" class="headerlink" title="[10] Moderation"></a>[10] Moderation</h3><p><a href="https://platform.openai.com/docs/guides/moderation">Moderation</a>はOpenAIのAPIを利用する際に、入出力が<a href="https://openai.com/policies/usage-policies">OpenAIの利用ポリシー</a>に反していないかを監視するために利用できるモデルです（それ以外の目的での利用は禁止されています）。</p><p>Moderationでは、ポリシーに反しているかのフラグ(True&#x2F;False)に加えて、どのカテゴリー(sexual、hate、harassmentなど)で反しているか、各カテゴリーのスコアを返してくれます。</p><h3 id="11-Prompt-Flow"><a href="#11-Prompt-Flow" class="headerlink" title="[11] Prompt Flow"></a>[11] Prompt Flow</h3><p><a href="https://learn.microsoft.com/ja-jp/azure/machine-learning/prompt-flow/get-started-prompt-flow">Prompt Flow</a>はLLMを用いたアプリケーションの作成・デバッグ・評価・デプロイを行うことができるツールです。作成したフローがグラフで可視化されているため、開発時にはどのようなフローになるのかを簡単に確認することができます。また、作成したフローは簡単に評価することができます。その後、デプロイまでをPrompt Flowで完結させることができます。</p><details><summary>詳細</summary><img src="/images/20230913a/image_3.png" alt="image" width="1200" height="607" loading="lazy"><p>引用元: <a href="https://learn.microsoft.com/ja-jp/azure/machine-learning/prompt-flow/get-started-prompt-flow">プロンプト フローの概要 (プレビュー)</a></p></details><h3 id="12-Datadog"><a href="#12-Datadog" class="headerlink" title="[12] Datadog"></a>[12] Datadog</h3><p><a href="https://docs.datadoghq.com/ja/">Datadog</a>は、SaaS形式で利用できるモニタリングサービスです。</p><p>Datadogでは、OpenAI API利用時のトークンの総消費量、リクエストごとのトークンの平均総数、レスポンスタイム、APIのエラー率を監視することができます。</p><details><summary>詳細</summary><img src="/images/20230913a/datadog_dashboard.png" alt="datadog_dashboard" width="1200" height="675" loading="lazy"><p>引用元: <a href="https://www.datadoghq.com/ja/solutions/openai/">Datadog</a></p></details><h3 id="13-Dify"><a href="#13-Dify" class="headerlink" title="[13] Dify"></a>[13] Dify</h3><p><a href="https://docs.dify.ai/getting-started/intro-to-dify">Dify</a>はLLMを用いたアプリケーションを簡単に作成できるツールです。Difyではテキスト生成型と会話型のアプリケーションを作成することができます。</p><p>アプリケーションのタイプを決めた後は、プロンプトテンプレートを作成、データセットの読み込み、デバッグ、パラメータ調整等ができます。</p><p>また、アプリケーションの公開も行うことができます。</p><details><summary>参考</summary><img src="/images/20230913a/Dify_table.png" alt="Dify_table" width="946" height="548" loading="lazy"><p>引用元: <a href="https://docs.dify.ai/application/creating-an-application">Dify Docs -Creating An Application</a></p><img src="/images/20230913a/dify.gif" alt="dify.gif" width="800" height="495" loading="lazy"><p>引用元: <a href="https://twitter.com/dify_ai/status/1691296036420243456">Dify.AI on Twitter</a></p></details><h3 id="14-Fixie"><a href="#14-Fixie" class="headerlink" title="[14] Fixie"></a>[14] Fixie</h3><p><a href="https://www.fixie.ai/">Fixie</a>は、LLMを用いたアプリケーションを開発することができるプラットフォームです。</p><p>Fixieでは、agent registryに登録されているLLMを使用することができ、使用するLLMにはOpenAIなどのプロプライエタリモデルや独自にファインチューニングしたモデルなどを選ぶことができます。また、外部データとしてGitHub、Google Calendar、databaseなどを利用することができます。</p><p>開発したLLMを用いたアプリケーションを作成したい場合や、開発したLLMが期待通りの挙動を示すかどうかのテストなどに利用することができるかと思います。</p><h3 id="15-Playground"><a href="#15-Playground" class="headerlink" title="[15] Playground"></a>[15] Playground</h3><p><a href="https://learn.microsoft.com/ja-jp/azure/ai-services/openai/chatgpt-quickstart?tabs=command-line&pivots=programming-language-studio">Playground</a>は、Azure OpenAI Serviceで利用できる、モデルをインタラクティブに試すことが可能なサービスです。</p><p>チャット形式とcompletion形式でモデルを試すことができ、各種設定（システムメッセージ（モデルがどのように振舞うべきかを定義した文）や温度パラメータなど）もその場で変更することができます。</p><details><summary>参考</summary><img src="/images/20230913a/Chat_playground.png" alt="Chat_playground" width="1200" height="644" loading="lazy"><p>引用元: <a href="https://learn.microsoft.com/ja-jp/azure/ai-services/openai/chatgpt-quickstart?tabs=command-line&pivots=programming-language-studio#playground">クイックスタート: Azure OpenAI Service で GPT-35-Turbo と GPT-4 を使い始める</a></p></details><h3 id="16-Chroma"><a href="#16-Chroma" class="headerlink" title="[16] Chroma"></a>[16] Chroma</h3><p>LlamaIndex等で作成したIndexはどこかに保存しておいて、毎回作成するという手間は省きたいところです。</p><p><a href="https://docs.trychroma.com/">Chroma</a>はLlamaIndex等で作成したIndexの保存、活用を容易にするためのOSSのベクトルデータベースです。</p><p>LangChainやLlamaIndexとの連携をサポートしており（<a href="https://docs.trychroma.com/integrations">参考</a>）、またデプロイ先としてAWSが利用できます（<a href="https://docs.trychroma.com/deployment">参考</a>）。</p><h3 id="17-Elasticsearch"><a href="#17-Elasticsearch" class="headerlink" title="[17] Elasticsearch"></a>[17] Elasticsearch</h3><p><a href="https://www.elastic.co/jp/elasticsearch/">Elasticsearch</a>はElastic社が提供する全文検索エンジンです。</p><p>大量のデータ量やリクエスト量であってもスケーラブルに分散処理が可能となっています。 バージョン8.0からはNLPを用いたセマンティック検索の機能も追加されました（<a href="https://www.elastic.co/jp/virtual-events/introduction-to-nlp-models-and-vector-search">参考</a>）。</p><p>これにより、LLMを活用したシステムにおける外部データの保存先として利用することができます。</p><h3 id="18-Faiss"><a href="#18-Faiss" class="headerlink" title="[18] Faiss"></a>[18] Faiss</h3><p><a href="https://github.com/facebookresearch/faiss">Faiss</a>はMetaが作成したOSSのベクトル検索ライブラリです。</p><p>テキストのインデックスの作成、検索が可能となっています。</p><p>マルチGPUでの検索もサポートされており、高速に類似した文章を検索することができます。</p><h3 id="19-Pinecone"><a href="#19-Pinecone" class="headerlink" title="[19] Pinecone"></a>[19] Pinecone</h3><p><a href="https://www.pinecone.io/">Pinecone</a>はフルマネージドなベクトルデータベースです。</p><p>商用のサービスとはなりますが、インデックスの作成、検索、保存・管理をこのサービス1つで完了させることができます。また、スケーリングにも対応しているため、大量のリクエストにも高速に対応することができます。</p><h3 id="20-LangChain"><a href="#20-LangChain" class="headerlink" title="[20] LangChain"></a>[20] LangChain</h3><p>LLMを拡張し様々なタスクに特化させるための代表的なOSSツールとして、<a href="https://docs.langchain.com/docs/">LangChain</a>があります。</p><p>LangChainでは、LLMの呼び出しから、プロンプトの管理、外部データの活用、連続的なタスクの実行などが簡単に実装できます。</p><details><summary>詳細</summary>以下にLangChainで提供されている主要な機能を紹介します。<div class="scroll"><table><thead><tr><th>機能</th><th>説明</th></tr></thead><tbody><tr><td>Models</td><td>LangChainがサポートしている多くのモデルを同一インターフェースで扱える</td></tr><tr><td>Prompts</td><td>プロンプトの管理、最適化、シリアル化ができる</td></tr><tr><td>Memory</td><td>LLMとのやり取りを保存でき、またそれを用いてLLMに過去のやり取りを踏まえた回答を促すことができる</td></tr><tr><td>Indexes</td><td>LLMに外部データを踏まえた回答をさせるため、外部データのロードやクエリ、更新のためのインターフェースが用意されている</td></tr><tr><td>Chains</td><td>LLMに対して連続的に指示を出すことができる</td></tr><tr><td>Agents</td><td>LLMに次にすべきことの決定、実行、結果の観測を繰り返させ、高レベルの指示に応えさせることができる</td></tr><tr><td>Callbacks</td><td>Chainの過程を記録することができ、アプリケーションのデバッグ・評価をしやすくする</td></tr></tbody></table></div></details><h3 id="21-LlamaIndex"><a href="#21-LlamaIndex" class="headerlink" title="[21] LlamaIndex"></a>[21] LlamaIndex</h3><p><a href="https://gpt-index.readthedocs.io/en/latest/index.html">LlamaIndex</a>は、大量の文書等から質問に関連する内容を抽出し、その内容に基づいてLLMに回答させるといったことができます。</p><p>この場合、まず大量の文書をベクトル化して保持しておきます。質問文が来たら、ベクトルとの類似度をもとに関連する文章を抽出し、</p><p>その内容をプロンプトに含めてLLMに回答させるという流れになります。</p><p>LlamaIndexを用いることで、</p><ul><li>外部データの読み込み</li><li>Indexの作成</li><li>クエリで関連データを抽出</li></ul><p>ができるようになります。</p><h3 id="22-Cosmos-DB"><a href="#22-Cosmos-DB" class="headerlink" title="[22] Cosmos DB"></a>[22] Cosmos DB</h3><p><a href="https://learn.microsoft.com/ja-jp/azure/cosmos-db/introduction">Cosmos DB</a>は、チャット形式のLLMを用いたアプリケーションにおいて、会話履歴を保存する場合に使うことができます。 Cosmos DBはAzureのフルマネージドなNoSQLデータベースです。</p><p><a href="https://qiita.com/nohanaga/items/18baccb843b4148e6a77#3-%E3%83%81%E3%83%A3%E3%83%83%E3%83%88%E5%B1%A5%E6%AD%B4%E3%81%AE%E6%A4%9C%E7%B4%A2azure-cache-for-redis">こちらの記事</a>では、実際にCosmos DBを用いてチャットの履歴を保存する例が紹介されていますのでご参照ください。</p><h3 id="23-Azure-Cache-for-Redis"><a href="#23-Azure-Cache-for-Redis" class="headerlink" title="[23] Azure Cache for Redis"></a>[23] Azure Cache for Redis</h3><p><a href="https://azure.microsoft.com/products/cache">Azure Cache for Redis</a>も会話履歴を保存する際に利用することができます。通常はインメモリキャッシュとして使用することが想定されますが、データ永続化の機能を利用することでNoSQLのDBとしても利用することができます</p><p>（<a href="https://qiita.com/nohanaga/items/18baccb843b4148e6a77#3-%E3%83%81%E3%83%A3%E3%83%83%E3%83%88%E5%B1%A5%E6%AD%B4%E3%81%AE%E6%A4%9C%E7%B4%A2azure-cache-for-redis">参考</a>）。</p><h3 id="24-Semantic-Kernel"><a href="#24-Semantic-Kernel" class="headerlink" title="[24] Semantic Kernel"></a>[24] Semantic Kernel</h3><p><a href="https://github.com/microsoft/semantic-kernel">Semantic Kernel(SK)</a>は、Microsoftが開発しているOSSのサービスで、LLMと従来のプログラミング言語を簡単に組み合わせることが可能で、LLMをアプリに統合することができます。</p><p>SKでは、LLMを特定のタスクを実行する関数(Semantic Function)として扱い、従来のプログラミング言語の関数(Native Function)と合わせて、「スキル」という枠組みで扱います。そして、これらのスキルをパイプライン化してまとめることが可能です。</p><p>さらにプランナーという機能では、登録されたスキルを使って自動でタスク実行のためのスキルの選択・実行順を考えてくれます。</p><h3 id="25-Guardrails-AI"><a href="#25-Guardrails-AI" class="headerlink" title="[25] Guardrails AI"></a>[25] Guardrails AI</h3><p><a href="https://shreyar.github.io/guardrails/">Guardrails AI</a>はLLMの出力に対して、構造検証、型検証、品質検証を行うことができるPythonライブラリです。</p><p>Guardrails AIには以下のような出力検証機能があります。</p><ul><li>生成されたテキストに偏りがないか、生成されたコードにバグがないかなどの意味的な検証を行う</li><li>バリデーションが失敗した場合、修正アクション（LLMに再びプロンプトを入力する等）を実行する</li><li>構造や型（JSONなど）の検証を行う</li></ul><h2 id="LLMシステム構成例"><a href="#LLMシステム構成例" class="headerlink" title="LLMシステム構成例"></a>LLMシステム構成例</h2><p>これまで、LLMに対するMLOpsチームの課題ややるべきことを中心に説明しました。ここからは、LLMの具体的なユースケースから理解を深めていただくことを目的として、LLMシステムの構成例を紹介していきます。</p><p>本章では、LLMシステムの構成例を「クラウドサービスに依存しない構成例」と「クラウドサービスを用いた構成例」に分けてご紹介します。</p><p>いずれの例も、社内文書やWeb上のドキュメント等をチャット形式で検索できるようなシステムの構成例です。</p><h3 id="クラウドサービスに依存しない構成例"><a href="#クラウドサービスに依存しない構成例" class="headerlink" title="クラウドサービスに依存しない構成例"></a>クラウドサービスに依存しない構成例</h3><p>以下はLLMを用いたチャットによる文書検索システムの構成例です。</p><p>特定のクラウドサービスに依存せず、可能な限りOSSで構成する際の構成案を考えてみました。</p><img src="/images/20230913a/LLM構成例5.png" alt="LLM構成例5" width="921" height="416" loading="lazy"><ul><li>①UI<ul><li>ユーザーからの入力をチャット形式で受け付ける</li><li>チャット形式のインターフェースに<a href="https://github.com/oobabooga/text-generation-webui">Text generation web UI</a>というツールを利用</li><li>あらゆるLLMに対応しているため、モデルの交換等がスムーズに行える</li></ul></li><li>②前処理<ul><li>プロンプトインジェクションという攻撃を防ぐ役割を持つ</li><li>プロンプトインジェクションとは、「LLMに対して特殊な質問をすることで、LLMが持つ機密情報や非公開データを不正に引き出す攻撃」を指す</li><li>ユーザーからの入力を何らかの形でフィルタリングする必要がありますが、確固たる手法は未だ無い</li><li>現状、前処理部は概念として図示しているが、今後必要になってくると考えられる</li><li>この前処理部分は、プロンプト生成部にまとめても良い</li></ul></li><li>③プロンプト生成<ul><li>ここでは入力された質問からプロンプトを生成する</li><li>プロンプト生成のためのライブラリとして、<a href="https://github.com/hwchase17/langchain">LangChain</a>や<a href="https://github.com/jerryjliu/llama_index">LlamaIndex</a>が代表的</li><li>ライブラリを使うことで、「長い文章をベクトル化してプロンプトに含める」や「ベクトルDBから検索したい文章を抽出しプロンプトに含める」等の処理が実装できる</li></ul></li><li>④ベクトルDB<ul><li>ベクトルデータを扱えるデータベース</li><li>社内文書など、様々なテキストデータをベクトル化し、得られたベクトルをデータベースに格納する</li><li>検索する時は、検索したいキーワードのベクトルと類似のベクトルをデータベースから検索する</li><li>ベクトルDB・全文検索エンジンとして、<a href="https://github.com/chroma-core/chroma">Chroma</a>や<a href="https://www.elastic.co/jp/elasticsearch/">Elasticsearch</a>等が挙げられる</li></ul></li><li>⑤LLM<ul><li>自力でファインチューニングしたモデルやプロプライエタリモデルを使用する</li></ul></li><li>⑥後処理<ul><li>LLMの出力の品質を保つために、出力に後処理を施す</li><li><a href="https://shreyar.github.io/guardrails/">Guardrails AI</a>というライブラリを使うと、生成されたテキストに偏りがないか、生成されたコードにバグがないかなどを検証することができる</li><li>この後処理部分は、プロンプト生成部にまとめても良い</li></ul></li></ul><h3 id="クラウドサービスを用いた構成例"><a href="#クラウドサービスを用いた構成例" class="headerlink" title="クラウドサービスを用いた構成例"></a>クラウドサービスを用いた構成例</h3><p>上記の、クラウドサービスに依存しないチャットによる文書検索システムに似たものを三大クラウドサービス（Azure, AWS, GCP）で構成する場合は以下のようになります。</p><h4 id="Azure"><a href="#Azure" class="headerlink" title="Azure"></a>Azure</h4><p>AzureにおけるLLMを活用したシステム開発の特徴は以下の通りです。</p><ul><li><a href="https://azure.microsoft.com/ja-jp/products/cognitive-services/openai-service">Azure OpenAI Service</a>により、OpenAIが提供しているGPT-4やGPt-3.5、Codex等が利用可能</li><li>文書検索には<a href="https://azure.microsoft.com/ja-jp/products/search">Azure Cognitive Search</a>というサービスを使うことで、PDFやHTML,Microsoft Office形式など様々なデータソースから検索可能</li><li>OpenAIのAPIと比べて、プライベートネットワーク、リージョンの可用性、責任あるAIコンテンツのフィルター処理などの機能が利用可能</li></ul><p>※ただし、6&#x2F;27現在、新規の利用者はモデルのファインチューニングを行うことができない点に注意が必要です。</p><details><summary>構成図</summary><img src="/images/20230913a/azure_arch.png" alt="azure_arch" width="999" height="475" loading="lazy"></details><h4 id="AWS"><a href="#AWS" class="headerlink" title="AWS"></a>AWS</h4><p>AWSにおけるLLMを活用したシステム開発の特徴は以下の通りです。</p><ul><li>AWS独自のLLMである<a href="https://aws.amazon.com/jp/bedrock/titan/">Amazon Titan</a>やそれらをAPI経由で利用できる<a href="https://aws.amazon.com/jp/bedrock/">Amazon Bedrock</a>を用いて開発が可能</li><li>LangChainを実行するサーバーとしてLambdaを活用し、サーバーレスなシステムを構築可能</li><li>文書検索には<a href="https://aws.amazon.com/jp/kendra/">Amazon Kendra</a>というサービスを使うことで、S3上のPDFやHTML,Microsoft Office形式など様々なデータソースから検索可能</li><li>Amazon SageMakerと統合されており、複数モデルをテストするための実験や基盤モデルを大規模に管理するためのパイプライン等の機能が利用可能</li></ul><details><summary>構成図</summary><img src="/images/20230913a/AWS_arch.png" alt="AWS_arch" width="1200" height="835" loading="lazy"></details><h4 id="GCP"><a href="#GCP" class="headerlink" title="GCP"></a>GCP</h4><p>GCPにおけるLLMを活用したシステム開発の特徴は以下の通りです。</p><ul><li>LLMのモデルには、<a href="https://cloud.google.com/vertex-ai/docs/start/explore-models">Model Garden</a>にてGoogle製のLLMであるPaLM、Imagen、Codey、Chirp等が利用可能</li><li>文書検索（グラウンディング）には<a href="https://cloud.google.com/vertex-ai/docs/generative-ai/embeddings/get-text-embeddings">Vertex AI Embeddings for Text</a>と<a href="https://cloud.google.com/vertex-ai/docs/matching-engine/overview?hl=ja">Vertex AI Matching Engine</a>を使うことで、外部のビジネスデータから所望の文書を検索可能</li><li><a href="https://cloud.google.com/vertex-ai/docs/generative-ai/learn/generative-ai-studio">Generative AI Studio</a>という開発環境が用意されており、プロンプトの設計&#x2F;テスト、基盤モデルのファインチューニングができる</li></ul><details><summary>構成図</summary><p>記事執筆現在（2023年6月14日）GCPにおける、LLMを含む構成例は見当たりませんでしたが、<br>以下にグラウンディング（&#x3D;LLMモデルがLLM外部のデータに接続すること）の構成の概略を示します。</p><img src="/images/20230913a/GCP_arch.png" alt="GCP_arch" width="1200" height="676" loading="lazy"><p>引用元: <a href="https://cloud.google.com/blog/ja/products/ai-machine-learning/how-to-use-grounding-for-your-llms-with-text-embeddings">Google Cloud Japan ブログ</a></p></details><h2 id="おわりに"><a href="#おわりに" class="headerlink" title="おわりに"></a>おわりに</h2><p>本記事では、「LLM開発のためにMLOpsチームがやるべきこと」というテーマでLLMのMLOpsに関連する部分を幅広くご紹介しました。</p><p>これからLLM開発を検討している方々やMLOpsに携わっている方々の参考となれば幸いです。</p><p><a href="/articles/20230914a/">【LLMOps】LLMの実験管理にTruLens-Evalを使ってみた</a>の記事も公開されました。合わせてご覧ください。</p><p>（2023年9月19日追記）関連して <a href="/articles/20230919a/">Prompt Flowでプロンプト評価の管理を行う</a> という記事も公開しました。</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h2 id=&quot;はじめに&quot;&gt;&lt;a href=&quot;#はじめに&quot; class=&quot;headerlink&quot;</summary>
        
      
    
    
    
    <category term="DataScience" scheme="https://future-architect.github.io/categories/DataScience/"/>
    
    
    <category term="インターン" scheme="https://future-architect.github.io/tags/%E3%82%A4%E3%83%B3%E3%82%BF%E3%83%BC%E3%83%B3/"/>
    
    <category term="MLOps" scheme="https://future-architect.github.io/tags/MLOps/"/>
    
    <category term="LLM" scheme="https://future-architect.github.io/tags/LLM/"/>
    
    <category term="インターン2023" scheme="https://future-architect.github.io/tags/%E3%82%A4%E3%83%B3%E3%82%BF%E3%83%BC%E3%83%B32023/"/>
    
  </entry>
  
  <entry>
    <title>LLM開発のフロー</title>
    <link href="https://future-architect.github.io/articles/20230912a/"/>
    <id>https://future-architect.github.io/articles/20230912a/</id>
    <published>2023-09-11T15:00:00.000Z</published>
    <updated>2023-10-02T00:07:27.506Z</updated>
    
    <content type="html"><![CDATA[<h1 id="はじめに"><a href="#はじめに" class="headerlink" title="はじめに"></a>はじめに</h1><p>こんにちは、SAIG&#x2F;MLOpsチームでアルバイトをしている板野・平野です。</p><p>今回は、昨今注目されている大規模言語モデル(LLM)の開発においてMLOpsチームがやるべきことを考えるため、まずはLLM開発の流れを調査・整理しました。</p><p>本記事はその内容を「LLM開発のフロー」という題目でまとめたものです。LLMを本番運用するときに考慮すべきこと、LLM開発・運用を支援するサービスやツール・LLMシステムの構成例などについては、「<a href="/articles/20230913a/">LLM開発でMLOpsチームがやるべきこと</a>」と題して別記事でご紹介していますので、ぜひ併せてご覧ください。</p><p>ここでのLLM開発とは、「LLM自体の開発」および「LLMを活用したシステム開発」の両方を含みます。また、「LLM自体の開発」は学習フェーズ、「LLMを活用したシステム開発」は推論フェーズ、として記載しています。</p><p>本記事ではLLM開発における各フェーズのフローを解説します。</p><h1 id="LLM開発のフロー"><a href="#LLM開発のフロー" class="headerlink" title="LLM開発のフロー"></a>LLM開発のフロー</h1><p>LLM開発は下図のように、LLM自体の開発（<a href="#1-%E3%83%A2%E3%83%87%E3%83%AB%E3%82%92%E7%94%A8%E6%84%8F%E3%81%99%E3%82%8B%E5%AD%A6%E7%BF%92">1.モデルを用意する（学習）</a>）とLLMを活用したシステム開発（<a href="#2-%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E8%83%BD%E5%8A%9B%E3%82%92%E5%BC%95%E3%81%8D%E5%87%BA%E3%81%99%E6%8E%A8%E8%AB%96">2.モデルの能力を引き出す（推論）</a>）の大きく2つのフェーズに分けられます。</p><img src="/images/20230912a/LLM_dev.png" alt="LLM_dev.png" width="960" height="540" loading="lazy"><p>以下、各フェーズについて詳しく解説します。</p><h2 id="1-モデルを用意する（学習）"><a href="#1-モデルを用意する（学習）" class="headerlink" title="1. モデルを用意する（学習）"></a>1. モデルを用意する（学習）</h2><p>モデルを用意するには、大きく分けて以下の3つの方法があります。</p><ul><li>(A) ゼロからモデルを学習する</li><li>(B) 公開済みの基盤モデルから学習する</li><li>(C) プロプライエタリモデルを利用する</li></ul><p>※プロプライエタリモデル：ソースコードや構造等が非公開なモデルのこと。<br>（例）ChatGPT(GPT-3.5)やGPT-4等</p><p>どの方法を用いてLLM開発を行うべきかについては、要件に応じて決定します。<br>各方法のメリット・デメリットについては下表をご参考ください。</p><div class="scroll"><table><thead><tr><th></th><th>(A) ゼロからモデルを学習する</th><th>(B) 公開済みの基盤モデルから学習する</th><th>(C) プロプライエタリモデルを利用する</th></tr></thead><tbody><tr><td>メリット</td><td>・モデル構造を自由に選択可能<br>・使用した全データセットを把握可能</td><td>・基盤モデル作成のコスト不要<br>・様々な公開基盤モデルを試せる</td><td>・推論リソースの用意が不要<br>・汎用的なタスクにおいて高品質</td></tr><tr><td>デメリット</td><td>・学習に大量の計算リソースの用意が必要<br>・推論リソースの用意が必要</td><td>・基盤モデルのライセンスに依存<br>・推論リソースの用意が必要</td><td>・オンプレ運用ができない<br>・モデルが意図しないタイミングで更新される可能性がある</td></tr></tbody></table></div><p>以下、モデルを用意するための各方法の詳細を解説していきます。</p><h3 id="A-ゼロからモデルを学習する"><a href="#A-ゼロからモデルを学習する" class="headerlink" title="(A) ゼロからモデルを学習する"></a>(A) ゼロからモデルを学習する</h3><p>ChatGPT(GPT-3.5)と学習方法が同じInstructGPTと呼ばれるモデルの学習方法は、論文として公開されており、下図のようなフローで学習されています。</p><p>※論文リンクはこちらです。<br><a href="https://arxiv.org/abs/2203.02155">Training language models to follow instructions with human feedback</a></p><img src="/images/20230912a/flow_from_scratch.png" alt="flow_from_scratch" width="902" height="283" loading="lazy"><ul><li>①大量のコーパスで学習<ul><li>未学習モデルに対して大量のコーパス（自然言語の文）で学習を行い、基盤モデルを構築</li><li>次に来る単語（next-token）を予測するモデルとなるため、それっぽい文章を作成できる</li><li>基盤モデルは、質問に答えたり対話したりする能力が乏しい</li></ul></li><li>②教師ありファインチューニング（SFT）<ul><li>基盤モデルに対して「指示文・コンテキスト・理想の回答を人力で集めたデータセット」でファインチューニングする</li><li>人力で集めたデータセットとは、<a href="https://huggingface.co/datasets/kunishou/databricks-dolly-15k-ja">こちら</a>にあるような指示文(instruction)、コンテキスト(input)、理想の回答(output)がセットになったもの</li><li>ファインチューニングして得られるモデルはSFT(Supervised Fine-Tuning)モデルという</li><li>SFTモデルには、質問に答えたり対話したりする等のタスク処理能力がある</li></ul></li><li>③人間のフィードバックによる強化学習（RLHF）<ul><li>人間のフィードバックによる強化学習のことをReinforcement Learning from Human Feedback(RLHF)と呼ぶ</li><li>SFTモデルに対して、文の品質をより向上させるためにRewardモデルを使用して強化学習を行う</li><li>Rewardモデルとは、文章を入力すると、その文章の評価を数値として出力してくれるモデルのこと</li><li>Rewardモデルは人間のフィードバック等を利用して別途作成しなければならない</li><li>SFTモデルと比べ、人間にとってより好ましく流暢な出力が得られるようになる</li></ul></li></ul><p>①まで完了すると、プロンプトに続く文を次々と出力するだけのモデルが完成します。</p><p>LLM開発に、まずこのプロセスは必須です。この時点ではまだ要約や質疑応答などのタスクに対するファインチューニングが行われていないため、要約や質疑応答等のタスクをさせようとしても返答が不安定です。基盤モデルの学習データで<code>「日本の首都は？東京です。」</code>や<code>「要約してください。&quot;&quot;&quot;&lt;要約したい文書&gt;&quot;&quot;&quot;。」</code> のようなinstructionのアノテーションが付いているものは極めて稀で、なにか特定のタスクを解かせるための学習がされていないからです。</p><p>②まで完了すると、質問に答えたり、対話したりする能力がついたモデルが完成します。この時点で、基本的なタスクを行うのに最低限のことは身についているため、より実用に近づきます。このプロセスは大半のケースで必要だと考えられます。</p><p>③まで完了すると、人間にとってより好ましい出力ができるモデルが完成します。ここまでするか否かは、要件やモデルに行わせたいタスクによって判断します。</p><div class="note info" style="background: #e5f8e2; padding:16px; margin:24px 12px; border-radius:8px;">  <span class="fa fa-fw fa-check-circle"></span><p>ゼロからモデルを学習する場合に必要な計算リソースの参考値をご紹介します。</p><p>GPT-3に似たBLOOMというモデルは1760億のパラメータを持っており、<a href="https://bigscience.huggingface.co/blog/bloom">BLOOMの発表記事</a>では、学習に<code>117日</code>掛かり、<code>300万ユーロ（約4.5億円）</code>もの金銭的コストが掛かったと述べられています。</p><p>ただし、LLM関連の技術の進歩は早く、学習方法を工夫することで大幅に計算コストを減らしたり、パラメータ数が小さいモデルを使っても高い精度が出せたり等、より時間やコストを抑えられるようになってきています。</p></div><h3 id="B-公開済みの基盤モデルから学習する"><a href="#B-公開済みの基盤モデルから学習する" class="headerlink" title="(B) 公開済みの基盤モデルから学習する"></a>(B) 公開済みの基盤モデルから学習する</h3><p>最近では基盤モデルがオープンソースで公開されるようになってきています。</p><p>公開されている基盤モデルを使用すれば、「ゼロからLLMを学習する」の学習フローにおいて大きなコストを要する「①大量のコーパスで学習」のプロセスをスキップできます。</p><p>公開されている基盤モデルからは、以下のようなフローで追加学習を行います。</p><img src="/images/20230912a/from_base_model.png" alt="from_base_model" width="899" height="280" loading="lazy"><ul><li>①公開されている基盤モデルの選定<ul><li>商用利用可能なものは、<a href="https://ai.meta.com/llama/">Llama 2 (ラマツー)</a>や<a href="https://huggingface.co/rinna">rinna</a>, <a href="https://huggingface.co/cyberagent">OpenCALM</a>などがあり様々な選択肢から選択できる<ul><li>※公開済みモデルの中でも、<a href="https://rinna.co.jp/news/2023/05/20220531.html">rinna (japanese-gpt-neox-3.6b-instruction-ppo)</a>のようにファインチューニングや強化学習が行われているものもあります</li></ul></li><li>モデル選定には「公開済みの基盤モデルが学習に用いたデータセット」や「パラメータ数」等を参考にする</li></ul></li><li>②教師ありファインチューニング（SFT）<ul><li>※ <strong>(A)ゼロからモデルを学習する</strong>と同じ</li></ul></li><li>③人間のフィードバックによる強化学習（RLHF）<ul><li>※ <strong>(A)ゼロからモデルを学習する</strong>と同じ</li></ul></li></ul><div class="note info" style="background: #e5f8e2; padding:16px; margin:24px 12px; border-radius:8px;">  <span class="fa fa-fw fa-check-circle"></span><p>公開済みの基盤モデルから学習する場合に必要な計算リソースの参考値をご紹介します。</p><p>ゼロから学習する場合と比べ、ファインチューニングから始める場合は効率的なファインチューニング手法(Parameter-Efficient Fine-Tuning: PEFT)が複数あります。</p><p><a href="https://note.com/npaka/n/na5b8e6f749ce">こちらの事例</a>ではLoRAというPEFT手法や8ビット量子化等のメモリ削減手法を適用し、<code>VRAM使用量:23.5GB</code>で1台のGPUでファインチューニングができています。</p></div><h3 id="C-プロプライエタリモデルを利用する"><a href="#C-プロプライエタリモデルを利用する" class="headerlink" title="(C) プロプライエタリモデルを利用する"></a>(C) プロプライエタリモデルを利用する</h3><p>OpenAI等のAPI経由で公開されているモデルを利用する方法です。<br>現状、LLMを手軽に用意するにはこの方法が一番です。</p><img src="/images/20230912a/proprietary.png" alt="proprietary" width="757" height="257" loading="lazy"><p>そのまま使うこともできますが、API経由でプロプライエタリモデルをファインチューニングすることもできます。<br><a href="https://platform.openai.com/docs/guides/fine-tuning">OpenAIのドキュメント</a>によると、ファインチューニングで以下のような効果が期待できるようです。</p><ul><li>プロンプトで調整するよりも高品質な結果</li><li>プロンプトに収まらない程の多くの例でトレーニング可能</li><li>プロンプトを短くできることによるトークンの節約・レイテンシの減少</li></ul><h2 id="2-モデルの能力を引き出す（推論）"><a href="#2-モデルの能力を引き出す（推論）" class="headerlink" title="2. モデルの能力を引き出す（推論）"></a>2. モデルの能力を引き出す（推論）</h2><p>続いて、LLMを活用したシステム開発（推論フェーズ）について解説します。</p><p>従来のMLモデルは入出力の形式が一定で、分類や予測などの特定のタスクに活用する使い方が主流でした。<br>一方、LLMは汎用的なモデルであるため、1つのLLMモデルであらゆるタスク（質問応答、要約など）をこなすことができます。<br>このため、LLMモデルを入手したら、タスクを正しくこなせるように入力（プロンプト）を調節してモデルの能力を最大限引き出す工夫が新たに必要となりました。</p><img src="/images/20230912a/prompt_eng_grnd.png" alt="prompt_eng_grnd" width="861" height="383" loading="lazy"><p>図内のバックエンドプログラムとして挙げられている<a href="https://langchain.com/">LangChain</a>とは、モデルの能力を引き出すあらゆる部分を効率化するライブラリで、知識データへの円滑なアクセス等も実装することができます。</p><p>モデルの能力を最大限引き出す工夫として、大きく以下の2つの要素があります。</p><ul><li>①プロンプトエンジニアリング<ul><li>LLMへの「聞き方」を工夫することで質問応答や算術推論などのタスク処理能力を向上させる</li><li>プロンプトの中に望ましい答え方のフォーマット等を埋め込んだり、例示したりする</li><li>望んだ回答が返ってこない確率を減らす</li></ul></li><li>②グラウンディング（任意）<ul><li><a href="https://book.st-hakky.com/docs/llm-grounding/">グラウンディング</a>とは、仮想世界で存在するLLM等のシステムを現実世界と繋げること<ul><li>現実世界にアクセスして情報検索をしたり、コマンドを発生したりする等</li></ul></li><li>LLM単体が知らないことでも答えられるようにするための知識データを用意する<ul><li>文の要約など、外部知識を要しない質問の場合は不要</li></ul></li><li>知識データの情報をプロンプトに付加することでLLMが知らない事も答えられるようになる</li><li>LLMの特徴である、嘘をつくこと（&#x3D;幻覚：Hallucination）を抑えられる</li><li>出力の根拠が把握できる</li></ul></li></ul><h3 id="①プロンプトエンジニアリング"><a href="#①プロンプトエンジニアリング" class="headerlink" title="①プロンプトエンジニアリング"></a>①プロンプトエンジニアリング</h3><p>プロンプトエンジニアリングの一例を以下にご紹介します。</p><ul><li>Zero-shotプロンプティング<ul><li>モデルに対して事前に情報や例を与えずに直接質問をすること</li><li>質問例）「次の文をポジティブかネガティブに分類してください」「次の文章を要約してください」「1+1&#x3D; 」等</li></ul></li><li>Few-shotプロンプティング<ul><li>モデルに対して事前にいくつかの例を提示してから質問すること</li><li>質問例）「1+1&#x3D;2, 3+3&#x3D;6, 4+4&#x3D; 」「みかん→フルーツ, サッカー→スポーツ, 猫→ 」等</li></ul></li><li>Chain-of-Thought（CoT）プロンプティング<ul><li>モデルに中間的な推論ステップ（思考過程）を介するように促すこと</li><li>「ステップバイステップで考えてみましょう。」の文言を入れるだけで良い結果が得られることがある</li><li>質問例）「6個のバナナを買いました。それを友達に2つ渡しました。それから3つのバナナを買って1つ食べました。残りは何個ですか？ ステップバイステップで考えてみましょう。」<br>他にもプロンプトエンジニアリングやその他の技術は多々あります。興味のある方は、<a href="https://www.promptingguide.ai/jp">こちら</a>のサイトが参考になります。</li></ul></li></ul><h3 id="②グラウンディング（任意）"><a href="#②グラウンディング（任意）" class="headerlink" title="②グラウンディング（任意）"></a>②グラウンディング（任意）</h3><p>グラウンディングの一例として、「ベクトルデータベースに知識データを格納しておき、検索クエリから類似のテキストを上位数件分持ってくる」等が挙げられます。<br>これを実現するための大まかな手順は以下の通りです。</p><p>まず、以下の流れでベクトルデータベースを準備します。</p><img src="/images/20230912a/embedding.png" alt="embedding" width="713" height="354" loading="lazy"><ul><li>文書を用意する（社内QAチャットを作りたい場合は社内文書など）</li><li>文書が長い場合、チャンク分けをする（短い文書&#x3D;チャンクに切り分ける）</li><li>テキストをチャンク毎に低次元空間に埋め込む (Embeddingを作成する &#x2F; ベクトル化する)<ul><li>テキストを入力として受け取り、ベクトルを出力してくれる、エンベディングモデルというモデルがある</li><li>そのようなモデルは様々あり、OpenAIの<a href="https://platform.openai.com/docs/guides/embeddings/what-are-embeddings">text-embedding-ada-002</a>が高性能なモデルとして挙げられる</li></ul></li><li>チャンク毎に、「テキスト」と「ベクトル」の対をベクトルDBとして格納する</li></ul><p>ベクトルDBが作成できたら、以下のように利用します。</p><img src="/images/20230912a/grounding.png" alt="grounding" width="960" height="504" loading="lazy"><ul><li>ユーザーの質問文を元に、LLMが検索クエリを生成する<ul><li>ユーザーの質問が単純であれば、その質問をそのままクエリとしてもよい</li></ul></li><li>検索クエリのテキストをベクトル化する<ul><li>ベクトルDBを作成するときに使用したエンベディングモデルと同じものを利用する</li></ul></li><li>ベクトルDBに格納されている各ベクトルと、クエリのベクトルとの類似度を計算する</li><li>類似度が高い上位のテキスト（チャンク）を取り出し、LLMのプロンプトに含める</li></ul><p>基本となる考え方は以上ですが、これを簡単に実現できるようにクラウドサービスやライブラリとして提供されているものもあります。</p><p>ツール等の詳細は後日、別記事にて解説予定です。</p><h1 id="まとめ"><a href="#まとめ" class="headerlink" title="まとめ"></a>まとめ</h1><p>本記事では「LLM開発のフロー」と題し、LLM自体の開発およびLLMを活用したシステム開発のフローをご紹介しました。</p><p>これからLLM開発を検討している方々やMLOpsに携わっている方々の参考となれば幸いです。</p><p>今回ご紹介した「LLM開発のフロー」を前提とした、<a href="/articles/20230913a/">LLM開発でMLOpsチームがやるべきこと</a>についてもぜひ併せてご覧ください。</p><p>（2023年9月19日追記）関連して <a href="/articles/20230919a/">Prompt Flowでプロンプト評価の管理を行う</a> という記事も公開しました。</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h1 id=&quot;はじめに&quot;&gt;&lt;a href=&quot;#はじめに&quot; class=&quot;headerlink&quot;</summary>
        
      
    
    
    
    <category term="DataScience" scheme="https://future-architect.github.io/categories/DataScience/"/>
    
    
    <category term="インターン" scheme="https://future-architect.github.io/tags/%E3%82%A4%E3%83%B3%E3%82%BF%E3%83%BC%E3%83%B3/"/>
    
    <category term="LLM" scheme="https://future-architect.github.io/tags/LLM/"/>
    
    <category term="インターン2023" scheme="https://future-architect.github.io/tags/%E3%82%A4%E3%83%B3%E3%82%BF%E3%83%BC%E3%83%B32023/"/>
    
    <category term="プロンプトエンジニアリング" scheme="https://future-architect.github.io/tags/%E3%83%97%E3%83%AD%E3%83%B3%E3%83%97%E3%83%88%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2%E3%83%AA%E3%83%B3%E3%82%B0/"/>
    
  </entry>
  
  <entry>
    <title>SwiftUIのカスタムアラートダイアログについて考える</title>
    <link href="https://future-architect.github.io/articles/20230908a/"/>
    <id>https://future-architect.github.io/articles/20230908a/</id>
    <published>2023-09-07T15:00:00.000Z</published>
    <updated>2023-10-02T00:07:27.505Z</updated>
    
    <content type="html"><![CDATA[<h1 id="はじめに"><a href="#はじめに" class="headerlink" title="はじめに"></a>はじめに</h1><p>こんにちは。HealthCare Innovation Group(HIG)<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>所属の清水です。</p><p>本記事は、<a href="/articles/20230830a/" title="夏の自由研究連載2023 を始めます">夏の自由研究ブログ連載2023</a>の5本目です。</p><p>SwiftUIにおけるアラートダイアログを自作で実装する場合、どんな方法があるか考えてみました。</p><p>Swiftを用いたiOSアプリ開発で、アラートを自作したいと考えたことはありませんか？Webアプリでもモバイルアプリでも、ユーザに問題を報告したり動作による影響を警告したりする上で、アラートは重要です。</p><p>SwiftUIでも<a href="https://developer.apple.com/documentation/SwiftUI/View/alert(_:isPresented:actions:)-1bkka"><code>alert</code></a>が標準で用意されています。ただし、フォントサイズやダイアログのサイズが変更できないため、iPadで利用する場合画面に対してかなり小さく扱いづらいです。</p><p>SwiftUI標準の<code>alert</code>をシミュレータ iPad Pro (12.9-inch) で表示した際の図</p><img src="/images/20230908a/68747470733a2f2.png" alt="" width="1200" height="1643" loading="lazy"><p>画面に対してかなり小さい・・・。</p><p>そこで、「自由にカスタマイズできるアラートダイアログを自作する場合、どのような実装方法があるか」を自由研究の題材とすることにしました。</p><p>今回試してみた3種類のカスタムアラートを、実装方法と共に紹介したいと思います。<br>※もっと良い実装方法をご存知でしたら、教えていただきたいです！</p><div class="note info" style="background: #e5f8e2; padding:16px; margin:24px 12px; border-radius:8px;">  <span class="fa fa-fw fa-check-circle"></span><p>本記事では触れていませんが、カスタムアラートダイアログに関するライブラリも公開されています。合わせて確認頂けると良いと思います。（例: <a href="https://github.com/divadretlaw/CustomAlert">CustomAlert</a>）</p></div><h1 id="検証内容"><a href="#検証内容" class="headerlink" title="検証内容"></a>検証内容</h1><p>アラートは、通常の画面より手前（通常画面に重なる形）に表示します。<br>今回は、重ねて表示するためのコンポーネントの中から、以下の3種類の実装方法で比較していきたいと思います。</p><ol><li><code>fullScreenCover</code>を利用した方法</li><li><code>overlay</code>を利用した方法</li><li><code>ZStack</code>を利用した方法</li></ol><h2 id="事前準備"><a href="#事前準備" class="headerlink" title="事前準備"></a>事前準備</h2><p>画面に重ねて表示するためのダイアログをViewとして用意しています。SwiftUI標準の<code>alert</code>に見た目を寄せたアラートViewを、iPad Pro (12.9-inch) 向けにサイズ調整したViewがこちらです。このViewをいくつかの方法で重ねていきます。</p><p>※実装は、記事後半に記載しています。</p><img src="/images/20230908a/68747470733a2f2_2.png" alt="" width="1140" height="1420" loading="lazy"><h2 id="1-fullScreenCoverを利用した方法"><a href="#1-fullScreenCoverを利用した方法" class="headerlink" title="1. fullScreenCoverを利用した方法"></a>1. <code>fullScreenCover</code>を利用した方法</h2><p>一つ目は、<a href="https://developer.apple.com/documentation/swiftui/view/fullscreencover(ispresented:ondismiss:content:)"><code>fullScreenCover</code></a>を利用した方法です。</p><p>引数に渡したフラグがtrueの時、全画面を覆うViewをモーダル表示します。</p><p>他の方法と比較</p><ul><li>メリット<ul><li>画面全体にモーダル表示するため、アラート表示中に他の動作ができないように制限しやすい。</li></ul></li><li>デメリット<ul><li><code>fullScreenCover</code> は表示時に画面下から上まで覆うアニメーションを伴って表示するため、アニメーションのカスタマイズが難しい。（調べた限りほぼできない。）<br>アニメーションを非活性にすることはできる。<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup></li></ul></li></ul><img src="/images/20230908a/68747470733a2f2.gif" alt="" width="75%" loading="lazy"><h2 id="2-overlayを利用した方法"><a href="#2-overlayを利用した方法" class="headerlink" title="2. overlayを利用した方法"></a>2. <code>overlay</code>を利用した方法</h2><p>二つ目は、<a href="https://developer.apple.com/documentation/swiftui/view/overlay(alignment:content:)"><code>overlay</code></a>を利用した方法です。<br>名前の通り、親Viewより手前に指定したViewを重ねて表示します。アラートの使用用途を考えるとちょうど良さそうです。</p><p>他の方法と比較</p><ul><li>メリット<ul><li><code>overlay</code>自体は重ねて表示するだけなので、アニメーションなどをカスタマイズしやすい。</li></ul></li><li>デメリット<ul><li>あくまでも元となるViewに重ねるため、重ねて表示する範囲は呼び出すViewに依存する。<br>例えば、<code>VStack</code>に紐づけると<code>VStack</code>の範囲が重ねるViewの表示範囲となり、表示範囲外は操作できてしまう。（下のgif参照）</li></ul></li></ul><img src="/images/20230908a/68747470733a2f2_2.gif" alt="" width="75%" loading="lazy"><h2 id="3-ZStackを利用した方法"><a href="#3-ZStackを利用した方法" class="headerlink" title="3. ZStackを利用した方法"></a>3. <code>ZStack</code>を利用した方法</h2><p>三つ目は、<a href="https://developer.apple.com/documentation/swiftui/zstack"><code>ZStack</code></a>を利用した方法です。<br><code>fullScreenCover</code>や<code>overlay</code>はViewのInstance Methodを利用していたのですが、こちらは内包するViewの表示順を制御するものなので、毛色が異なります。</p><p>他の方法と比較</p><ul><li>メリット<ul><li>アプリ大元のViewに重ねることで、画面全体を覆って表示制御できる。</li></ul></li><li>デメリット<ul><li>ダイアログ表示を制御するフラグやダイアログに表示する内容を<code>App</code>階層まで伝える必要があるため、単一のView内で状態管理が完結しない。</li></ul></li></ul><img src="/images/20230908a/68747470733a2f2_3.gif" alt="" width="75%" loading="lazy"><h2 id="コード実装例"><a href="#コード実装例" class="headerlink" title="コード実装例"></a>コード実装例</h2><p>今回利用したソースコードは、こちらです。</p><h3 id="App"><a href="#App" class="headerlink" title="App"></a>App</h3><figure class="highlight swift"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">IsShowAlert</span>: <span class="title class_">EnvironmentKey</span> &#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">let</span> defaultValue: <span class="type">Binding</span>&lt;<span class="type">Bool</span>&gt; <span class="operator">=</span> .constant(<span class="literal">false</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">extension</span> <span class="title class_">EnvironmentValues</span> &#123;</span><br><span class="line">    <span class="keyword">var</span> isShowAlert: <span class="type">Binding</span>&lt;<span class="type">Bool</span>&gt; &#123;</span><br><span class="line">        <span class="keyword">get</span> &#123; <span class="keyword">self</span>[<span class="type">IsShowAlert</span>.<span class="keyword">self</span>] &#125;</span><br><span class="line">        <span class="keyword">set</span> &#123; <span class="keyword">self</span>[<span class="type">IsShowAlert</span>.<span class="keyword">self</span>] <span class="operator">=</span> newValue &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">@main</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">SampleApp</span>: <span class="title class_">App</span> &#123;</span><br><span class="line">    <span class="meta">@State</span> <span class="keyword">private</span> <span class="keyword">var</span> isShowAlert: <span class="type">Bool</span> <span class="operator">=</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> body: <span class="keyword">some</span> <span class="type">Scene</span> &#123;</span><br><span class="line">        <span class="type">WindowGroup</span> &#123;</span><br><span class="line">            <span class="type">ZStack</span> &#123;</span><br><span class="line">                <span class="type">ContentView</span>()</span><br><span class="line">                    .environment(\.isShowAlert, <span class="variable">$isShowAlert</span>)</span><br><span class="line">                <span class="comment">/// 3. `ZStack`を利用した実装方法</span></span><br><span class="line">                <span class="keyword">if</span> isShowAlert &#123;</span><br><span class="line">                    <span class="type">CustomAlertView</span>(alertTitle: <span class="type">Text</span>(<span class="string">&quot;タイトル&quot;</span>)) &#123;</span><br><span class="line">                        <span class="type">Button</span>(<span class="string">&quot;OK&quot;</span>) &#123;</span><br><span class="line">                            <span class="variable">$isShowAlert</span>.wrappedValue.toggle()</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125; message: &#123;</span><br><span class="line">                        <span class="type">Text</span>(<span class="string">&quot;メッセージ&quot;</span>)</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="ContentView"><a href="#ContentView" class="headerlink" title="ContentView"></a>ContentView</h3><figure class="highlight swift"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">ContentView</span>: <span class="title class_">View</span> &#123;</span><br><span class="line">    <span class="comment">/// 標準アラートの表示を管理するフラグ</span></span><br><span class="line">    <span class="meta">@State</span> <span class="keyword">var</span> isShowDefaultAlert: <span class="type">Bool</span> <span class="operator">=</span> <span class="literal">false</span></span><br><span class="line">    <span class="comment">/// `fullScreenCover`を利用したカスタムアラートの表示を管理するフラグ</span></span><br><span class="line">    <span class="meta">@State</span> <span class="keyword">var</span> isShowFullScreenCoverAlert: <span class="type">Bool</span> <span class="operator">=</span> <span class="literal">false</span></span><br><span class="line">    <span class="comment">/// `overlay`を利用したカスタムアラートの表示を管理するフラグ</span></span><br><span class="line">    <span class="meta">@State</span> <span class="keyword">var</span> isShowOverlayAlert: <span class="type">Bool</span> <span class="operator">=</span> <span class="literal">false</span></span><br><span class="line">    <span class="comment">/// `ZStack`を利用したカスタムアラートの表示を管理するフラグ</span></span><br><span class="line">    <span class="meta">@Environment</span>(\.isShowAlert) <span class="keyword">var</span> isShowAlert</span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> body: <span class="keyword">some</span> <span class="type">View</span> &#123;</span><br><span class="line">        <span class="type">ZStack</span> &#123;</span><br><span class="line">            <span class="type">VStack</span>(spacing: <span class="number">50</span>) &#123;</span><br><span class="line">                <span class="type">Button</span>(</span><br><span class="line">                    action: &#123;</span><br><span class="line">                        isShowDefaultAlert <span class="operator">=</span> <span class="literal">true</span></span><br><span class="line">                    &#125;,</span><br><span class="line">                    label: &#123;</span><br><span class="line">                        <span class="type">Text</span>(<span class="string">&quot;標準アラートを表示する&quot;</span>)</span><br><span class="line">                    &#125;</span><br><span class="line">                )</span><br><span class="line">                <span class="type">Button</span>(</span><br><span class="line">                    action: &#123;</span><br><span class="line">                        isShowFullScreenCoverAlert <span class="operator">=</span> <span class="literal">true</span></span><br><span class="line">                    &#125;,</span><br><span class="line">                    label: &#123;</span><br><span class="line">                        <span class="type">Text</span>(<span class="string">&quot;`fullScreenCover`のアラートを表示する&quot;</span>)</span><br><span class="line">                    &#125;</span><br><span class="line">                )</span><br><span class="line">                <span class="type">Button</span>(</span><br><span class="line">                    action: &#123;</span><br><span class="line">                        isShowOverlayAlert <span class="operator">=</span> <span class="literal">true</span></span><br><span class="line">                    &#125;,</span><br><span class="line">                    label: &#123;</span><br><span class="line">                        <span class="type">Text</span>(<span class="string">&quot;`overlay`のアラートを表示する&quot;</span>)</span><br><span class="line">                    &#125;</span><br><span class="line">                )</span><br><span class="line">                <span class="type">Button</span>(</span><br><span class="line">                    action: &#123;</span><br><span class="line">                        isShowAlert.wrappedValue <span class="operator">=</span> <span class="literal">true</span></span><br><span class="line">                    &#125;,</span><br><span class="line">                    label: &#123;</span><br><span class="line">                        <span class="type">Text</span>(<span class="string">&quot;`ZStack`のアラートを表示する&quot;</span>)</span><br><span class="line">                    &#125;</span><br><span class="line">                )</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        .alert(<span class="type">Text</span>(<span class="string">&quot;タイトル&quot;</span>), isPresented: <span class="variable">$isShowDefaultAlert</span>) &#123;</span><br><span class="line">            <span class="type">Button</span>(<span class="string">&quot;OK&quot;</span>) &#123;</span><br><span class="line">                isShowDefaultAlert.toggle()</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; message: &#123;</span><br><span class="line">            <span class="type">Text</span>(<span class="string">&quot;メッセージ&quot;</span>)</span><br><span class="line">        &#125;</span><br><span class="line">        .alertFullScreenCover(<span class="type">Text</span>(<span class="string">&quot;タイトル&quot;</span>), isPresented: <span class="variable">$isShowFullScreenCoverAlert</span>) &#123;</span><br><span class="line">            <span class="type">Button</span>(<span class="string">&quot;OK&quot;</span>) &#123;</span><br><span class="line">                isShowFullScreenCoverAlert.toggle()</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; message: &#123;</span><br><span class="line">            <span class="type">Text</span>(<span class="string">&quot;メッセージ&quot;</span>)</span><br><span class="line">        &#125;</span><br><span class="line">        .alertOverlay(<span class="type">Text</span>(<span class="string">&quot;タイトル&quot;</span>), isPresented: <span class="variable">$isShowOverlayAlert</span>) &#123;</span><br><span class="line">            <span class="type">Button</span>(<span class="string">&quot;OK&quot;</span>) &#123;</span><br><span class="line">                isShowOverlayAlert.toggle()</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; message: &#123;</span><br><span class="line">            <span class="type">Text</span>(<span class="string">&quot;メッセージ&quot;</span>)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Extensions"><a href="#Extensions" class="headerlink" title="Extensions"></a>Extensions</h3><figure class="highlight swift"><table><tr><td class="code"><pre><span class="line"><span class="keyword">extension</span> <span class="title class_">View</span> &#123;</span><br><span class="line">    <span class="comment">/// 1. `fullScreenCover`を利用した実装方法</span></span><br><span class="line">    <span class="keyword">func</span> <span class="title function_">alertFullScreenCover</span>&lt;<span class="type">A</span>, <span class="type">M</span>&gt;(</span><br><span class="line">        <span class="keyword">_</span> <span class="params">title</span>: <span class="type">Text</span>,</span><br><span class="line">        <span class="params">isPresented</span>: <span class="type">Binding</span>&lt;<span class="type">Bool</span>&gt;,</span><br><span class="line">        <span class="meta">@ViewBuilder</span> <span class="params">actions</span>: <span class="keyword">@escaping</span> () -&gt; <span class="type">A</span>,</span><br><span class="line">        <span class="meta">@ViewBuilder</span> <span class="params">message</span>: <span class="keyword">@escaping</span> () -&gt; <span class="type">M</span></span><br><span class="line">    ) -&gt; <span class="keyword">some</span> <span class="type">View</span> <span class="keyword">where</span> <span class="type">A</span> : <span class="type">View</span>, <span class="type">M</span> : <span class="type">View</span> &#123;</span><br><span class="line">        fullScreenCover(isPresented: isPresented) &#123;</span><br><span class="line">            <span class="type">CustomAlertView</span>(alertTitle: title, actions: actions, message: message)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/// 2. `overlay`を利用した実装方法</span></span><br><span class="line">    <span class="keyword">func</span> <span class="title function_">alertOverlay</span>&lt;<span class="type">A</span>, <span class="type">M</span>&gt;(</span><br><span class="line">        <span class="keyword">_</span> <span class="params">title</span>: <span class="type">Text</span>,</span><br><span class="line">        <span class="params">isPresented</span>: <span class="type">Binding</span>&lt;<span class="type">Bool</span>&gt;,</span><br><span class="line">        <span class="meta">@ViewBuilder</span> <span class="params">actions</span>: <span class="keyword">@escaping</span> () -&gt; <span class="type">A</span>,</span><br><span class="line">        <span class="meta">@ViewBuilder</span> <span class="params">message</span>: <span class="keyword">@escaping</span> () -&gt; <span class="type">M</span></span><br><span class="line">    ) -&gt; <span class="keyword">some</span> <span class="type">View</span> <span class="keyword">where</span> <span class="type">A</span> : <span class="type">View</span>, <span class="type">M</span> : <span class="type">View</span> &#123;</span><br><span class="line">        overlay &#123;</span><br><span class="line">            <span class="keyword">if</span> isPresented.wrappedValue &#123;</span><br><span class="line">                <span class="type">CustomAlertView</span>(alertTitle: title, actions: actions, message: message)</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="CustomAlertView"><a href="#CustomAlertView" class="headerlink" title="CustomAlertView"></a>CustomAlertView</h3><figure class="highlight swift"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> SwiftUI</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">CustomAlertView</span>&lt;<span class="title class_">A</span>, <span class="title class_">M</span>&gt;: <span class="title class_">View</span> <span class="title class_">where</span> <span class="title class_">A</span> : <span class="title class_">View</span>, <span class="title class_">M</span> : <span class="title class_">View</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> alertTitle: <span class="type">Text</span></span><br><span class="line">    <span class="meta">@ViewBuilder</span> <span class="keyword">var</span> actions: () -&gt; <span class="type">A</span></span><br><span class="line">    <span class="meta">@ViewBuilder</span> <span class="keyword">var</span> message: () -&gt; <span class="type">M</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> body: <span class="keyword">some</span> <span class="type">View</span> &#123;</span><br><span class="line">        <span class="type">ZStack</span> &#123;</span><br><span class="line">            <span class="comment">// 背景部分</span></span><br><span class="line">            <span class="type">Color</span>.black</span><br><span class="line">                .opacity(<span class="number">0.2</span>)</span><br><span class="line">                .edgesIgnoringSafeArea(.all)</span><br><span class="line">            <span class="comment">// ダイアログ部分</span></span><br><span class="line">            <span class="type">VStack</span> &#123;</span><br><span class="line">                alertTitle</span><br><span class="line">                    .font(.largeTitle)</span><br><span class="line">                    .bold()</span><br><span class="line">                    .padding(.top, <span class="number">20</span>)</span><br><span class="line">                    .padding(.bottom, <span class="number">10</span>)</span><br><span class="line">                message()</span><br><span class="line">                    .font(.title)</span><br><span class="line">                <span class="type">Divider</span>()</span><br><span class="line">                    .padding(.top, <span class="number">20</span>)</span><br><span class="line">                actions()</span><br><span class="line">                    .font(.title)</span><br><span class="line">                    .padding(.vertical, <span class="number">20</span>)</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line">            .frame(width: <span class="type">UIScreen</span>.main.bounds.width <span class="operator">/</span> <span class="number">2</span>)</span><br><span class="line">            .background(.white)</span><br><span class="line">            .cornerRadius(<span class="number">15</span>)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">CustomAlert_Previews</span>: <span class="title class_">PreviewProvider</span> &#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">var</span> previews: <span class="keyword">some</span> <span class="type">View</span> &#123;</span><br><span class="line">        <span class="type">CustomAlertView</span>(alertTitle: <span class="type">Text</span>(<span class="string">&quot;タイトル&quot;</span>), actions: &#123;</span><br><span class="line">            <span class="type">Button</span>(<span class="string">&quot;OK&quot;</span>) &#123;&#125;</span><br><span class="line">        &#125;, message: &#123;</span><br><span class="line">            <span class="type">Text</span>(<span class="string">&quot;メッセージ&quot;</span>)</span><br><span class="line">        &#125;)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="さいごに"><a href="#さいごに" class="headerlink" title="さいごに"></a>さいごに</h1><p>本記事では、自由研究としてアラートダイアログを自作する際の実装方法に関して、3種類を比較してみました。</p><p>アラートダイアログは性質上、表示中他の操作ができないことが求められると思います。今回試した中では、三つ目の<code>ZStack</code>を利用した方法がアプリ大元のViewに重ねることでアラートを一番手前に表示する要件を満たしやすいと感じました。</p><p>また、今回試して分かったメリット・デメリットを以下の表にまとめました。</p><div class="scroll"><table><thead><tr><th align="left">試した実装方法</th><th align="left">メリット</th><th align="left">デメリット</th></tr></thead><tbody><tr><td align="left">1. <code>fullScreenCover</code>を利用した方法</td><td align="left">画面全体にモーダル表示するため、アラート表示中に他の動作ができないように制限しやすい。</td><td align="left"><code>fullScreenCover</code> は表示時に画面下から上まで覆うアニメーションを伴って表示するため、アニメーションのカスタマイズが難しい。（調べた限りほぼできない。）</td></tr><tr><td align="left">2. <code>overlay</code>を利用した方法</td><td align="left"><code>overlay</code>自体は重ねて表示するだけなので、アニメーションなどをカスタマイズしやすい。</td><td align="left">あくまでも元となるViewに重ねるため、重ねて表示する範囲は呼び出すViewに依存する。</td></tr><tr><td align="left">3. <code>ZStack</code>を利用した方法</td><td align="left">アプリ大元のViewに重ねることで、画面全体を覆って表示制御できる。</td><td align="left">ダイアログ表示を制御するフラグやダイアログに表示する内容を<code>App</code>階層まで伝える必要があるため、単一のView内で状態管理が完結しない。</td></tr></tbody></table></div><p>何かしらの参考になれば幸いです。</p><h1 id="参考リンク"><a href="#参考リンク" class="headerlink" title="参考リンク"></a>参考リンク</h1><p><a href="https://developer.apple.com/documentation/SwiftUI/View/alert(_:isPresented:actions:)-1bkka">https://developer.apple.com/documentation/SwiftUI/View/alert(_:isPresented:actions:)-1bkka</a></p><p><a href="https://developer.apple.com/documentation/swiftui/view/fullscreencover(ispresented:ondismiss:content:)">https://developer.apple.com/documentation/swiftui/view/fullscreencover(ispresented:ondismiss:content:)</a></p><p><a href="https://developer.apple.com/documentation/swiftui/view/overlay(alignment:content:)">https://developer.apple.com/documentation/swiftui/view/overlay(alignment:content:)</a></p><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0;"><li id="fn:1"><span style="vertical-align: top; padding-right: 10px;">1.</span><span style="vertical-align: top;">医療・ヘルスケア分野での案件や新規ビジネス創出を担う、2020年に誕生した事業部です。設立エピソードは<a href="https://note.future.co.jp/n/n8b57d4bf4604" title="新規事業の立ち上げ　フューチャーの知られざる医療・ヘルスケアへの挑戦">未来報</a>の記事をご覧ください。</span><a href="#fnref:1" rev="footnote"> ↩</a></li><li id="fn:2"><span style="vertical-align: top; padding-right: 10px;">2.</span><span style="vertical-align: top;"><a href="https://stackoverflow.com/questions/69712759/swiftui-fullscreencover-with-no-animation">SwiftUI: fullScreenCover with no animation?</a></span><a href="#fnref:2" rev="footnote"> ↩</a></li></ol></div></div>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h1 id=&quot;はじめに&quot;&gt;&lt;a href=&quot;#はじめに&quot; class=&quot;headerlink&quot; title=&quot;はじめに&quot;&gt;&lt;/a&gt;はじめに&lt;/h1&gt;&lt;p&gt;こんにちは。HealthCare Innovation Group(HIG)&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a</summary>
        
      
    
    
    
    <category term="Programming" scheme="https://future-architect.github.io/categories/Programming/"/>
    
    
    <category term="iOS" scheme="https://future-architect.github.io/tags/iOS/"/>
    
    <category term="Swift" scheme="https://future-architect.github.io/tags/Swift/"/>
    
    <category term="SwiftUI" scheme="https://future-architect.github.io/tags/SwiftUI/"/>
    
    <category term="iPad" scheme="https://future-architect.github.io/tags/iPad/"/>
    
    <category term="iPhone" scheme="https://future-architect.github.io/tags/iPhone/"/>
    
  </entry>
  
  <entry>
    <title>Sentence-Transformersを使ってみた！YouTube動画のセリフを手軽にセマンティック検索</title>
    <link href="https://future-architect.github.io/articles/20230906a/"/>
    <id>https://future-architect.github.io/articles/20230906a/</id>
    <published>2023-09-05T15:00:00.000Z</published>
    <updated>2023-10-02T00:07:27.505Z</updated>
    
    <content type="html"><![CDATA[<h2 id="はじめに"><a href="#はじめに" class="headerlink" title="はじめに"></a>はじめに</h2><p>こんにちは。フューチャーTIG DXユニット所属の王です。</p><p>本記事は、<a href="/articles/20230830a/">夏の自由研究ブログ連載2023</a>の4本目です。</p><p>今回はテキストの埋め込みエンコーダーを使ってセマンティック検索をおもちゃレベルで簡単に実装する方法を紹介します。分かりやすいように、YouTubeの動画のセリフをコーパスとして使用します。将来的に時間軸のメタ情報も利用したら、検索結果には動画の何分何秒に特定、遷移リンクの生成などもいろいろ面白いことができると思います。</p><h2 id="目次"><a href="#目次" class="headerlink" title="目次"></a>目次</h2><ul><li>セマンティック検索を注目するきっかけ</li><li>セマンティック検索とは</li><li>原理<ul><li>埋め込みベクトル(Embedding Vector)</li><li>埋め込みベクトルを使ったセマンティック検索</li></ul></li><li>実装<ul><li>使ったライブラリ</li><li>Semantic Searchの実装</li></ul></li><li>まとめ</li></ul><h2 id="セマンティック検索を注目するきっかけ"><a href="#セマンティック検索を注目するきっかけ" class="headerlink" title="セマンティック検索を注目するきっかけ"></a>セマンティック検索を注目するきっかけ</h2><p>ChatGPTなどの生成AIが大ヒットしている現在、その応用場面は増加しており、自然言語で機械と会話し指示を与えたり情報を引いたりすることは今どきのトレンドになっています。しかし、生成AIを使用する際には、情報の最新性やファクトチェックの不足などの懸念点が存在します。これらの問題を低減するためには、なるべくコンテキストや背景情報など、比較的な高品質のインプットを提供し、生成式AIが得意な情報の抽出、変換、整形などのみ任せるのがうまい使い方でしょう。</p><p>生成AIに１回のクエリでインプットできる情報は限られていますので、事前に関係しそうな情報を粗く抽出するために、公開していないデータや特定のコーパスを使って、自然言語でクエリする際に、セマンティック検索が必要となります。</p><h2 id="セマンティック検索-Semantic-Search-とは"><a href="#セマンティック検索-Semantic-Search-とは" class="headerlink" title="セマンティック検索(Semantic Search)とは"></a>セマンティック検索(Semantic Search)とは</h2><p>最初に、セマンティック検索と典型的なレキシカル検索（語彙検索、字句検索、Lexical Search）を比較します。レキシカル検索は、テキスト内の文字列や単語の表面的な一致に焦点を当てます。特定の文字列や単語がテキスト内に存在するかどうかを確認し、その一致度に基づいて情報を選別します。そのため、同義語や関連語、コンテキストに対応することが難しく、意味的な関連性を欠いた検索結果になり、自然言語のクエリに対する弱点があります。</p><p>一方、セマンティック検索は、キーワードだけでなく、文脈や意味に基づいて情報を検索するアプローチです。関連性やコンテキストを考慮し、より高度な情報検索を実現でき、同義語や関連語、さらに部分的な誤字などにも対応できるため、自然言語のクエリに適しています。</p><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>テキストの埋め込みによってセマンティック検索の原理を簡単に説明します。</p><h3 id="埋め込みベクトル-Embedding-Vector"><a href="#埋め込みベクトル-Embedding-Vector" class="headerlink" title="埋め込みベクトル(Embedding Vector)"></a>埋め込みベクトル(Embedding Vector)</h3><p>コンピュータの世界には、文字だけではなく、画像、音声、動画などすべてのデータは符号化(Encoding)での表現ができます。それと似た思想で、単語、文、段落などを表す「意味」や「関連性」を数値のベクトルの表現で符号化に変換することは「埋め込み」と言います。その変換の条件は、意味が近い原文の変換後の埋め込みベクトルも距離が近いことです。</p><p>そうすることによって、統一化された表現形式「埋め込みベクトル」で「意味」の近さが定量的に表現で切るようになります。もちろん、文に対してベクトルの埋め込みは、深層学習などの技術を使って大量な事前計算が必要ですが、自ら訓練しても良いですし、後述のSentence-Transformerを利用して、公開の事前訓練された公開のモデルを簡単に使用できます。</p><p>ところで、ここの「距離」の定義は、ベクトルのドット積、コサイン類似度、ユークリッド距離など多数の形式はできますが、予め選定したら良いです。計算の簡単さを考慮したら、ユークリッド距離よりドット積、コサイン類似度のほうがよく採用されるでしょう。そしてベクトルを正規化（長さ1に統一する）のテクニックを使ったら、みんな等価になります。</p><p>さらに、もとの情報は文字に限らず、画像や音声、マルチメディアの情報も埋め込みベクトルに変換して数値化にしたら、文字と画像の距離や画像と音声の距離なども測ることが可能になります。画像や音声の類似検索、タグや説明文との紐付けなどいろいろ応用場面が可能になります。</p><h3 id="埋め込みベクトルを使ったセマンティック検索"><a href="#埋め込みベクトルを使ったセマンティック検索" class="headerlink" title="埋め込みベクトルを使ったセマンティック検索"></a>埋め込みベクトルを使ったセマンティック検索</h3><p>余談ですが、RDF (Resource Description Framework) を使用したセマンティック検索もありましたが、高度な事前定義と複雑のアルゴリズムが必要で実装は難しいです。今回ご紹介している埋め込みベクトルの手法は、事前のモデルの訓練での大量な計算でカバーしています。ただし、そのモデルの計算は、車輪の発明のように、大手が1度作ったら、誰でも繰り返して利用できて、恩恵を受けられます。これまで以上にAIの民主化を進めていますね。</p><p>さて、埋め込みベクトルを使ったセマンティック検索の手順を簡単にまとめます。</p><ol><li>事前にデータベースやコーパスの情報を文や段落粒度を分割し、それぞれ高次元(数百から数千次元)のベクトルに埋め込みエンコーディング変換しておきます。</li><li>クエリ文も同様に埋め込みエンコーディングして、ベクトル化して、それと距離が近いものが検索の候補結果になります。</li><li>計算した距離（近似度）がの検索のランキングになります。</li><li>（Optional）そして、検索の動作を高速化するために、事前のコーパスにベクトルによってインデックスをつけることができます。後述のSimple Neighborsはインデックスの構造と高速化検索をやってくれます。</li></ol><h2 id="実装"><a href="#実装" class="headerlink" title="実装"></a>実装</h2><h3 id="使ったライブラリ"><a href="#使ったライブラリ" class="headerlink" title="使ったライブラリ"></a>使ったライブラリ</h3><p>以下の2つのライブラリを使って実装しています。どれもシンプルなインターフェースを持って使いやすいと思います。</p><h4 id="Sentence-Transformers"><a href="#Sentence-Transformers" class="headerlink" title="Sentence-Transformers"></a>Sentence-Transformers</h4><p><a href="https://sbert.net/">https://sbert.net/</a></p><p>pipを使用して簡単にインストールできます。</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">pip install sentence-transformers</span><br></pre></td></tr></table></figure><p>Sentence-Transformersは、テキストだけではなく、画像のembeddingも対応できますが、今回はテキストの検索にフォーカスしたいので割愛します。画像の検索の詳細は<a href="https://sbert.net/examples/applications/image-search/README.html">このページ</a>をご参考ください。</p><p>Sentence-Transformersのフレームワークが<a href="https://huggingface.co/sentence-transformers">huggingface</a>で多数のモデルが公開しています（執筆時点124個）。</p><p>モデルの命名について、<code>qa</code>がついているモデルは、(質問、回答) ペアのセットでトレーニングされて、セマンティック検索用です。つまり、クエリ&#x2F;質問が与えられた場合、関連する文章を見つける用途です。そして、<code>multi</code>がついているモデルは、多言語対応のモデルです。違う言語のインプットであっても、意味が似たものなら埋め込みベクトルの距離が近いようにエンコーディングしてくれます。ちなみに、最初から多言語のデータを使わず、例えばまずは英語で訓練して、そのモデルを教師モデルとして利用し、更に多言語に拡張する手法もあるらしく、興味深いです。</p><h4 id="Simple-Neighbors"><a href="#Simple-Neighbors" class="headerlink" title="Simple Neighbors"></a>Simple Neighbors</h4><p><a href="https://simpleneighbors.readthedocs.io/en/latest/">https://simpleneighbors.readthedocs.io/en/latest/</a></p><p>コーパスの項目に対して最近傍検索を実行するための簡単なインターフェイスです。<br><code>Annoy</code>、<code>Sklearn</code>、<code>BruteForcePurePython</code>の3つのバックエンドをサポートしていますが、<code>Annoy</code>が推奨していますので、それも一緒にインストールします。</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">pip install simpleneighbors annoy</span><br></pre></td></tr></table></figure><p>高速に検索するため、事前にindexのツリーをビルドする必要があります。つまり、検索対象のデータを増加したら、改めてツイリーのビルドが必要という点に要注意です。</p><p>また、N-Neighborを探す結果は近似的な結果になることにもご注意ください。とはいえ、訓練のモデルから検索結果の精度はすべて有限であるので、近似と言っても十分な精度が保証できていると思います。（参考: <a href="https://en.wikipedia.org/wiki/Nearest_neighbor_search#Approximate_nearest_neighbor">Approximate Nearest Neighbors</a>）</p><h3 id="Semantic-Searchの実装"><a href="#Semantic-Searchの実装" class="headerlink" title="Semantic Searchの実装"></a>Semantic Searchの実装</h3><p>今回はこのドキュメントを参考して、実装してみました。</p><p><a href="https://www.sbert.net/examples/applications/semantic-search/README.html">https://www.sbert.net/examples/applications/semantic-search/README.html</a></p><p>まずは、<a href="https://www.youtube.com/watch?v=9tSEByUy47o&ab_channel=FUTURERecruiting/%E3%83%95%E3%83%A5%E3%83%BC%E3%83%81%E3%83%A3%E3%83%BC%E6%A0%AA%E5%BC%8F%E4%BC%9A%E7%A4%BE">フューチャーの会社紹介ページ</a>のYouTube動画のセリフを<code>corpus/future.txt</code>ファイルに保存します。今回は手動で前処理として文と文の間に改行で区切りました。<br>（<em>※YouTubeから自動生成のセリフで誤字などが入っています。一旦無視します。<br>ただし、「フューチャー」が「Qちゃん」になっているのはみっともないので手修正を加えました。</em>）</p><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">皆さん、こんにちは。</span><br><span class="line">フューチャーのWebセミナーにアクセスいただき、ありがとうございます。</span><br><span class="line">この動画ではフューチャーの会社概要とビジネスについてご紹介します。</span><br><span class="line">早速、会社概要からご紹介します。</span><br><span class="line">フューチャーは1989年にエンジニアが立ち上げたITコンサルティング企業です。</span><br><span class="line">創業時から、ITでビジネスを牽引することをコンセプトに掲げ、いわゆるDXにあたることを推進してきました。</span><br><span class="line">また、店頭公開時には日本で初めてITコンサルティング業として事業登録をされたのもフューチャーです。</span><br><span class="line">日本初のITコンサルティング企業であり、DXを30年以上推進してきた会社と覚えていただければと思います。</span><br><span class="line">業績も昨年は過去最高を更新するなど非常に順調です。</span><br><span class="line">次に、私たちが大切にしている考え方、Our Philosophyをご紹介します。</span><br><span class="line">「本質を見極める」、「大義を問う」、「初めてに挑戦する」、「難題を楽しむ」、「ないものはつくる」。</span><br><span class="line">例えば、創業当社から他の会社がなかなか手がけないような案件であったり、難しい案件に積極的にチャレンジしてきましたので、初めてに挑戦する難題を楽しむであったり、エンジニアニメが作り上げた会社というところもあり、ないものは何でも自分たちで作ってしまおう、そういったカルチャーも深く浸透しています。</span><br><span class="line">続いて、フューチャーのミッションを紹介します。</span><br><span class="line">お客様の未来活用を最大化し、自らも新たな価値を創造する。</span><br><span class="line">フューチャーグループには大きく2つの事業体があります。</span><br><span class="line">1つは、ITコンサルティング&amp;サービス事業です。</span><br><span class="line">こちらはお客様向けの課題解決をしていく事業群で、フューチャーアーキテクトがコアカンパニーとして、ITコンサルティングを牽引しています。</span><br><span class="line">もう一つはビジネスイノベーション事業です。</span><br><span class="line">こちらはこれまでのノウハウを生かして、自社でサービスを立ち上げようというもので、まさにお客様の未来活用を最大化するITコンサルティングと、自分たちでも新たな価値を創造していく両軸で事業を展開しています。</span><br><span class="line">ここからはフューチャーのビジネスについてご紹介します。</span><br><span class="line">フューチャーのお客様は、様々な業界そしてそれぞれの業界を代表するような企業様です。</span><br><span class="line">私たちは、私たちの強みであるITを用いて、それぞれのお客様の経営課題を解決したり、あるいはお客様と一緒に業界改革をIP戦略パートナーとしてになっています。</span><br><span class="line">私たちのビジネスの特徴をご紹介します。</span><br><span class="line">創業当初から、お客様の経営戦略、それを達成するための業務改革、そしてそれを支えているシステム改革。</span><br><span class="line">これらを三位一体で捉えてプロジェクトを推進してきました。</span><br><span class="line">昨今、DXと盛んに叫ばれるようになりましたが、私たちフューチャーは経営と業務、そしてその裏にあるシステムは切っても切り離せないものだと創業当初から考えて、それらを三位一体で捉えて推進するということを30年以上続けてきました。</span><br><span class="line">さらに詳細にビジネスの流れや他社との違いについてご紹介します。</span><br><span class="line">プロジェクトはどんな未来を描くのか、戦略を立て、計画に落として、その計画に則ってシステム的に具現化し、出来上がったシステムが価値を創造するという流れが一般的です。</span><br><span class="line">プロジェクトの推進体制で見てみると、一般的には得意な領域ごとに会社が複数社にまたがって行っているケースが多いです。</span><br><span class="line">例えば、未来を描くところはコンサル系の企業様が行って、具現化していくところはSIer系の企業様が行ってといった形です。</span><br><span class="line">あるいは、一つの会社であるけれど、コンサルタントとエンジニアのように職種が分かれているケースも多いかなと思います。</span><br><span class="line">では、フューチャーはどうかと言いますと、フィーチャーは図の通り、戦略からシステム構築運用まで一気通貫でになっています。</span><br><span class="line">また、職種もITコンサルタント職一触者です。</span><br><span class="line">戦略を立てるコンサルタントとしての部分と、システムを構築していくエンジニアとしての部分、どちらも一人一人のITコンサルタントが担っています。</span><br><span class="line">ソースコードレベルで相手を理解しているITコンサルタントが担うからこそ、絵に描いた餅で終わるというのではなくて、しっかりと価値を想像するところまで伴走できる。</span><br><span class="line">そしてそれを30年以上続けてきたというのはなかなか他の会社には簡単に真似できないフューチャーならではの強みになっています。</span><br><span class="line">また、皆さんのキャリアというのを考えてみていただいても、コンサルタントとエンジニア、どちらも一つの会社で経験できるというのはキャリアの幅が広がり、市場価値の高い人材に成長できると思っていただけると思います。</span><br><span class="line">最後に、フューチャーのことをもっと知りたい方に各種メディアをご紹介します。</span><br><span class="line">フューチャーのオウンドメディア未来報では、フューチャーの人に焦点を当ててキャリアやカルチャーをご紹介しています。</span><br><span class="line">フューチャーが大切にしている技術についてもっと深く知りたい方は、テックブログやテックキャストがおすすめです。</span><br><span class="line">最後までご覧いただき、ありがとうございます。</span><br><span class="line">皆さんと選考でお会いできることを楽しみにしております。</span><br></pre></td></tr></table></figure><p>今回は<a href="https://www.sbert.net/docs/pretrained_models.html">このページ</a>に紹介したモデルの中に、multi言語対応のモデルをピックアップし、予めメタデータとして用意します。モデル名<code>name</code>、ベクトルの次元<code>dims</code>、距離関数<code>metric</code>の属性を定義します。方便上、名前でモデルを引く関数<code>find_model_with_name</code>も定義します。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">models = [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment"># Multi-lingual model of Universal Sentence Encoder for 15 languages:</span></span><br><span class="line">        <span class="comment"># Arabic, Chinese, Dutch, English, French, German, Italian, Korean, Polish, Portuguese, Russian, Spanish, Turkish.</span></span><br><span class="line">        <span class="string">&quot;name&quot;</span>: <span class="string">&quot;distiluse-base-multilingual-cased-v1&quot;</span>,</span><br><span class="line">        <span class="string">&quot;dims&quot;</span>: <span class="number">512</span>,</span><br><span class="line">        <span class="string">&quot;metric&quot;</span>: <span class="string">&quot;angular&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment"># Multi-lingual model of Universal Sentence Encoder for 50 languages.</span></span><br><span class="line">        <span class="string">&quot;name&quot;</span>: <span class="string">&quot;distiluse-base-multilingual-cased-v2&quot;</span>,</span><br><span class="line">        <span class="string">&quot;dims&quot;</span>: <span class="number">512</span>,</span><br><span class="line">        <span class="string">&quot;metric&quot;</span>: <span class="string">&quot;angular&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment"># Multi-lingual model of paraphrase-multilingual-MiniLM-L12-v2, extended to 50+ languages.</span></span><br><span class="line">        <span class="string">&quot;name&quot;</span>: <span class="string">&quot;paraphrase-multilingual-MiniLM-L12-v2&quot;</span>,</span><br><span class="line">        <span class="string">&quot;dims&quot;</span>: <span class="number">384</span>,</span><br><span class="line">        <span class="string">&quot;metric&quot;</span>: <span class="string">&quot;angular&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment"># Multi-lingual model of paraphrase-mpnet-base-v2, extended to 50+ languages.</span></span><br><span class="line">        <span class="string">&quot;name&quot;</span>: <span class="string">&quot;paraphrase-multilingual-mpnet-base-v2&quot;</span>,</span><br><span class="line">        <span class="string">&quot;dims&quot;</span>: <span class="number">768</span>,</span><br><span class="line">        <span class="string">&quot;metric&quot;</span>: <span class="string">&quot;angular&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment"># This model was tuned for semantic search:</span></span><br><span class="line">        <span class="comment"># Given a query/question, if can find relevant passages.</span></span><br><span class="line">        <span class="comment"># It was trained on a large and diverse set of (question, answer) pairs.</span></span><br><span class="line">        <span class="comment"># 215M (question, answer) pairs from diverse sources.</span></span><br><span class="line">        <span class="string">&quot;name&quot;</span>: <span class="string">&quot;multi-qa-mpnet-base-dot-v1&quot;</span>,</span><br><span class="line">        <span class="string">&quot;dims&quot;</span>: <span class="number">768</span>,</span><br><span class="line">        <span class="string">&quot;metric&quot;</span>: <span class="string">&quot;dot&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment"># This model was tuned for semantic search:</span></span><br><span class="line">        <span class="comment"># Given a query/question, if can find relevant passages.</span></span><br><span class="line">        <span class="comment"># It was trained on a large and diverse set of (question, answer) pairs.</span></span><br><span class="line">        <span class="comment"># 215M (question, answer) pairs from diverse sources.</span></span><br><span class="line">        <span class="string">&quot;name&quot;</span>: <span class="string">&quot;multi-qa-mpnet-base-cos-v1&quot;</span>,</span><br><span class="line">        <span class="string">&quot;dims&quot;</span>: <span class="number">768</span>,</span><br><span class="line">        <span class="string">&quot;metric&quot;</span>: <span class="string">&quot;angular&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">find_model_with_name</span>(<span class="params">models, name</span>):</span><br><span class="line">    <span class="keyword">for</span> model <span class="keyword">in</span> models:</span><br><span class="line">        <span class="keyword">if</span> model[<span class="string">&quot;name&quot;</span>] == name:</span><br><span class="line">            <span class="keyword">return</span> model</span><br><span class="line">    <span class="keyword">raise</span> NameError(<span class="string">f&quot;Could not find model <span class="subst">&#123;name&#125;</span>.&quot;</span>)</span><br></pre></td></tr></table></figure><p>以下はSemanticSearchクラスでシンプルにベーシックな機能（モデルを読み込み、corpusの読み込み、エンコードして文をベクトル化すし、vector tree indexのビルド、そして、N個の最近傍探索）を実装します。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sentence_transformers <span class="keyword">import</span> SentenceTransformer, util</span><br><span class="line"><span class="keyword">from</span> simpleneighbors <span class="keyword">import</span> SimpleNeighbors</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SemanticSearch</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model</span>):</span><br><span class="line">        self.encoder = SentenceTransformer(model[<span class="string">&quot;name&quot;</span>])</span><br><span class="line">        self.index = SimpleNeighbors(model[<span class="string">&quot;dims&quot;</span>], model[<span class="string">&quot;metric&quot;</span>])</span><br><span class="line">        <span class="keyword">if</span> model[<span class="string">&quot;metric&quot;</span>] == <span class="string">&quot;angular&quot;</span>:</span><br><span class="line">            self.metric_func = util.cos_sim</span><br><span class="line">        <span class="keyword">elif</span> model[<span class="string">&quot;metric&quot;</span>] == <span class="string">&quot;dot&quot;</span>:</span><br><span class="line">            self.metric_func = util.dot_score</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">load_corpus</span>(<span class="params">self, filename</span>):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">f&quot;corpus/<span class="subst">&#123;filename&#125;</span>&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            self.feed(f.read().split(<span class="string">&quot;\n&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">feed</span>(<span class="params">self, sentences</span>):</span><br><span class="line">        <span class="keyword">for</span> sentence <span class="keyword">in</span> sentences:</span><br><span class="line">            vector = self.encoder.encode(sentence)</span><br><span class="line">            self.index.add_one(sentence, vector)</span><br><span class="line">        self.index.build()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">find_nearest</span>(<span class="params">self, query, n=<span class="number">5</span></span>):</span><br><span class="line">        vector = self.encoder.encode(query)</span><br><span class="line">        nearests = self.index.nearest(vector, n)</span><br><span class="line">        res = []</span><br><span class="line">        <span class="keyword">for</span> neighbor <span class="keyword">in</span> nearests:</span><br><span class="line">            dist = self.metric_func(vector, self.index.vec(neighbor))</span><br><span class="line">            res.append((neighbor, <span class="built_in">float</span>(dist)))</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><p>早速、クエリを投げてみます。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    model = find_model_with_name(</span><br><span class="line">        models, <span class="string">&quot;distiluse-base-multilingual-cased-v2&quot;</span>)</span><br><span class="line">    ss = SemanticSearch(model)</span><br><span class="line">    ss.load_corpus(<span class="string">&quot;future.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    res = ss.find_nearest(<span class="string">&quot;フューチャーはいつ創立されましたか。&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> r <span class="keyword">in</span> res:</span><br><span class="line">        <span class="built_in">print</span>(r)</span><br></pre></td></tr></table></figure><p><strong>出力結果1</strong></p><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">(&#x27;フューチャーは1989年にエンジニアが立ち上げたITコンサルティング企業です。&#x27;, 0.2547425627708435)</span><br><span class="line">(&#x27;では、フューチャーはどうかと言いますと、フィーチャーは図の通り、戦略からシステム構築運用まで一気通貫でになっています。&#x27;, 0.19687587022781372)</span><br><span class="line">(&#x27;創業時から、ITでビジネスを牽引することをコンセプトに掲げ、いわゆるDXにあたることを推進してきました。&#x27;, 0.1668681502342224)</span><br><span class="line">(&#x27;フューチャーグループには大きく2つの事業体があります。&#x27;, 0.164341002702713)</span><br><span class="line">(&#x27;昨今、DXと盛んに叫ばれるようになりましたが、私たちフューチャーは経営と業務、そしてその裏にあるシステムは切っても切り離せないものだと創業当初から考えて、それらを三位一体で捉えて推進するということを30年以上続けてきました。&#x27;, 0.16331210732460022)</span><br></pre></td></tr></table></figure><p>文章に「創立」などのキーワードが登場していないですけど、1個目近似度高い文（時間に関して述べているからかもしれません）がうまくヒットしています。</p><p>今度は他のモデルでやってみます。<br>モデル：<code>paraphrase-multilingual-MiniLM-L12-v2</code><br>クエリ：<code>フューチャーはいつ創立されましたか。</code><br><strong>出力結果2</strong></p><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">(&#x27;昨今、DXと盛んに叫ばれるようになりましたが、私たちフューチャーは経営と業務、そしてその裏にあるシステムは切っても切り離せないものだと創業当初から考えて、それらを三位一体で捉えて推進するということを30年以上続けてきました。&#x27;, 0.45087340474128723)</span><br><span class="line">(&#x27;日本初のITコンサルティング企業であり、DXを30年以上推進してきた会社と覚えていただければと思います。&#x27;, 0.3921096622943878)</span><br><span class="line">(&#x27;フューチャーは1989年にエンジニアが立ち上げたITコンサルティング企業です。&#x27;, 0.36329418420791626)</span><br><span class="line">(&#x27;創業当初から、お客様の経営戦略、それを達成するための業務改革、そしてそれを支えているシステム改革。&#x27;, 0.3592120409011841)</span><br><span class="line">(&#x27;創業時から、ITでビジネスを牽引することをコンセプトに掲げ、いわゆるDXにあたることを推進してきました。&#x27;, 0.35177189111709595)</span><br></pre></td></tr></table></figure><p>結果が変わりましたが、「昨今」や「創業」や「30年」が含まれた文はトップになっています。まあまあ許容できる結果でしょう。</p><p>他の質問とモデルでもやってみます。</p><p>モデル：<code>paraphrase-multilingual-MiniLM-L12-v2</code><br>クエリ：<code>未来報はなんですか。</code></p><p><strong>出力結果3</strong></p><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">(&#x27;フューチャーのオウンドメディア未来報では、フューチャーの人に焦点を当ててキャリアやカルチャーをご紹介しています。&#x27;, 0.5177506804466248)</span><br><span class="line">(&#x27;最後に、フューチャーのことをもっと知りたい方に各種メディアをご紹介します。&#x27;, 0.44624844193458557)</span><br><span class="line">(&#x27;プロジェクトはどんな未来を描くのか、戦略を立て、計画に落として、その計画に則ってシステム的に具現化し、出来上がったシステムが価値を創造するという流れが一般的です。&#x27;, 0.4249690771102905)</span><br><span class="line">(&#x27;例えば、未来を描くところはコンサル系の企業様が行って、具現化していくところはSIer系の企業様が行ってといった形です。&#x27;, 0.40904152393341064)</span><br><span class="line">(&#x27;次に、私たちが大切にしている考え方、Our&#x27;, 0.40697067975997925)</span><br></pre></td></tr></table></figure><p>モデル：<code>multi-qa-mpnet-base-dot-v1</code><br>クエリ：<code>長所はなに</code></p><p><strong>出力結果4</strong></p><p>（<em>※このモデルは、他のコサイン類似度とは違ってドット積で距離を評価しているので、1以上の距離結果がありうる</em>）</p><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">(&#x27;そしてそれを30年以上続けてきたというのはなかなか他の会社には簡単に真似できないフューチャーならではの強みになっています。&#x27;, 18.705921173095703)</span><br><span class="line">(&#x27;さらに詳細にビジネスの流れや他社との違いについてご紹介します。&#x27;, 18.43102264404297)</span><br><span class="line">(&#x27;皆さん、こんにちは。&#x27;, 16.867801666259766)</span><br><span class="line">(&#x27;業績も昨年は過去最高を更新するなど非常に順調です。&#x27;, 16.38519287109375)</span><br><span class="line">(&#x27;お客様の未来活用を最大化し、自らも新たな価値を創造する。&#x27;, 15.685336112976074)</span><br></pre></td></tr></table></figure><p>今度は、英語のコーパスを利用して、日本語で質問してみます。<br>HuggingFace出品の「Text embeddings &amp; semantic search」を紹介する<a href="https://www.youtube.com/watch?v=OATCgQtNX2o&ab_channel=HuggingFace">このビデオ</a>のセリフを引っ張ってきます。<code>corpus/semantic_search.txt</code>に保存します。</p><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">Text embeddings and semantic search.</span><br><span class="line">In this video we’ll explore how Transformer models represent text as embedding vectors and how these vectors can be used to find similar documents in a corpus.</span><br><span class="line">Text embeddings are just a fancy way of saying that we can represent text as an array of numbers called a vector.</span><br><span class="line">To create these embeddings we usually use an encoder-based model like BERT.</span><br><span class="line">In this example, you can see how we feed three sentences to the encoder and get three vectors as the output.</span><br><span class="line">Reading the text, we can see that walking the dog seems to be most similar to walking the cat, but let&#x27;s see if we can quantify this.</span><br><span class="line">The trick to do the comparison is to compute a similarity metric between each pair of embedding vectors.</span><br><span class="line">These vectors usually live in a high-dimensional space, so a similarity metric can be anything that measures some sort of distance between vectors.</span><br><span class="line">One popular metric is cosine similarity, which uses the angle between two vectors to measure how close they are.</span><br><span class="line">In this example, our embedding vectors live in 3D and we can see that the orange and grey vectors are close to each other and have a smaller angle.</span><br><span class="line">Now one problem we have to deal with is that Transformer models like BERT will actually return one embedding vector per token.</span><br><span class="line">For example in the sentence &quot;I took my dog for a walk&quot;, we can expect several embedding vectors, one for each word.</span><br><span class="line">For example, here we can see the output of our model has produced 9 embedding vectors per sentence, and each vector has 384 dimensions.</span><br><span class="line">But what we really want is a single embedding vector for the whole sentence.</span><br><span class="line">To deal with this, we can use a technique called pooling.</span><br><span class="line">The simplest pooling method is to just take the token embedding of the CLS token.</span><br><span class="line">Alternatively, we can average the token embeddings which is called mean pooling.</span><br><span class="line">With mean pooling only thing we need to make sure is that we don&#x27;t include the padding tokens in the average, which is why you can see the attention mask being used here.</span><br><span class="line">This now gives us one 384 dimensional vector per sentence which is exactly what we want.</span><br><span class="line">And once we have our sentence embeddings, we can compute the cosine similarity for each pair of vectors.</span><br><span class="line">In this example we use the function from scikit-learn and you can see that the sentence &quot;I took my dog for a walk&quot; has an overlap of 0.83 with &quot;I took my cat for a walk&quot;. Hooray.</span><br><span class="line">We can take this idea one step further by comparing the similarity between a question and a corpus of documents.</span><br><span class="line">For example, suppose we embed every post in the Hugging Face forums.</span><br><span class="line">We can then ask a question, embed it, and check which forum posts are most similar.</span><br><span class="line">This process is often called semantic search, because it allows us to compare queries with context.</span><br><span class="line">To create a semantic search engine is quite simple in Datasets.</span><br><span class="line">First we need to embed all the documents.</span><br><span class="line">In this example, we take a small sample from the SQUAD dataset and apply the same embedding logic as before.</span><br><span class="line">This gives us a new column called &quot;embeddings&quot; that stores the embedding of every passage.</span><br><span class="line">Once we have our embeddings, we need a way to find nearest neighbours to a query.</span><br><span class="line">Datasets provides a special object called a FAISS index that allows you to quickly compare embedding vectors.</span><br><span class="line">So we add the FAISS index, embed a question and voila. we&#x27;ve now found the 3 most similar articles which might store the answer.</span><br></pre></td></tr></table></figure><p>同じように、それをロードして、日本語のクエリで投げてみます。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    model = find_model_with_name(</span><br><span class="line">        models, <span class="string">&quot;paraphrase-multilingual-MiniLM-L12-v2&quot;</span>)</span><br><span class="line">    ss = SemanticSearch(model)</span><br><span class="line">    ss.load_corpus(<span class="string">&quot;semantic_search.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    res = ss.find_nearest(<span class="string">&quot;埋め込みベクトルでのエンコーディングについて、どんなモデルを使えますか&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> r <span class="keyword">in</span> res:</span><br><span class="line">        <span class="built_in">print</span>(r)</span><br></pre></td></tr></table></figure><p><strong>出力結果5</strong></p><p>それなりにいい感じにヒットできていますね。</p><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">(&#x27;To create these embeddings we usually use an encoder-based model like BERT.&#x27;, 0.6005619764328003)</span><br><span class="line">(&#x27;In this video we’ll explore how Transformer models represent text as embedding vectors and how these vectors can be used to find similar documents in a corpus.&#x27;, 0.5864262580871582)</span><br><span class="line">(&#x27;For example, here we can see the output of our model has produced 9 embedding vectors per sentence, and each vector has 384 dimensions.&#x27;, 0.5198760032653809)</span><br><span class="line">(&#x27;In this example, we take a small sample from the SQUAD dataset and apply the same embedding logic as before.&#x27;, 0.4749892055988312)</span><br><span class="line">(&#x27;In this example, our embedding vectors live in 3D and we can see that the orange and grey vectors are close to each other and have a smaller angle.&#x27;, 0.46906405687332153)</span><br></pre></td></tr></table></figure><p>モデル：<code>distiluse-base-multilingual-cased-v1</code><br>クエリ：<code>セマンティック検索には、どんなテクニックが使えるか</code></p><p><strong>出力結果6</strong></p><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">(&#x27;Text embeddings and semantic search.&#x27;, 0.3169878125190735)</span><br><span class="line">(&#x27;To create a semantic search engine is quite simple in Datasets.&#x27;, 0.22516131401062012)</span><br><span class="line">(&#x27;To deal with this, we can use a technique called pooling.&#x27;, 0.19742435216903687)</span><br><span class="line">(&#x27;This process is often called semantic search, because it allows us to compare queries with context.&#x27;, 0.1717163324356079)</span><br><span class="line">(&#x27;Once we have our embeddings, we need a way to find nearest neighbours to a query.&#x27;, 0.1544724851846695)</span><br></pre></td></tr></table></figure><h2 id="まとめ"><a href="#まとめ" class="headerlink" title="まとめ"></a>まとめ</h2><p>本記事では、セマンティック検索の概念や原理を簡単に説明しました。そして埋め込みベクトルの実装をシンプルに実現してデモしました。言語問わずにクエリを投げて、そこそこの精度の検索ランキングの結果が得ました。</p><p>AIの民主化が発展している現在、いろいろの技術のハードルが下がってきて、中小企業や一般の人々にも簡単に利用・導入可能になり、そのオポテュニティーをうまく掴める組織と人間こそ未来の勝者になるでしょう。</p><p>では、ようこそ〜　Futureへ！</p><img src="/images/20230906a/Future_Search_Semantic_HighTech.jpg" alt="Future_Search_Semantic_HighTech.jpg" width="768" height="768" loading="lazy">*Image Generated by leonardo.ai*]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h2 id=&quot;はじめに&quot;&gt;&lt;a href=&quot;#はじめに&quot; class=&quot;headerlink&quot; title=&quot;はじめに&quot;&gt;&lt;/a&gt;はじめに&lt;/h2&gt;&lt;p&gt;こんにちは。フューチャーTIG DXユニット所属の王です。&lt;/p&gt;
&lt;p&gt;本記事は、&lt;a</summary>
        
      
    
    
    
    <category term="DataScience" scheme="https://future-architect.github.io/categories/DataScience/"/>
    
    
    <category term="ChatGPT" scheme="https://future-architect.github.io/tags/ChatGPT/"/>
    
    <category term="AI" scheme="https://future-architect.github.io/tags/AI/"/>
    
    <category term="SemanticSearch" scheme="https://future-architect.github.io/tags/SemanticSearch/"/>
    
    <category term="embedding" scheme="https://future-architect.github.io/tags/embedding/"/>
    
    <category term="SentenceTransformers" scheme="https://future-architect.github.io/tags/SentenceTransformers/"/>
    
  </entry>
  
  <entry>
    <title>Raspberry PiからArduinoに接続したLCDに文字を表示する</title>
    <link href="https://future-architect.github.io/articles/20230905a/"/>
    <id>https://future-architect.github.io/articles/20230905a/</id>
    <published>2023-09-04T15:00:00.000Z</published>
    <updated>2023-10-02T00:07:27.504Z</updated>
    
    <content type="html"><![CDATA[<h2 id="はじめに"><a href="#はじめに" class="headerlink" title="はじめに"></a>はじめに</h2><p>初めまして。製造（PLMソリューション）所属&#x2F;九州在住　の水田です。</p><p>夏の自由研究連載2023の第3弾の方を執筆させていただきます。</p><p>今回が技術ブログ初投稿になります。不慣れな部分もありますが、なるべく分かりやすく書くように心がけていますので、最後までお付き合いください。</p><h2 id="研究テーマについて"><a href="#研究テーマについて" class="headerlink" title="研究テーマについて"></a>研究テーマについて</h2><p>漠然と</p><ul><li>ArduinoやRaspberry Piを触ってみたい</li><li>ArduinoにWebサーバを構築してみたい</li></ul><p>…と思ったので<strong>Raspberry Piに立てたWebサーバのブラウザから好きな文字列を入力してArduinoに接続したLCDに表示する</strong> までをやっていきます。</p><p>最終的には、在宅勤務している部屋のドアに設置して、スマホ経由でブラウザにアクセスして会議中であることを表示できればいいなとか考えています。</p><p>あと、色々とハマったのでその辺りも書いておこうかと思います。</p><p>※長くなるのでRaspberry PiやArduinoの基本的な部分の話は、割愛しています。</p><h2 id="構成-予定"><a href="#構成-予定" class="headerlink" title="構成(予定)"></a>構成(予定)</h2><p>最終的に以下の図のような構成を予定しています。</p><img src="/images/20230905a/image.png" alt="" width="987" height="197" loading="lazy"><h2 id="Arduino→LCDへの表示"><a href="#Arduino→LCDへの表示" class="headerlink" title="Arduino→LCDへの表示"></a>Arduino→LCDへの表示</h2><p>まずは、LCDに任意の文字列を表示してみます。</p><h3 id="使用するArduinoについて"><a href="#使用するArduinoについて" class="headerlink" title="使用するArduinoについて"></a>使用するArduinoについて</h3><p>家にあるArduinoを使おうとしたのですが、どのLCDを買えばよいのかがよく分からなかったので、新しくスターターキットを購入しました。値段の割に基本的なセンサー類からLCDやコントローラーまでついている上にサンプルコードまでついていて分かりやすいです。</p><p><a href="https://www.amazon.co.jp/dp/B06XF2HZGT/ref=as_sl_pc_qf_sp_asin_til?tag=amazon0b2-22&linkCode=w00&linkId=e5061d4d72ecf8efbd042e6417de9ad3&creativeASIN=B06XF2HZGT">ELEGOO Arduino用UNO R3スターターキット レベルアップ チュートリアル付 mega2560 r3 nanoと互換 [並行輸入品] </a></p><p>以下、実際につないで動かしてみた画像と使用したソースコードです。</p><img src="/images/20230905a/lcd.jpg" alt="" width="1200" height="900" loading="lazy"><figure class="highlight cpp"><figcaption><span>Arduino</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="comment">// LCDを使用するためのライブラリをインクルード</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;LiquidCrystal.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Arduinoから出力するPin番号とLCDのPin番号との対応を定義</span></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> rs = <span class="number">7</span>, en = <span class="number">8</span>, d4 = <span class="number">9</span>, d5 = <span class="number">10</span>, d6 = <span class="number">11</span>, d7 = <span class="number">12</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// LCDの初期化（使用するPin番号の指定）</span></span><br><span class="line"><span class="function">LiquidCrystal <span class="title">lcd</span><span class="params">(rs, en, d4, d5, d6, d7)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">setup</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  lcd.<span class="built_in">begin</span>(<span class="number">16</span>, <span class="number">2</span>);             <span class="comment">// 桁数と行数の指定</span></span><br><span class="line">  lcd.<span class="built_in">clear</span>();                  <span class="comment">// 画面のクリア</span></span><br><span class="line">  lcd.<span class="built_in">setCursor</span>(<span class="number">0</span>, <span class="number">0</span>);          <span class="comment">// カーソル位置の指定（1行目の1文字目に設定）</span></span><br><span class="line">  lcd.<span class="built_in">print</span>(<span class="string">&quot;Hello, World!&quot;</span>);   <span class="comment">// 文字出力</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">loop</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  lcd.<span class="built_in">setCursor</span>(<span class="number">0</span>, <span class="number">1</span>);          <span class="comment">// カーソル位置の指定（2行目の1文字目に設定）</span></span><br><span class="line">  lcd.<span class="built_in">print</span>(<span class="built_in">millis</span>() / <span class="number">1000</span>);   <span class="comment">// 文字出力</span></span><br><span class="line">  lcd.<span class="built_in">print</span>(<span class="string">&quot; [sec]&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><div class="note info" style="background: #e5f8e2; padding:16px; margin:24px 12px; border-radius:8px;">  <span class="fa fa-fw fa-check-circle"></span><p>以下の理由で少しハマりました。ハードウェアは原因の特定が難しい、、、<br></p><ul><li>可変抵抗の初期不良なのかブレッドボードにうまく刺さらない為、LCDのコントラストがうまく調整できず文字が表示できなかった。→可変にする必要もないので固定抵抗で対応<br></li><li>LCDもブレッドボードにちゃんと刺さらないので、出力されなかったり文字化けが発生したりした</li></ul></div><h2 id="Raspberry-Pi-の準備"><a href="#Raspberry-Pi-の準備" class="headerlink" title="Raspberry Pi の準備"></a>Raspberry Pi の準備</h2><p>Raspberry Piについては、昔購入したModel Bを使用。OSの状態とか覚えていないので、まずは付属のSDカードよりRaspian（wheezy）を再インストール＆以下の作業を実施</p><ul><li>packageの更新</li><li>python3とpipの更新</li><li>pyserial（＝シリアル通信で使用するpythonモジュール）のインストール</li></ul><div class="note info" style="background: #e5f8e2; padding:16px; margin:24px 12px; border-radius:8px;">  <span class="fa fa-fw fa-check-circle"></span><p>wheezyはサポートが切れているので、新しいバージョン（BusterとかBullseeye）にしたかったのですがRaspberry Pi Imagerを使用して書き込むとOSが全然立ち上がってくれない為、諦めてwheezyでやっています。</p></div><h3 id="packageの更新"><a href="#packageの更新" class="headerlink" title="packageの更新"></a>packageの更新</h3><p>apt-getがうまく動かなかったので苦労しました。</p><p>色々と調べてみるとapt-getでパッケージを更新する際に使用するミラーサイトのURLが古いのが原因だったみたいです。以下に記載があるURLを最新のURLに書き換えて対応しました。</p><ul><li>&#x2F;etc&#x2F;apt&#x2F;sources.list</li><li>&#x2F;etc&#x2F;apt&#x2F;sources.list.d&#x2F;collabora.list</li></ul><h3 id="python3とpipの更新"><a href="#python3とpipの更新" class="headerlink" title="python3とpipの更新"></a>python3とpipの更新</h3><p>apt-getでインストールしようとするとエラーになるのでこっちも苦労しました。色々と調べた結果、pyenvを使用してインストールするとうまくいきました。</p><h3 id="pyserial（＝シリアル通信で使用するpythonモジュール）のインストール"><a href="#pyserial（＝シリアル通信で使用するpythonモジュール）のインストール" class="headerlink" title="pyserial（＝シリアル通信で使用するpythonモジュール）のインストール"></a>pyserial（＝シリアル通信で使用するpythonモジュール）のインストール</h3><p>pipでインストールしたらすぐに終わりました。</p><h2 id="Raspberry-Pi-→Arduinoへシリアル通信"><a href="#Raspberry-Pi-→Arduinoへシリアル通信" class="headerlink" title="Raspberry Pi →Arduinoへシリアル通信"></a>Raspberry Pi →Arduinoへシリアル通信</h2><p>Raspberry PiとArduinoの準備が大体整ったので試しにシリアル通信を行ってみます。<br>以下のような文字列送信用のPythonを用意します。</p><div class="note info" style="background: #e5f8e2; padding:16px; margin:24px 12px; border-radius:8px;">  <span class="fa fa-fw fa-check-circle"></span><p>ser.open()時にPermissionエラーが出た場合は、portに指定しているポートに対して権限を付与すれば大丈夫です。<br>例）sudo chmod 666 &#x2F;dev&#x2F;ttyACM0</p></div><figure class="highlight python"><figcaption><span>Raspberry Pi（送信側）</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> serial</span><br><span class="line"></span><br><span class="line">ser = serial.Serial()</span><br><span class="line">ser.port = <span class="string">&#x27;/dev/ttyACM0&#x27;</span></span><br><span class="line">ser.baundrate = <span class="number">9600</span></span><br><span class="line">ser.<span class="built_in">open</span>()</span><br><span class="line"></span><br><span class="line">data = <span class="string">&#x27;NOW MEETING...  16:30 - 17:30&#x27;</span></span><br><span class="line">ser.write(data.encode())</span><br><span class="line">ser.close()</span><br></pre></td></tr></table></figure><p>Arduino側は、上記コードを以下のように書き換えます。なお、送られてくる文字列は1文字目～16文字目までを1行目に、17文字目～32文字目までを2行目に出す想定にしています</p><figure class="highlight cpp"><figcaption><span>Arduino（受信側）</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="comment">// LCDを使用するためのライブラリをインクルード</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;LiquidCrystal.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Arduinoから出力するPin番号とLCDのPin番号との対応を定義</span></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> rs = <span class="number">7</span>, en = <span class="number">8</span>, d4 = <span class="number">9</span>, d5 = <span class="number">10</span>, d6 = <span class="number">11</span>, d7 = <span class="number">12</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// LCDの初期化（使用するPin番号の指定）</span></span><br><span class="line"><span class="function">LiquidCrystal <span class="title">lcd</span><span class="params">(rs, en, d4, d5, d6, d7)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">setup</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  lcd.<span class="built_in">begin</span>(<span class="number">16</span>, <span class="number">2</span>);             <span class="comment">// 桁数と行数の指定</span></span><br><span class="line">  lcd.<span class="built_in">clear</span>();                  <span class="comment">// 画面のクリア</span></span><br><span class="line">  lcd.<span class="built_in">setCursor</span>(<span class="number">0</span>, <span class="number">0</span>);          <span class="comment">// カーソル位置の指定（1行目の1文字目に設定）</span></span><br><span class="line">  lcd.<span class="built_in">print</span>(<span class="string">&quot;INPUT...OK&quot;</span>);      <span class="comment">// 文字出力</span></span><br><span class="line">  Serial.<span class="built_in">begin</span>(<span class="number">9600</span>);           <span class="comment">// ボーレートの設定</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">loop</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (Serial.<span class="built_in">available</span>())                         <span class="comment">// シリアル通信が有効かどうかの確認</span></span><br><span class="line">  &#123;</span><br><span class="line">    String input = Serial.<span class="built_in">readString</span>();           <span class="comment">// 文字列取得</span></span><br><span class="line">    lcd.<span class="built_in">clear</span>();                                  <span class="comment">// 画面のクリア</span></span><br><span class="line">    lcd.<span class="built_in">setCursor</span>(<span class="number">0</span>, <span class="number">0</span>);                          <span class="comment">// カーソル位置の指定（1行目の1文字目に設定）</span></span><br><span class="line">    lcd.<span class="built_in">print</span>(input);                             <span class="comment">// 文字出力</span></span><br><span class="line"></span><br><span class="line">    String input2 = <span class="built_in">String</span>(input.<span class="built_in">substring</span>(<span class="number">16</span>));  <span class="comment">// 文字列の後半部分を抜き出し</span></span><br><span class="line">    lcd.<span class="built_in">setCursor</span>(<span class="number">0</span>, <span class="number">1</span>);                          <span class="comment">// カーソル位置の指定（2行目の1文字目に設定）</span></span><br><span class="line">    lcd.<span class="built_in">print</span>(input2);                            <span class="comment">// 文字出力</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以下、結果です。<br><img src="/images/20230905a/2.jpg" alt="" width="1200" height="1600" loading="lazy"></p><h3 id="うまくいっているように見えますが"><a href="#うまくいっているように見えますが" class="headerlink" title="うまくいっているように見えますが"></a>うまくいっているように見えますが</h3><p>実は、うまくいっていないんです。。。笑</p><p>具体的に書くと</p><ul><li>上記Pythonファイルを叩いても、LCDが点滅するだけ</li><li>Pythonファイルの内容をPython3のコマンドラインに張り付けて実行<br>→LCDに表示される（上記は、この時の写真となります）</li></ul><p>調べてみると、Arduino Unoには「USB経由でシリアル通信した場合にDTR端子の状態がLOWであればリセットがかかる」仕様があるらしくこれが原因でLCDがリセットされているようです。DTR端子をHIGHにすればよいのでは？とは思うので設定してみてはいるのですがなぜかうまくいかない。</p><h3 id="仮説"><a href="#仮説" class="headerlink" title="仮説"></a>仮説</h3><p>open()後にsleepを入れるとうまくいくのでは？という仮説が出てきました。<br>ファイル実行では、open→writeまでの処理に間が無いので、open処理完了→DTRリセット処理　のリセット中に書き込みを行っていてうまくいっていないような気がしてきました。</p><p>コマンドライン実行では、ser.open()→数秒後にser.writeを実行という流れなので、数秒の間にリセット処理が完了→LCDへの書き込みがうまくいくという流れのような気がしています。</p><p>コマンドライン実行時のopen処理直後のLCDを見ていると、open直後のタイミングでLCDにリセットがかかっているように見えます。試す価値がありそうです。</p><p>（open＝シリアル通信開始なので当たり前と言ったら当たり前ですが、、、）</p><p>以下のようにsleepを2秒入れて実行してみました。</p><figure class="highlight python"><figcaption><span>Raspberry Pi（送信側）</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> serial</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">ser = serial.Serial()</span><br><span class="line">ser.port = <span class="string">&#x27;/dev/ttyACM0&#x27;</span></span><br><span class="line">ser.baundrate = <span class="number">9600</span></span><br><span class="line">ser.<span class="built_in">open</span>()</span><br><span class="line">time.sleep(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">data = <span class="string">&#x27;NOW MEETING...  16:30 - 17:30&#x27;</span></span><br><span class="line">ser.write(data.encode())</span><br><span class="line">ser.close()</span><br></pre></td></tr></table></figure><p>結果としてはうまくいきました。仮説が当たっていたみたいです。</p><p>個人的には、以下の理由で上記方法は気に入らないのですがひとまず、これで進めます。</p><ul><li>本来であればDTR端子を何とかする（＝設定やらなんやらで何とかする）のが筋</li><li>sleepで解決するのが力技っぽくて、あまり好みではない</li></ul><h3 id="よくよく考えると、、、"><a href="#よくよく考えると、、、" class="headerlink" title="よくよく考えると、、、"></a>よくよく考えると、、、</h3><p>sleepを入れない方向でもいいのでは？と考えています。</p><p>まず、Webサーバの方に必要なモジュールをブラウザに表示する内容から考えると以下のようになると考えています。</p><p><strong>ブラウザ表示（仮）</strong><br><img src="/images/20230905a/image_2.png" alt="" width="597" height="301" loading="lazy"></p><ul><li>シリアル通信開始（接続ボタン押下）</li><li>シリアル通信終了（切断ボタン押下）</li><li>文字列送信（送信ボタン押下）</li></ul><p>上記のようなUIで考えると、シリアル通信開始～送信ボタン押下までには、タイムラグがあると思います。</p><p>仮に接続ボタンを無くしたようなUIであっても、文字列送信部分に入力するのに数秒はかかるはずなので、sleepは無くて良いと想像しています。<br><span style="font-size: 70%;">（接続ボタン押下からコンマ数秒で入力する超人または、RTA挑戦者は考えていないです）</span></p><p>そのため、この後の方向としては、以下のようになると考えています。</p><ul><li>文字列送信については、sleepを入れない形でひとまず実装を進める</li><li>上記実装で問題が発生した場合、改めてsleepを入れることを検討する</li></ul><h2 id="おわりに"><a href="#おわりに" class="headerlink" title="おわりに"></a>おわりに</h2><h3 id="Webサーバは？"><a href="#Webサーバは？" class="headerlink" title="Webサーバは？"></a>Webサーバは？</h3><p>という声が聞こえてきそうですが、これ以上自由研究に作業時間が取れそうにないので今回はここまでとさせていただきます。今後執筆する機会があれば、続きを書きます。</p><p>メモ：残作業</p><ul><li>Webサーバ構築（Apache?nginx?マシンスペックが弱いので軽いのがいい）</li><li>マイコンへの書き込み及び、基盤へのはんだ付け作業</li><li>マイコンとRaspberry Piを設置するようの箱を用意（木？近所に3Dプリンターが使える店があるのでプラスチック？)</li><li>ドアへの設置</li></ul><h3 id="あとがき"><a href="#あとがき" class="headerlink" title="あとがき"></a>あとがき</h3><p>初めてArduinoやRaspberry Piに触ってみましたが色々とトラブルが続いて思うように進まなかったです。ハードウェア周りは、未経験だったので、良い経験にはなったかなと考えています。</p><p>あと、今回のような誰かに見せるようなものを書いたりすると、アウトプットの仕方を考えたりする練習にもなると思うので、書いたことが無くて二の足を踏んでいるような方がいれば、挑戦してみると良い経験になるかと思います。</p><p>では、また執筆する機会があればお会いしましょう</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h2 id=&quot;はじめに&quot;&gt;&lt;a href=&quot;#はじめに&quot; class=&quot;headerlink&quot;</summary>
        
      
    
    
    
    <category term="IoT" scheme="https://future-architect.github.io/categories/IoT/"/>
    
    
    <category term="電子工作" scheme="https://future-architect.github.io/tags/%E9%9B%BB%E5%AD%90%E5%B7%A5%E4%BD%9C/"/>
    
    <category term="RaspberryPi" scheme="https://future-architect.github.io/tags/RaspberryPi/"/>
    
    <category term="Arduino" scheme="https://future-architect.github.io/tags/Arduino/"/>
    
    <category term="初心者" scheme="https://future-architect.github.io/tags/%E5%88%9D%E5%BF%83%E8%80%85/"/>
    
  </entry>
  
  <entry>
    <title>UnityのShaderでVRプラネタリウムを作ったけどうまくいかず悔しかったので自作の星を作ったら宇宙が終わった</title>
    <link href="https://future-architect.github.io/articles/20230901a/"/>
    <id>https://future-architect.github.io/articles/20230901a/</id>
    <published>2023-08-31T15:00:00.000Z</published>
    <updated>2023-10-02T00:07:27.503Z</updated>
    
    <content type="html"><![CDATA[<h2 id="はじめに"><a href="#はじめに" class="headerlink" title="はじめに"></a>はじめに</h2><p>こんにちは。TIG DX ユニット所属、金欠コンサルタントの藤井です。</p><p><a href="/articles/20230821a/">夏の自由研究連載</a>の第2弾です。夏休みの宿題っぽいものを題材にしてみました。</p><p>実は私、星を見るのが好きなので、天体望遠鏡を買ったり、星を撮るためにカメラを買ったりしています。せっかくならいい環境で見たいので、南は沖縄から北は北海道まで星を見に行っています。（海外も行きたい）。ただ、星を見に行くとなるとどうしても長距離移動になるので、お金もかかるし大変です。天気に左右されるのもつらいところです。</p><p>ということで今回は、遠出しなくてもいろんな星を見ることができるように、VR でプラネタリウムを作ろうと思います。</p><p>なお、本記事では Unity そのものの機能や、Shader の基本的な部分には触れず、作成したソースを参照しながら、重要な部分のみを詳細に記載しています。</p><h2 id="事前準備等"><a href="#事前準備等" class="headerlink" title="事前準備等"></a>事前準備等</h2><h3 id="大方針"><a href="#大方針" class="headerlink" title="大方針"></a>大方針</h3><p>VR プラネタリウムを作るためには、VR 空間上で星の配置を再現していく必要があります。実現方針としては概ね以下の 2 つに分かれるかと思います。</p><ol><li>実際に宇宙空間を作成し、星をオブジェクトとして配置していく<ul><li>メリット：非常にわかりやすく、実装コストが低い。</li><li>デメリット：大量のオブジェクトを作成することになるため、負荷が高い。</li></ul></li><li>天球を作成し、天球上に星の絵（テクスチャ）を描く<ul><li>メリット：オブジェクトは天球のみのため、負荷が低い。</li><li>デメリット：テクスチャの解像度に依存して厳密性が低下する。</li></ul></li></ol><p>ところで皆さんは宇宙にどれぐらいの星（恒星）があるかご存知でしょうか。星の数ほど、というぐらいなので途方もない数であるということはイメージできると思います。結論としては、宇宙の大きさが無限大なので、星の数も無限大です。とはいえ、我々が地球から観測できる星の数は有限であるため、十分な観測技術があれば星の数を数えることは原理上は可能なはずです。（現在確認可能な範囲でも数十億個はあると言われています。）</p><p>この観測できる星をすべて網羅した、星表と呼ばれるものを作りたい、という野望を天文学者は古より抱いており、紀元前から現代に至るまで様々な星表が作られてきました。ただ、これらの星表はもちろん完璧なものではなく、実際に記載されているのは数十万程度です。</p><p>母数が多いので、数十万と聞くと少なく見えますが、決して小さい値ではありません。特に今回は Meta Quest 2 を用いてプラネタリウムを作ろうと思っているので、マシンスペックもそこまで高くありません。そのため今回は、負荷を低減できる方針 2 を採用します。</p><h2 id="Shader-で-Skybox-に動的に星を描いてみる"><a href="#Shader-で-Skybox-に動的に星を描いてみる" class="headerlink" title="Shader で Skybox に動的に星を描いてみる"></a>Shader で Skybox に動的に星を描いてみる</h2><p>では、天球上に星を描いてみましょう。ただし今回は天球用のオブジェクトは作成せず、Skybox と呼ばれるものを使います。Unity にデフォルトで用意されている、オブジェクトが存在しなければ描画される背景のようなもので、ゲーム空間を取り囲むように配置されています。</p><p>Skybox に星の絵を描くに当たり、実際に星空のテクスチャを描いて貼り付けても良いのですが、今回は Shader で動的に星景を作成することにしてみました。理由は Shader を書いてみたかったからです。</p><p>Unity では、「ゲーム空間内の<code>(x,y,z)</code>という座標に hoge というオブジェクトが有るから、画面上の<code>(X,Y)</code>座標のピクセルには<code>(r,g,b)</code>という色を出力しよう」という処理を Shader と呼ばれるものが行っています。<br>つまり Shader に適切な指示を出してもらえば、実態としてはゲーム空間内に何も存在していないにも関わらず、画面上には何かが表示されている、ということができます。</p><p>これにより、単純にゲーム空間内に召喚するオブジェクトが減るという効果はもちろんあるのですが、それに加えて Unity では、C#で書かれたロジックは CPU で（ほぼ）直列に処理がされ、Shader は GPU で並列に処理がされます。基本的に描写する対象の数が多いほど、処理の並列度が重要になってくるため、星の表示はすべて Shader にまかせてしまえば、非常に軽快に宇宙を再現できるのではないか、という気がしてきました。<br>なお、結論から記載すると、これはダメでした。</p><h3 id="Shader-を書いてみる"><a href="#Shader-を書いてみる" class="headerlink" title="Shader を書いてみる"></a>Shader を書いてみる</h3><p>Unity の Shader では、HLSL と呼ばれる言語を用いて処理を記述していきます。</p><p>とりあえず試しに 2 つ、白と赤の星が表示されるようなものを作ってみたものが<a href="https://github.com/shomuMatch/VRPlanetarium/blob/master/Assets/Shader/sample1.shader">こちらの sample1.shader</a>です。</p><p>重要なのは以下のあたりです。</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 星の存在する方向や色、明るさを定義</span></span><br><span class="line"><span class="type">static</span> <span class="type">const</span> Star stars[<span class="number">2</span>] = &#123;</span><br><span class="line">      createStar(float3(<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>), fixed3(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>), <span class="number">0.5</span>),</span><br><span class="line">      createStar(float3(<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>), fixed3(<span class="number">1</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), <span class="number">1</span>),</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 背景色を定義</span></span><br><span class="line">fixed4 <span class="title function_">drawBackground</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">      <span class="keyword">return</span> fixed4(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 星を描画</span></span><br><span class="line">fixed4 <span class="title function_">drawStars</span><span class="params">(float3 dir)</span></span><br><span class="line">&#123;</span><br><span class="line">      float3 o = float3(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line">      <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">2</span>; i++)</span><br><span class="line">      &#123;</span><br><span class="line">            float3 direction = normalize(stars[i].direction);</span><br><span class="line">            fixed3 color = normalize(stars[i].color);</span><br><span class="line">            <span class="type">float</span> angle = dot(dir, direction);</span><br><span class="line">            o += color * <span class="built_in">pow</span>(max(<span class="number">0.0</span>, angle), _radiusCoefficient * (stars[i].magnitude + <span class="number">2</span>)) * <span class="built_in">pow</span>(<span class="number">2.5</span>, <span class="number">-1</span> * stars[i].magnitude) * _brightnessCoefficient;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> float4(o, <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 各ピクセルごとの色を決定</span></span><br><span class="line">fixed4 <span class="title function_">frag</span><span class="params">(v2f i)</span> : SV_Target</span><br><span class="line">&#123;</span><br><span class="line">      <span class="keyword">return</span> drawBackground() + drawStars(i.texcoord);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>コメントで書いている通りなのですが、<code>frag()</code>という関数の返り値に応じて、画面上の各ピクセルごとの色が決定されます。（<code>#pragma fragment frag</code>という記述で定義しています）</p><p>この<code>frag()</code>の引数である<code>i</code>のメンバ変数<code>texcoord</code>には、画面内の各ピクセルにおける視線方向のベクトルが格納されています。この視線方向のベクトルと、別途定義している星の存在する方向を示しているベクトルとの内積を取ることで、どのピクセルに星を描画するべきかを決定しているのが<code>drawStars()</code>です。ざっくり書くと、視線方向と星の存在する方向が同じであれば星を描画し、若干ずれていたとしても、星の明るさに応じてほんの少しは描画する。みたいなことを表現しています。これを星の数だけ繰り返すようループしています。なお、shader では単純なループは適切に最適化され、並列処理が行われます。配列の要素間のやり取りなど、直列実行が不可避なものに関しては並列化されませんが、そもそもそういう処理は GPU で実施することを推奨されません。</p><p>さて、この Shader を Skybox に適用するとどのように星が見えるかというと、こんな感じです。</p><img src="/images/20230901a/image.png" alt="image.png" width="1200" height="602" loading="lazy"><p>結構それっぽい気がしますね。</p><p>ではここからどんどん星を増やしていきましょう。と思ったのですが、以下のような制約の壁にぶつかり続け、結局は断念しました。</p><ul><li>Shader では外部ファイルからデータを読み込んで描画することができない。<ul><li>そのため、星の情報をすべてハードコーディングすることになりました。</li><li>ファイル読み込みを C#で行い、Shader に結果を渡す、みたいなこともできる気がしたのですが、うまく行かず…</li></ul></li><li>Shader で利用できる配列の要素数に上限があった。<ul><li>1 配列の要素数、ではなく、全配列の要素数の合計が 4096 以下である必要があるようでした。</li><li>そのため、配列ではなく個別に変数を大量に宣言することになりました。</li></ul></li><li>10 万個の星を描こうとしたところ、Shader のコンパイルがタイムアウトした。<ul><li>個別変数の数に応じてコンパイル時間が伸びていき、やがてはタイムアウトしてしまいました。</li><li>環境変数でタイムアウト時間が設定されているようなので、伸ばすことは可能そうなのですが、とりあえずは星の数を減らして試してみることにしました。</li></ul></li><li>1 万個ぐらいの星を描いたあたりで、PC が唸りを上げ始めた。<ul><li>GPU がフル回転を始めました。</li><li>あと普通にめちゃくちゃ重たくなっていたため、ここで心が折れました。</li></ul></li></ul><p>一応ある程度は描けていたので供養のためキャプチャを掲載しておきます。</p><img src="/images/20230901a/image_2.png" alt="" width="1200" height="728" loading="lazy"><p>なんか、星空って感じではないですね？</p><p>もしかしたら色や明るさを計算するロジックにバグがあるのかもしれませんが、心が折れたのでこれ以上は深追いしません。</p><h2 id="テクスチャを描いて貼り付ける方針に切り替える"><a href="#テクスチャを描いて貼り付ける方針に切り替える" class="headerlink" title="テクスチャを描いて貼り付ける方針に切り替える"></a>テクスチャを描いて貼り付ける方針に切り替える</h2><p>Skybox に動的に星を描く方針は頓挫したし、とりあえず Shader を書いてみるという目的は達成したため、素直にテクスチャを描いて、それを貼り付ける方針に切り替えます。切り替えは大事。</p><h3 id="テクスチャを描く"><a href="#テクスチャを描く" class="headerlink" title="テクスチャを描く"></a>テクスチャを描く</h3><p>まずはテクスチャを作成するための星のデータを用意します。</p><p>今回 VR プラネタリウムを作るにあたって、とりあえずは実際の星空を再現したいので、観測データを用いることにします。冒頭で星表というものを紹介しましたが、今回はその中でも、ヒッパルコス星表というものを使っていきます。ヒッパルコス衛星により取得されたデータを編纂したもので、12 万弱の星のデータが記録されています。<a href="https://heasarc.gsfc.nasa.gov/db-perl/W3Browse/w3table.pl?tablehead=name=hipparcos&Action=More+Options">NASA がデータを公開してくれている</a>ので、こちらから必要なデータを取得していきます。</p><p>HIP 番号（name）、赤経（ra）、赤緯（dec）、等級（vmag）、B-V 色指数（bv_color）を選択してダウンロードしました。そのままだと使いづらいので、以下コマンドなどで csv に変換しておきます。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> hip.txt | sed <span class="string">&#x27;1,5d&#x27;</span> | sed <span class="string">&#x27;s/ \+|/|/g&#x27;</span> | sed <span class="string">&#x27;s/| \+/|/g&#x27;</span> | awk -F <span class="string">&#x27;|&#x27;</span> -v <span class="string">&#x27;OFS=,&#x27;</span> <span class="string">&#x27;&#123;print $2,$3,$4,$5,$6&#125;&#x27;</span> &gt; hip.csv</span><br></pre></td></tr></table></figure><p>この csv をもとにテクスチャを描画する<a href="https://github.com/shomuMatch/VRPlanetarium/blob/master/hip/drawTexture.py">python スクリプト</a>を作成しました。</p><p>ざっくりこんな感じのことをしています。</p><ul><li>赤経・赤緯を度（degree）に変換して描画する位置を決定する。</li><li>等級と赤緯から画像上での星の大きさを決定する。<ul><li>本来星はものすごく遠いため、明るさによらず点として見えるはずですが、人の目の錯覚として明るいものは大きく見えたり、大気による散乱効果が明るいほど強いことなどを踏まえ、明るい星ほど大きく描画しています。</li><li>天球を平面のテクスチャで表現するため、赤道部分はそのままに、極地に近づくほど横に引き伸ばした描画とする必要があります。</li></ul></li><li>等級・B-V 色指数から各星の色・明るさを決定する。<ul><li>観測値である B-V 色指数から星の表面温度を推定、黒体を仮定して表面温度から RGB 値を算出しています。</li><li>等級が 1 変わると、2.5 倍明るさが変わるので、HSV 色空間における V 値が等級に応じて増減するようにしています。<ul><li>ただし、人の目が明るさ（暗さ）に慣れたり、カメラの露光時間を長くしたりすることで、絶対的な明るさと見かけの明るさは必ずしも一致しないことを考慮し、可変パラメータとしています。</li></ul></li><li>計算の根拠はスクリプト上に参考 URL を記載しています。</li></ul></li><li>ガンマ補正を行う。<ul><li>人間の目やカメラによる補正として、ガンマ補正ができるようにしています。こちらもパラメータは可変です。</li></ul></li></ul><p>スクリプトにより描画したテクスチャがこちらです。</p><img src="/images/20230901a/texture3.9_2.5.png" alt="" width="1200" height="600" loading="lazy"><p>高解像度画像に、小さな星の点を表示しているので、あまりきらびやかではないです。</p><h3 id="テクスチャを-Skybox-に適用する"><a href="#テクスチャを-Skybox-に適用する" class="headerlink" title="テクスチャを Skybox に適用する"></a>テクスチャを Skybox に適用する</h3><p>テクスチャが生成できればあとは Unity に取り込んで、適切に設定するだけです。</p><p>まずは Import して、解像度を高めに設定しておきます。</p><img src="/images/20230901a/image_3.png" alt="image.png" width="898" height="790" loading="lazy"><p>そしたら Skybox 用のマテリアルを作成し、Shader を<code>Skybox/Panoramic</code>に、Mapping を<code>Latitude Longitude Layout</code>に設定し、テクスチャのところにインポートしたテクスチャを適用します。</p><img src="/images/20230901a/image_4.png" alt="image.png" width="896" height="666" loading="lazy"><p>最後にメニューの Window -&gt; Rendering &gt; Lighting から Lighting 設定を開き、Environment タブにある Skybox Material に作成した Material をセットします。</p><p>これで準備は完了です。VR 環境で見てみましょう。</p><img src="/images/20230901a/output.gif" alt="output.gif" width="1024" height="1024" loading="lazy"><p>うーん…とりあえず、星空っぽくはある…？（なんか、オリオン座の形おかしい気がする。）</p><h2 id="おわりに"><a href="#おわりに" class="headerlink" title="おわりに"></a>おわりに</h2><p>ここまでやっておいてなんなんですが、思ったより微妙でした。<br>考えられる要因はいくつか有ります。</p><ul><li>解像度が足りていない。<ul><li>テクスチャの解像度・VR ヘッドセットの解像度ともに、現実世界には遠く及びません。そのためどうしても星というよりは、なんか光っている点、みたいに見えてしまいます。</li></ul></li><li>星の数が少ない。<ul><li>10 万強の星を再現しているとはいえ、当然宇宙に存在するすべての星を再現できているわけではありません。</li><li>特に、天の川銀河の外にある銀河の星や、星雲などのデータはヒッパルコス星表には含まれていないため、どうしても実際の星空とは異なってしまいます。</li><li>この問題を解決するには、実際に世界各地で撮った星景写真をつなぎ合わせてテクスチャを作るしかないかなあと思います。</li></ul></li><li>臨場感がない。<ul><li>これは現実のプラネタリウムにも言えることですが、やはり現地で自然に囲まれながら見る星空、というものに、言語化できない魅力があります。気温や風、音など、単に視覚情報に限らない様々な情報が多角的に私達を魅了しているのだと実感しました。</li><li>現実のプラネタリウムでは、この問題を、魅力的なナレーションや上映内容によって補っているのだと思います。</li><li>ゲームの背景など、脇役に据えるのであれば、このぐらいでも良いのかもしれません。</li></ul></li></ul><p>頑張った割にはこんなものか、というオチになってしまい悔しいですが、ともあれある程度のプラネタリウムを再現できたので、夏の自由研究としては良しとします。<br>ちなみに、今回はヒッパルコス星表のデータを使用しましたが、同じフォーマットでデータを追加することで、自由に星を追加できます。</p><p>・・・・・・・・</p><img src="/images/20230901a/image_5.png" alt="image.png" width="1200" height="193" loading="lazy"><p>せっかくなので-75 等星である、「スーパー明るい藤井星」を追加してみました。見てみましょう。</p><img src="/images/20230901a/output2.gif" alt="output2.gif" width="1024" height="1024" loading="lazy"><p>宇宙は、なんか亀裂入ったし光に包まれて終わりました。</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h2 id=&quot;はじめに&quot;&gt;&lt;a href=&quot;#はじめに&quot; class=&quot;headerlink&quot; title=&quot;はじめに&quot;&gt;&lt;/a&gt;はじめに&lt;/h2&gt;&lt;p&gt;こんにちは。TIG DX ユニット所属、金欠コンサルタントの藤井です。&lt;/p&gt;
&lt;p&gt;&lt;a</summary>
        
      
    
    
    
    <category term="Programming" scheme="https://future-architect.github.io/categories/Programming/"/>
    
    
    <category term="Unity" scheme="https://future-architect.github.io/tags/Unity/"/>
    
    <category term="VR" scheme="https://future-architect.github.io/tags/VR/"/>
    
    <category term="Shader" scheme="https://future-architect.github.io/tags/Shader/"/>
    
    <category term="プラネタリウム" scheme="https://future-architect.github.io/tags/%E3%83%97%E3%83%A9%E3%83%8D%E3%82%BF%E3%83%AA%E3%82%A6%E3%83%A0/"/>
    
  </entry>
  
  <entry>
    <title>夏の自由研究：CreateMLを使ってカブトムシを分類するミニアプリを作ってみる。</title>
    <link href="https://future-architect.github.io/articles/20230831a/"/>
    <id>https://future-architect.github.io/articles/20230831a/</id>
    <published>2023-08-30T15:00:00.000Z</published>
    <updated>2023-10-02T00:07:27.502Z</updated>
    
    <content type="html"><![CDATA[<h2 id="はじめに"><a href="#はじめに" class="headerlink" title="はじめに"></a>はじめに</h2><p>こんにちは！HealthCare Innovation Group(HIG)<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>所属の橋本です。</p><p>本記事は、<a href="/articles/20230830a/">夏の自由研究ブログ連載2023</a>の1本目です。</p><p>夏の風物詩であるカブトムシやクワガタを識別するミニアプリを作りました。</p><p>夏の自由研究ブログの連載があると聞いて、せっかくなら夏っぽい題材にしたいなと、私が小さい時にたくさん捕まえていたカブトムシを題材にしようと考えました。</p><p>「Swiftと機械学習あたりを絡めて何かできないかな？」と考えたところ、CreateMLという様々な機械学習モデルをGUIで作ることができると知ったため、カブトムシやクワガタの画像を学習させたモデルを使ったミニアプリを作ることにしました。</p><p>今回は、作成したミニアプリをもとに、CreateMLの使い方について紹介したいと思います。<br><img src="/images/20230831a/image.png" alt="" width="718" height="247" loading="lazy"></p><p><strong>作成したカブトムシ・クワガタを分類するミニアプリ</strong><br><img src="/images/20230831a/beatle_app.gif" alt="" width="177" height="384" loading="lazy"></p><h2 id="目次"><a href="#目次" class="headerlink" title="目次"></a>目次</h2><ul><li>CreateML、CoreMLとは</li><li>CreateMLを使ってカブトムシ・クワガタを識別するモデルの作成からアプリへ実装まで<ul><li>学習データ、テストデータを用意する</li><li>識別モデルを作成</li><li>アプリへ実装する</li></ul></li><li>最後に</li></ul><h2 id="CreateML、CoreMLとは"><a href="#CreateML、CoreMLとは" class="headerlink" title="CreateML、CoreMLとは"></a>CreateML、CoreMLとは</h2><p>CreateMLとは、Appleが提供する機械学習のフレームワークの一つで、機械学習モデルを作成するツールです。また、このCreateMLで作成したモデルを実際にiOSアプリなどで使用ために使われるフレームワークとしてCoreMLがあります。簡単に説明すると、</p><ul><li>CreateMLが機械学習モデル（画像認識、オブジェクト認識、音声認識、文字認識など）を作成するもの</li><li>CoreMLが作成したモデルを様々な実際にアプリに組み込むもの</li></ul><p>というイメージで問題ないと思います。</p><p>以下のApple公式の機械学習に関するページにて、それぞれの説明が記載されています。</p><p><a href="https://developer.apple.com/jp/machine-learning/">https://developer.apple.com/jp/machine-learning/</a></p><p>CreateMLの説明文の引用です。</p><blockquote><p>Create MLアプリでは、コードを書かずにMac上でCore MLモデルをすばやく構築およびトレーニングすることができます。使いやすいアプリのインターフェイスとトレーニング向けに利用できるモデルにより、プロセスがこれまでになく簡単になり、トレーニングデータさえ用意すれば開始できます。モデルのトレーニングと正確性を可視化する手助けとして、スナップショットやプレビューといった機能でトレーニングプロセスをコントロールすることもできます。Create MLフレームワークおよびCreate ML Componentsを使用すると、モデル作成をより細部まで詳細にコントロールできます。</p></blockquote><p>CoreMLの説明文の引用です。</p><blockquote><p>Core MLなら、アプリに機械学習モデルを容易に組み込むことができる上、Appleデバイス上で目を見張るほど速いパフォーマンスを実現します。Core MLのAPIを使うと、構築済みの機械学習機能をアプリに追加することができます。またはCreate MLを使って、カスタムCore MLモデルをMac上で直接トレーニングすることも可能です。他のトレーニングライブラリからのモデルをCore ML Toolsを使って変換したり、すぐに使えるCore MLモデルをダウンロードしたりすることもできます。Xcodeで直接、モデルをプレビューしてそのパフォーマンスを把握することも簡単です。</p></blockquote><h2 id="CreateMLを使ってカブトムシ・クワガタを識別するモデルの作成からアプリへ実装まで"><a href="#CreateMLを使ってカブトムシ・クワガタを識別するモデルの作成からアプリへ実装まで" class="headerlink" title="CreateMLを使ってカブトムシ・クワガタを識別するモデルの作成からアプリへ実装まで"></a>CreateMLを使ってカブトムシ・クワガタを識別するモデルの作成からアプリへ実装まで</h2><p>まず、CreateMLを使って、カブトムシ・クワガタを識別する機械学習モデルを作成していきます。<br>こちらのページに学習済みのCoreMLが組み込まれたサンプルコードがあるため、こちらの中の<code>MobileNetV2</code>（画像識別のモデル）を使用してミニアプリを作成していきます。</p><p><a href="https://developer.apple.com/jp/machine-learning/models/">https://developer.apple.com/jp/machine-learning/models/</a></p><p>環境は、次のとおりです。</p><h3 id="実装環境"><a href="#実装環境" class="headerlink" title="実装環境"></a>実装環境</h3><ul><li>macOS: Ventura 13.4.1(c)</li><li>Xcode: Version 14.3.1 (14E300c)</li></ul><h4 id="学習データ、テストデータを用意する"><a href="#学習データ、テストデータを用意する" class="headerlink" title="学習データ、テストデータを用意する"></a>学習データ、テストデータを用意する</h4><p>4種類のカブトムシ・クワガタの画像を用意します。<br>学習データが100枚、テストデータが20枚それぞれ用意し、以下のフォルダ階層のように準備します。</p><h5 id="フォルダ階層"><a href="#フォルダ階層" class="headerlink" title="フォルダ階層"></a>フォルダ階層</h5><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">├trainingData</span><br><span class="line">｜├beatle <span class="comment">#カブトムシ</span></span><br><span class="line">｜├SawToothStagBeatle <span class="comment">#ノコギリクワガタ</span></span><br><span class="line">｜├GiantBeatle <span class="comment">#オオクワガタ</span></span><br><span class="line">｜└MiyamaStagBeatle <span class="comment">#ミヤマクワガタ</span></span><br><span class="line">├testData</span><br><span class="line">　├beatle <span class="comment">#カブトムシ</span></span><br><span class="line">　├SawToothStagBeatle <span class="comment">#ノコギリクワガタ</span></span><br><span class="line">　├GiantStagBeatle <span class="comment">#オオクワガタ</span></span><br><span class="line">　└MiyamaStagBeatle <span class="comment">#ミヤマクワガタ</span></span><br></pre></td></tr></table></figure><p>（飼育経験のあるこの四種類を分類することにしてみました。）</p><h3 id="識別モデルを作成"><a href="#識別モデルを作成" class="headerlink" title="識別モデルを作成"></a>識別モデルを作成</h3><p>CreateMLを<code>Xcode</code> &gt; <code>Open Developer Tool</code> &gt; <code>CreatML</code>をクリックし、ウィンドウを開きます。</p><p>先程用意したtrainingDataフォルダを以下の”＋”部分に、ドラック＆ドロップで追加します。</p><img src="/images/20230831a/image_2.png" alt="" width="1103" height="333" loading="lazy"><p>追加されると、次のようになります。</p><img src="/images/20230831a/image_3.png" alt="" width="1108" height="345" loading="lazy"><p>左上の<code>Train</code>を押下すると、渡したデータをもとに学習が始まります。</p><p>数秒で学習が完了し、以下のように学習時の様子が<code>Trainingタブ</code>で確認することができます。</p><img src="/images/20230831a/image_4.png" alt="" width="868" height="362" loading="lazy"><p>これで機械学習モデルの作成自体は完了です。</p><p>作成したモデルが未知のデータをどれほどの精度で分類できるか評価する方法として、学習時に使用していないテストデータを渡すことができます。CreateML上での実施方法は、Evaluationタブでtraining時と同様に、Testing dataにテスト用のデータをドラック＆ドロップで追加します。</p><img src="/images/20230831a/image_5.png" alt="" width="1114" height="398" loading="lazy"><p>今回の四種類のカブトムシ・クワガタの分類精度は、ノコギリクワガタが50％をわずかに下回っているが、4分類であることを考えると何もパラメータチューニングをしていない割に、オオクワガタ(giantStagBeatle)は65%とまずまずの精度となっていました。</p><h4 id="画像中のMetrics"><a href="#画像中のMetrics" class="headerlink" title="画像中のMetrics"></a>画像中のMetrics</h4><div class="scroll"><table><thead><tr><th align="left">Class</th><th align="right">Count</th><th align="right">Correct</th><th align="right">FP</th><th align="right">FN</th><th align="right">Precision</th><th align="right">Recall</th><th align="right">F1 Score</th></tr></thead><tbody><tr><td align="left">SawTooth<br>StagBeatle</td><td align="right">20</td><td align="right">9</td><td align="right">10</td><td align="right">11</td><td align="right">47%</td><td align="right">45%</td><td align="right">0.46</td></tr><tr><td align="left">Miyama<br>StagBeatle</td><td align="right">20</td><td align="right">10</td><td align="right">6</td><td align="right">10</td><td align="right">62%</td><td align="right">50%</td><td align="right">0.56</td></tr><tr><td align="left">Giant<br>StagBeatle</td><td align="right">20</td><td align="right">15</td><td align="right">8</td><td align="right">5</td><td align="right">65%</td><td align="right">75%</td><td align="right">0.7</td></tr><tr><td align="left">beatle</td><td align="right">20</td><td align="right">9</td><td align="right">7</td><td align="right">7</td><td align="right">59%</td><td align="right">65%</td><td align="right">0.62</td></tr></tbody></table></div><img src="/images/20230831a/image_6.png" alt="" width="1153" height="480" loading="lazy"><p>CreateMLで今回作ったモデルをCoreML　Model形式（<code>.mlmodel</code>）として取得します。</p><p>Outputタグに移動し、右上のGetから、<code>beatleAndStagBeatlesClassifier.mlmodel</code>を任意の場所に保存できます。</p><img src="/images/20230831a/image_7.png" alt="" width="1153" height="553" loading="lazy"><h3 id="アプリへ実装する"><a href="#アプリへ実装する" class="headerlink" title="アプリへ実装する"></a>アプリへ実装する</h3><p>こちらのサイト上部のdownloadからサンプルコード（<code>Vision+Core-ML.xcodeproj</code>）を落としてきます。</p><p><a href="https://developer.apple.com/documentation/vision/classifying_images_with_vision_and_core_ml">https://developer.apple.com/documentation/vision/classifying_images_with_vision_and_core_ml</a></p><p>サンプルコードの<code>Vision+Core-ML.xcodeproj</code>プロジェクトを開き、識別時に使用している分類器を<code>MobileNet.mlmodel</code>から<code>beatleAndStagBeatlesClassifier.mlmodel</code>に修正します。</p><p>具体的には、<code>ImagePredictor.swift</code>の中の　<code>MobileNet.mlmodel</code>から<code>beatleAndStagBeatlesClassifier.mlmodel</code>に書き換える対応のみを行います。</p><figure class="highlight swift"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ImagePredictor</span> &#123;</span><br><span class="line">    <span class="comment">/// - Tag: name</span></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">func</span> <span class="title function_">createImageClassifier</span>() -&gt; <span class="type">VNCoreMLModel</span> &#123;</span><br><span class="line">        <span class="comment">// Use a default model configuration.</span></span><br><span class="line">        <span class="keyword">let</span> defaultConfig <span class="operator">=</span> <span class="type">MLModelConfiguration</span>()</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Create an instance of the image classifier&#x27;s wrapper class.</span></span><br><span class="line">        <span class="keyword">let</span> imageClassifierWrapper <span class="operator">=</span> <span class="keyword">try?</span> beatlesAndStagBeatlesClassifier(configuration: defaultConfig)　<span class="comment">// ここを書き換えています。</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">guard</span> <span class="keyword">let</span> imageClassifier <span class="operator">=</span> imageClassifierWrapper <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="built_in">fatalError</span>(<span class="string">&quot;App failed to create an image classifier model instance.&quot;</span>)</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><p>これで学習させたモデルで撮影した画像が『カブトムシ』か『〇〇クワガタ』かを識別することができます。</p><p><strong>作成したカブトムシ・クワガタを分類するミニアプリ(再掲)</strong></p><p>（これを使えば、道端で遭遇したカブトムシ・クワガタの種類がわかるようになる？）</p><img src="/images/20230831a/beatle_app_2.gif" alt="" width="177" height="384" loading="lazy"><h2 id="最後に"><a href="#最後に" class="headerlink" title="最後に"></a>最後に</h2><p>今回は、CreateMLをつかって機械学習モデルを作ってみることができました。しかし、分類精度はあまり良くなかったため、細部までチューニングができるCreate ML Componentsを使用してモデル作成を行ってみたい思います。</p><p>今後もSwift周りで学習した内容を投稿していきたいと思いますので、その際もお読みいただけると嬉しいです。</p><h2 id="参考リンク"><a href="#参考リンク" class="headerlink" title="参考リンク"></a>参考リンク</h2><p><a href="https://developer.apple.com/machine-learning/create-ml/">https://developer.apple.com/machine-learning/create-ml/</a></p><p><a href="https://developer.apple.com/documentation/createml/">https://developer.apple.com/documentation/createml/</a></p><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0;"><li id="fn:1"><span style="vertical-align: top; padding-right: 10px;">1.</span><span style="vertical-align: top;">医療・ヘルスケア分野での案件や新規ビジネス創出を担う、2020年に誕生した事業部です。設立エピソードは<a href="https://note.future.co.jp/n/n8b57d4bf4604">未来報</a>の記事をご覧ください。</span><a href="#fnref:1" rev="footnote"> ↩</a></li></ol></div></div>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h2 id=&quot;はじめに&quot;&gt;&lt;a href=&quot;#はじめに&quot; class=&quot;headerlink&quot; title=&quot;はじめに&quot;&gt;&lt;/a&gt;はじめに&lt;/h2&gt;&lt;p&gt;こんにちは！HealthCare Innovation Group(HIG)&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a</summary>
        
      
    
    
    
    <category term="DataScience" scheme="https://future-architect.github.io/categories/DataScience/"/>
    
    
    <category term="機械学習" scheme="https://future-architect.github.io/tags/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92/"/>
    
    <category term="iOS" scheme="https://future-architect.github.io/tags/iOS/"/>
    
    <category term="Swift" scheme="https://future-architect.github.io/tags/Swift/"/>
    
    <category term="画像認識" scheme="https://future-architect.github.io/tags/%E7%94%BB%E5%83%8F%E8%AA%8D%E8%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>夏の自由研究連載2023 を始めます</title>
    <link href="https://future-architect.github.io/articles/20230830a/"/>
    <id>https://future-architect.github.io/articles/20230830a/</id>
    <published>2023-08-29T15:00:00.000Z</published>
    <updated>2023-10-02T00:07:27.501Z</updated>
    
    <content type="html"><![CDATA[<img src="/images/20230830a/IMG_3515.JPG" alt="" width="1200" height="800" loading="lazy"><p>こんにちは。技術ブログ運営の伊藤です。</p><p>今回はタイトルの通り、今年も夏の自由研究連載を始めますよ記事です。</p><h2 id="夏の自由研究連載とは"><a href="#夏の自由研究連載とは" class="headerlink" title="夏の自由研究連載とは"></a>夏の自由研究連載とは</h2><p>皆さんも一度は通ったことのある小学生の自由研究。時にはやってみたいことをテーマにして前のめりにやり続けていたり、反対に面倒なことを題材にしてしまったこともあったり、楽しかったり苦かったりする思い出のひとつかもしれません。</p><p>夏の自由研究連載とは、そんな気持ちを思い出しつつ、寄稿者の普段の興味をベースとして、</p><ul><li>普段手をつけられなかったけど、連載を機に何か手をつけてみる</li><li>童心を思い出して、何かをじっくり研究、工作してみる</li></ul><p>…などをブログにする連載です。</p><p>過去の投稿では、低音調理器を自作し、鶏胸肉まで食べるお料理記事や、実際にハードウェアまで含めて研究して記事になっていたので、本当に小学校の時やっていた自由研究のようです。</p><p>実は今年で4年目となり、技術ブログの連載の中ではそれなりに続いている連載の一つです。</p><h2 id="投稿スケジュール"><a href="#投稿スケジュール" class="headerlink" title="投稿スケジュール"></a>投稿スケジュール</h2><p>さて、今年の自由研究連載の投稿スケジュールです。</p><p>夏といえば！なネタから、「自由研究」というテーマに沿って普段自分の領域外のネタなど、幅広いネタが集まるのもこの連載の特徴であり、楽しいポイントの一つであります。</p><div class="scroll"><table><thead><tr><th>Date</th><th>Author</th><th>Title&amp;Theme</th></tr></thead><tbody><tr><td>8&#x2F;31</td><td>橋本竜我</td><td><a href="/articles/20230831a/">CreateMLでカブトムシを分類するミニアプリ開発</a></td></tr><tr><td>9&#x2F;1</td><td>藤井亮佑</td><td><a href="/articles/20230901a/">Unityを使ったVRプラネタリウム開発</a></td></tr><tr><td>9&#x2F;5</td><td>水田祐介</td><td><a href="/articles/20230905a/">Raspberry PiのブラウザからAudiuinoに接続したLCDに文字を表示する</a></td></tr><tr><td>9&#x2F;6</td><td>王紹宇</td><td><a href="/articles/20230906a/">Sentence-Transformersを使ってYouTube動画のセリフを検索する</a></td></tr><tr><td>9&#x2F;8</td><td>清水雄一郎</td><td><a href="/articles/20230908a/">SwiftUIのカスタムアラートダイアログについて考える</a></td></tr><tr><td>9&#x2F;8</td><td>真野隼記</td><td>データカタログツール</td></tr></tbody></table></div><h2 id="最後に"><a href="#最後に" class="headerlink" title="最後に"></a>最後に</h2><p>当の小学生はそろそろ夏休みが終わりそう、もしくは終わってしまった子もいますが、社会人ならではのネタも楽しみですね！</p><p>ブログの投稿内容や順番については変わる可能性はございますが、今年の連載も、これまでの連載も是非読んでみてください！</p><ul><li><a href="/articles/20200726/">2020</a></li><li><a href="/articles/20210823a/">2021</a></li><li><a href="/articles/20220822a/">2022</a></li></ul>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;img src=&quot;/images/20230830a/IMG_3515.JPG&quot; alt=&quot;&quot; width=&quot;1200&quot; height=&quot;800&quot;</summary>
        
      
    
    
    
    <category term="Programming" scheme="https://future-architect.github.io/categories/Programming/"/>
    
    
    <category term="インデックス" scheme="https://future-architect.github.io/tags/%E3%82%A4%E3%83%B3%E3%83%87%E3%83%83%E3%82%AF%E3%82%B9/"/>
    
    <category term="夏休み自由研究" scheme="https://future-architect.github.io/tags/%E5%A4%8F%E4%BC%91%E3%81%BF%E8%87%AA%E7%94%B1%E7%A0%94%E7%A9%B6/"/>
    
  </entry>
  
  <entry>
    <title>クライアント/サーバ構成でみるPlaywright</title>
    <link href="https://future-architect.github.io/articles/20230829a/"/>
    <id>https://future-architect.github.io/articles/20230829a/</id>
    <published>2023-08-28T15:00:00.000Z</published>
    <updated>2023-10-02T00:07:27.500Z</updated>
    
    <content type="html"><![CDATA[<p><a href="/articles/20230821a/">Playwright連載</a>6日目です。</p><h2 id="はじめに"><a href="#はじめに" class="headerlink" title="はじめに"></a>はじめに</h2><p>Playwrightはさまざまな言語でテストを記述することが可能です。</p><p><a href="https://playwright.dev/docs/languages">公式ドキュメント</a>を見ると <a href="https://github.com/microsoft/playwright">JavaScript&#x2F;TypeScript</a> をはじめとし、<a href="https://github.com/microsoft/playwright-python">Python</a> &#x2F; <a href="https://github.com/microsoft/playwright-java">Java</a> &#x2F; <a href="https://github.com/microsoft/playwright-dotnet">.Net</a> がサポートされていることがわかります。<br>そのほかにも<a href="https://github.com/playwright-community/playwright-go">Go</a>や<a href="https://github.com/YusukeIwaki/playwright-ruby-client">Ruby</a>といった言語もサードパーティ製の実装によって利用することが可能です。</p><p>このように幅広い言語をサポートしているのは利用者としてとても嬉しいことです。</p><p>今回はこのような他言語展開を可能にしているPlaywrightのアーキテクチャについて調べました。</p><h2 id="環境情報"><a href="#環境情報" class="headerlink" title="環境情報"></a>環境情報</h2><p>本記事執筆時点のPlaywrightの最新バージョンはv1.37.1であり、本記事の内容及び参照しているドキュメントやソースコードは当該バージョンのものを前提としています。</p><h2 id="Playwright-Architecture"><a href="#Playwright-Architecture" class="headerlink" title="Playwright Architecture"></a>Playwright Architecture</h2><p>通常のテストランナーを利用する場合、あまり意識することはないのですが、Playwrightはクライアント&#x2F;サーバの構成で動作させることが可能です。</p><p>なぜ意識することがないかというと、通常のテストランナーにおいては明示的に指定をしない限りクライアントとサーバはプロセスとして分離せず、同一のプロセスで動作するためです。</p><p>クライアント&#x2F;サーバ構成のイメージは下記の通りです。</p><img src="/images/20230829a/Playwright_Architecture.drawio.png" alt="Playwright_Architecture" width="800" height="320" loading="lazy"><p>サーバ側はWebSocketまたは標準入出力の口をもち、クライアントからのリクエストに応じて各ブラウザに対しての操作を実行します。クライアント側はテストスクリプトに応じてサーバに対してリクエストを送信します。</p><p>図を見ればわかるとおり、クライアント側はPlaywrightが定めるリクエスト&#x2F;レスポンスの形式に従ってWebSocket通信を行うことができればE2Eテストが実行なため、複数言語のサポートが容易となっています。</p><p>クライアント&#x2F;サーバ構成のE2Eテストツールと聞くと<a href="https://www.selenium.dev/">Selenium</a>が有名ですが、こちらも同じく複数の言語をサポートするよう設計されています。</p><p>ただし、PlaywrightはSeleniumよりも遥かに効率的かつ高速に動作するよう設計されており、通常のテストランナーにおいてクライアントとサーバを分離せずに実行できるような作りになっているのは良い点だと言えそうです。</p><h2 id="Playwright-CLI"><a href="#Playwright-CLI" class="headerlink" title="Playwright CLI"></a>Playwright CLI</h2><p>Playwright CLIの<a href="https://github.com/microsoft/playwright/blob/v1.37.1/packages/playwright-core/src/cli/program.ts">ソースコード</a>を読むと、公開されていないCLIのコマンドがいくつかあります。その中でもサーバを起動するコマンドは下記の3つとなります。</p><ul><li><a href="https://github.com/microsoft/playwright/blob/v1.37.1/packages/playwright-core/src/cli/program.ts#L249">run-driver</a></li><li><a href="https://github.com/microsoft/playwright/blob/v1.37.1/packages/playwright-core/src/cli/program.ts#L255">run-server</a></li><li><a href="https://github.com/microsoft/playwright/blob/v1.37.1/packages/playwright-core/src/cli/program.ts#L276">launch-server</a></li></ul><p>簡単に違いを説明します。</p><h3 id="run-driver"><a href="#run-driver" class="headerlink" title="run-driver"></a>run-driver</h3><p>標準入出力を通信経路とするPlaywright Serverを起動します。</p><p>内部実装は<a href="https://github.com/microsoft/playwright/blob/v1.37.1/packages/playwright-core/src/cli/driver.ts#L33">このあたり</a>を見るとJSON形式のメッセージを標準入出力でやりとりしていることがわかります。</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ npx playwright run-driver -h</span><br><span class="line">Usage: npx playwright run-driver [options]</span><br><span class="line"></span><br><span class="line">Options:</span><br><span class="line">  -h, --<span class="built_in">help</span>  display <span class="built_in">help</span> <span class="keyword">for</span> <span class="built_in">command</span></span><br></pre></td></tr></table></figure><h3 id="run-server"><a href="#run-server" class="headerlink" title="run-server"></a>run-server</h3><p>このコマンドはWebSocketを通信経路とするPlaywright Serverを起動します。</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ npx playwright run-server -h</span><br><span class="line">Usage: npx playwright run-server [options]</span><br><span class="line"></span><br><span class="line">Options:</span><br><span class="line">  --port &lt;port&gt;               Server port</span><br><span class="line">  --path &lt;path&gt;               Endpoint Path (default: <span class="string">&quot;/&quot;</span>)</span><br><span class="line">  --max-clients &lt;maxClients&gt;  Maximum clients</span><br><span class="line">  --mode &lt;mode&gt;               Server mode, either <span class="string">&quot;default&quot;</span> or <span class="string">&quot;extension&quot;</span></span><br><span class="line">  -h, --<span class="built_in">help</span>                  display <span class="built_in">help</span> <span class="keyword">for</span> <span class="built_in">command</span></span><br></pre></td></tr></table></figure><p>内部実装は<a href="https://github.com/microsoft/playwright/blob/v1.37.1/packages/playwright-core/src/remote/playwrightConnection.ts#L81">このあたり</a>を見ると、JSON形式のメッセージをWebSocketでやりとりしていることがわかります。</p><h3 id="launch-server"><a href="#launch-server" class="headerlink" title="launch-server"></a>launch-server</h3><p>このコマンドはWebSocketを通信経路するPlaywright Serverを起動します。<br><code>run-server</code> との違いとして <code>run-server</code> コマンドは複数のブラウザに対応したサーバを起動するのに対し、本コマンドは単一のブラウザに対応したサーバを起動します。</p><p>コマンドのオプションを見てもわかる通りブラウザの指定が必須となっています。</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ npx playwright launch-server -h</span><br><span class="line">Usage: npx playwright launch-server [options]</span><br><span class="line"></span><br><span class="line">Options:</span><br><span class="line">  --browser &lt;browserName&gt;         Browser name, one of <span class="string">&quot;chromium&quot;</span>, <span class="string">&quot;firefox&quot;</span> or <span class="string">&quot;webkit&quot;</span></span><br><span class="line">  --config &lt;path-to-config-file&gt;  JSON file with launchServer options</span><br><span class="line">  -h, --<span class="built_in">help</span>                      display <span class="built_in">help</span> <span class="keyword">for</span> <span class="built_in">command</span></span><br></pre></td></tr></table></figure><h3 id="クライアント-x2F-サーバ構成でのテスト実行"><a href="#クライアント-x2F-サーバ構成でのテスト実行" class="headerlink" title="クライアント&#x2F;サーバ構成でのテスト実行"></a>クライアント&#x2F;サーバ構成でのテスト実行</h3><p><code>npm init playwright@latest</code>で作成した初期プロジェクトでテストを実行します。</p><h4 id="サーバサイド"><a href="#サーバサイド" class="headerlink" title="サーバサイド"></a>サーバサイド</h4><p><code>run-server</code>コマンドを利用してPlaywright Serverを8008ポートで起動します。<br>なお、サーバ側のログを出力するため環境変数<code>DEBUG=pw:server</code>を指定します。</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ DEBUG=pw:server npx playwright run-server --port 8008</span><br><span class="line">Listening on ws://127.0.0.1:8008/</span><br></pre></td></tr></table></figure><h4 id="クライアントサイド"><a href="#クライアントサイド" class="headerlink" title="クライアントサイド"></a>クライアントサイド</h4><p><code>playwright.config.ts</code> を編集し、<a href="https://playwright.dev/docs/api/class-testoptions#test-options-connect-options">connectOptions</a>に接続先となる<code>ws://localhost:8008/</code>を指定します。</p><figure class="highlight ts"><table><tr><td class="code"><pre><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="title function_">defineConfig</span>(&#123;</span><br><span class="line">  <span class="comment">// (省略)</span></span><br><span class="line">  <span class="attr">use</span>: &#123;</span><br><span class="line">    <span class="attr">connectOptions</span>: &#123;</span><br><span class="line">      <span class="attr">wsEndpoint</span>: <span class="string">&quot;ws://localhost:8008/&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">  &#125;,</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>テストを実行すると6ケースのテストがパスします。</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ npx playwright <span class="built_in">test</span></span><br><span class="line">Running 6 tests using 4 workers</span><br><span class="line">  6 passed (8.2s)</span><br></pre></td></tr></table></figure><p>サーバ側のログを見ると6ケース（3ブラウザ * 2ケース）のテストのログが出力されていることがわかります。</p><details><summary>ログを見る</summary><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">pw:server [1] serving connection: / +34s</span><br><span class="line">pw:server [2] serving connection: / +3ms</span><br><span class="line">pw:server [3] serving connection: / +2ms</span><br><span class="line">pw:server [1] engaged launch mode <span class="keyword">for</span> <span class="string">&quot;webkit&quot;</span> +12ms</span><br><span class="line">pw:server [4] serving connection: / +7ms</span><br><span class="line">pw:server [3] engaged launch mode <span class="keyword">for</span> <span class="string">&quot;chromium&quot;</span> +2ms</span><br><span class="line">pw:server [2] engaged launch mode <span class="keyword">for</span> <span class="string">&quot;webkit&quot;</span> +2ms</span><br><span class="line">pw:server [4] engaged launch mode <span class="keyword">for</span> <span class="string">&quot;chromium&quot;</span> +89ms</span><br><span class="line">pw:server [2] disconnected. error: undefined +3s</span><br><span class="line">pw:server [2] starting cleanup +1ms</span><br><span class="line">pw:server [2] finished cleanup +74ms</span><br><span class="line">pw:server [1] disconnected. error: undefined +147ms</span><br><span class="line">pw:server [1] starting cleanup +0ms</span><br><span class="line">pw:server [1] finished cleanup +56ms</span><br><span class="line">pw:server [5] serving connection: / +325ms</span><br><span class="line">pw:server [5] engaged launch mode <span class="keyword">for</span> <span class="string">&quot;firefox&quot;</span> +8ms</span><br><span class="line">pw:server [6] serving connection: / +259ms</span><br><span class="line">pw:server [6] engaged launch mode <span class="keyword">for</span> <span class="string">&quot;firefox&quot;</span> +14ms</span><br><span class="line">pw:server [6] disconnected. error: undefined +3s</span><br><span class="line">pw:server [6] starting cleanup +1ms</span><br><span class="line">pw:server [5] disconnected. error: undefined +622ms</span><br><span class="line">pw:server [5] starting cleanup +0ms</span><br><span class="line">pw:server [6] finished cleanup +234ms</span><br><span class="line">pw:server [5] finished cleanup +247ms</span><br><span class="line">pw:server [3] disconnected. error: undefined +37s</span><br><span class="line">pw:server [3] starting cleanup +1ms</span><br><span class="line">pw:server [3] finished cleanup +35ms</span><br><span class="line">pw:server [4] disconnected. error: undefined +22s</span><br><span class="line">pw:server [4] starting cleanup +0ms</span><br><span class="line">pw:server [4] finished cleanup +37ms</span><br></pre></td></tr></table></figure></details><h3 id="別言語のクライアントはどうなっているのか"><a href="#別言語のクライアントはどうなっているのか" class="headerlink" title="別言語のクライアントはどうなっているのか"></a>別言語のクライアントはどうなっているのか</h3><p>各クライアントは実行時にPlaywrightのドライバをダウンロードし、<code>run driver</code>することでPlaywright Serverを立ち上げてテストを実行しているようです。</p><p>Playwrightのドライバは<code>https://playwright.azureedge.net/builds/driver/playwright-$&#123;version&#125;-$&#123;platform&#125;.zip</code>の形式でバージョンとプラットフォームを指定することでダウンロード可能です。<br>例. <a href="https://playwright.azureedge.net/builds/driver/playwright-1.37.1-mac.zip">https://playwright.azureedge.net/builds/driver/playwright-1.37.1-mac.zip</a></p><p>例えば <code>playwright-python</code> を見てみると<a href="https://github.com/microsoft/playwright-python/blob/v1.37.0/setup.py#L45">このあたり</a>でドライバをダウンロードし、<a href="https://github.com/microsoft/playwright-python/blob/v1.37.0/playwright/_impl/_transport.py#L123">このあたり</a>で<code>run-driver</code>をサブプロセスで実行しています。</p><p>なおこのドライバは実行環境にNode.jsランタイムがなくとも実行可能なバイナリとして配布されているため、例えば <code>playwright-python</code> を利用してテストを実行する場合はPythonの実行環境さえあれば良ということになります。</p><h2 id="おわりに"><a href="#おわりに" class="headerlink" title="おわりに"></a>おわりに</h2><p>普段使う分にはあまり意識することのないPlaywrightのアーキテクチャのお話でした。</p><p>本記事で説明している内容の多くが公式のドキュメントでは明文化されていないため、筆者もソースコードを追いながら理解した結果をまとめています。そのため将来的なバージョンアップにより本記事記載の内容が変更されることも十分にあり得ることをご了承いただけますと幸いです。</p><p>もし内容に不備や補足等ありましたらSNSや<a href="https://github.com/future-architect/tech-blog/issues">こちら</a>でご意見いただけますと幸いです。</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;&lt;a href=&quot;/articles/20230821a/&quot;&gt;Playwright連載&lt;/a&gt;6日目です。&lt;/p&gt;
&lt;h2 id=&quot;はじめに&quot;&gt;&lt;a href=&quot;#はじめに&quot; class=&quot;headerlink&quot;</summary>
        
      
    
    
    
    <category term="Programming" scheme="https://future-architect.github.io/categories/Programming/"/>
    
    
    <category term="Playwright" scheme="https://future-architect.github.io/tags/Playwright/"/>
    
  </entry>
  
  <entry>
    <title>PlaywrightをGitHubActions実行したときの初期処理についての試行錯誤</title>
    <link href="https://future-architect.github.io/articles/20230828a/"/>
    <id>https://future-architect.github.io/articles/20230828a/</id>
    <published>2023-08-27T15:00:00.000Z</published>
    <updated>2023-10-02T00:07:27.500Z</updated>
    
    <content type="html"><![CDATA[<p><a href="/articles/20230821a/">Playwright連載</a>5日目です。</p><p>近年PlaywrightやCypressを用いたE2Eテスト（エンドツーエンドテスト）が行われるようになってきました。</p><p>E2Eテストとはソフトウェアやシステムの全体的な動作や機能をテストする手法で、ユーザーが実際に行う操作を模倣したテストを行い、アプリケーションが予想通りに機能するかどうかを確認していきます。</p><p>具体的な操作手順をテストケースとして作成し、予期される結果との整合性を確認していくわけです。バグの早期発見のためにも、E2Eテストの自動化を行い、さらにはCIに組み込み定期的に実行していきたい。そしていざ組み込んでみると、CIの実行時間が気になってきます。</p><p>テスト自体の実行時間も短縮を行っていきたいですが、テストが始まるまでのイニシャライズ、初期処理の時間もそこそこ掛かってしまうもの。</p><p>今回はどのように設定していけば処理時間が短くなるか。試行錯誤とその結果を報告したいと思います。</p><h2 id="実行するテストの記述"><a href="#実行するテストの記述" class="headerlink" title="実行するテストの記述"></a>実行するテストの記述</h2><p>はじめに以下のコマンドでテスト環境を作成します。</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">mkdir</span> playwright-ci-test &amp;&amp; <span class="built_in">cd</span> playwright-ci-test</span><br><span class="line">$ git init</span><br><span class="line">$ npm init playwright@latest</span><br><span class="line">Initializing project <span class="keyword">in</span> <span class="string">&#x27;.&#x27;</span></span><br><span class="line">√ Do you want to use TypeScript or JavaScript? · JavaScript</span><br><span class="line">√ Where to put your end-to-end tests? · tests</span><br><span class="line">√ Add a GitHub Actions workflow? (y/N) · <span class="literal">true</span></span><br><span class="line">√ Install Playwright browsers (can be <span class="keyword">done</span> manually via <span class="string">&#x27;npx playwright install&#x27;</span>)? (Y/n) · <span class="literal">true</span></span><br><span class="line">（省略）</span><br><span class="line">Happy hacking! 🎭</span><br></pre></td></tr></table></figure><p>続いて、共通して実行するテストを用意します。以下のようなspecファイルを用意しました。フューチャー ブログのトップページにアクセスして HTMLのタイトルが適切であるかを確認するだけの簡単なテストです。また、Playwrightでは様々なブラウザでテストが行えますが、今回はChromiumのみでのテストとします。</p><figure class="highlight ts"><table><tr><td class="code"><pre><span class="line"><span class="comment">// tests/example.spec.ts</span></span><br><span class="line"><span class="keyword">import</span> &#123; test, expect &#125; <span class="keyword">from</span> <span class="string">&#x27;@playwright/test&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="title function_">test</span>(<span class="string">&#x27;has title&#x27;</span>, <span class="keyword">async</span> (&#123; page &#125;) =&gt; &#123;</span><br><span class="line">  <span class="keyword">await</span> page.<span class="title function_">goto</span>(<span class="string">&#x27;https://future-architect.github.io/&#x27;</span>);</span><br><span class="line">  <span class="keyword">await</span> <span class="title function_">expect</span>(page).<span class="title function_">toHaveTitle</span>(<span class="regexp">/フューチャー技術ブログ/</span>);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><h2 id="試行錯誤-その1-NPM-インストールでの初期設定"><a href="#試行錯誤-その1-NPM-インストールでの初期設定" class="headerlink" title="試行錯誤 その1 NPM インストールでの初期設定"></a>試行錯誤 その1 NPM インストールでの初期設定</h2><p>まずはPlaywrightのドキュメントを確認してみましょう。</p><p><a href="https://playwright.dev/docs/ci-intro">CI GitHub Actions | Playwright</a> というページにGitHub ActionsでPlaywrightを実行する際のymlファイルのサンプルが記載されています。こちらに書かれているymlファイルは <code>npm init playwright@latest</code> の実行時に <code>Add a GitHub Actions workflow? (y/N)</code> で <code>y</code> を押したときに生成されるymlファイルと同一のものになります。</p><p>作成されたymlファイルは、checkoutと依存ライブラリインストール後に、Playwrightのインストールとテスト実行、最後にテストレポートのアップロードという構成になっています。<br>今回は初期処理についての比較を行いたいので、テストレポートのアップロード部分を削除して、以下のようなymlファイルを配置しました。</p><figure class="highlight yaml"><figcaption><span>name Playwright Tests 1</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="attr">on:</span> <span class="string">push</span></span><br><span class="line"><span class="attr">jobs:</span></span><br><span class="line">  <span class="attr">test:</span></span><br><span class="line">    <span class="attr">timeout-minutes:</span> <span class="number">60</span></span><br><span class="line">    <span class="attr">runs-on:</span> <span class="string">ubuntu-latest</span></span><br><span class="line">    <span class="attr">steps:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">uses:</span> <span class="string">actions/checkout@v3</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">uses:</span> <span class="string">actions/setup-node@v3</span></span><br><span class="line">      <span class="attr">with:</span></span><br><span class="line">        <span class="attr">node-version:</span> <span class="number">18</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Install</span> <span class="string">dependencies</span></span><br><span class="line">      <span class="attr">run:</span> <span class="string">npm</span> <span class="string">ci</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Install</span> <span class="string">Playwright</span> <span class="string">Browsers</span></span><br><span class="line">      <span class="attr">run:</span> <span class="string">npx</span> <span class="string">playwright</span> <span class="string">install</span> <span class="string">--with-deps</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Run</span> <span class="string">Playwright</span> <span class="string">tests</span></span><br><span class="line">      <span class="attr">run:</span> <span class="string">npx</span> <span class="string">playwright</span> <span class="string">test</span></span><br></pre></td></tr></table></figure><p>こちらをGitHub Actionsで実行してみると33秒かかりました。インストール時のGitHub Action側の混み具合やDL速度によって時間は上下するかと思いますので、実行時間に関してはあくまで目安としてご覧ください。</p><img src="/images/20230828a/image.png" alt="image.png" width="654" height="457" loading="lazy"><p>今回の場合テストしか入っていないレポジトリなので、<code>npm ci</code> (Install dependencies) の時間が最小限に収まっています。例えば、フロントエンドのレポジトリにE2Eテストを相乗りさせている場合には依存ライブラリのインストール時間が余計にかかってしまいます。</p><h2 id="試行錯誤-その2-サブディレクトリでのインストール"><a href="#試行錯誤-その2-サブディレクトリでのインストール" class="headerlink" title="試行錯誤 その2 サブディレクトリでのインストール"></a>試行錯誤 その2 サブディレクトリでのインストール</h2><p>相乗りさせたレポジトリの場合に依存ライブラリのインストール時間が余計に掛かってしまうので、サブディレクトリにPlaywrightのもろもろを配置する場合は以下のようなymlファイルを用意することになります。</p><figure class="highlight yaml"><figcaption><span># .github\workflows\playwright-2.yml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="attr">name:</span> <span class="string">Playwright</span> <span class="string">Tests</span> <span class="number">2</span></span><br><span class="line"><span class="attr">on:</span> <span class="string">push</span></span><br><span class="line"><span class="attr">jobs:</span></span><br><span class="line">  <span class="attr">test:</span></span><br><span class="line">    <span class="attr">timeout-minutes:</span> <span class="number">60</span></span><br><span class="line">    <span class="attr">runs-on:</span> <span class="string">ubuntu-latest</span></span><br><span class="line">    <span class="attr">steps:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">uses:</span> <span class="string">actions/checkout@v3</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">uses:</span> <span class="string">actions/setup-node@v3</span></span><br><span class="line">      <span class="attr">with:</span></span><br><span class="line">        <span class="attr">node-version:</span> <span class="number">18</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Install</span> <span class="string">dependencies</span></span><br><span class="line">      <span class="attr">run:</span> <span class="string">npm</span> <span class="string">--prefix</span> <span class="string">./playwright</span> <span class="string">ci</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Install</span> <span class="string">Playwright</span> <span class="string">Browsers</span></span><br><span class="line">      <span class="attr">run:</span> <span class="string">(cd</span> <span class="string">playwright</span> <span class="string">&amp;&amp;</span> <span class="string">npx</span> <span class="string">playwright</span> <span class="string">install</span> <span class="string">--with-deps</span> <span class="string">&amp;&amp;</span> <span class="string">cd</span> <span class="string">-)</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Run</span> <span class="string">Playwright</span> <span class="string">tests</span></span><br><span class="line">      <span class="attr">run:</span> <span class="string">(cd</span> <span class="string">playwright</span> <span class="string">&amp;&amp;</span> <span class="string">npx</span> <span class="string">playwright</span> <span class="string">test</span> <span class="string">&amp;&amp;</span> <span class="string">cd</span> <span class="string">-)</span></span><br></pre></td></tr></table></figure><p>そして、レポジトリに<code>playwright</code>というディレクトリを作成し、その中で<code>npm init playwright@latest</code>を実行。その1と同様にspecファイルを配置しました。</p><p>こちらをGitHub Actionsで実行してみると29秒かかりました。</p><img src="/images/20230828a/image_2.png" alt="" width="658" height="462" loading="lazy"><p>こちらも実行時間はその1とほぼ同程度。Playwightでのテストレポジトリであればその1の構成、そうでない場合は、依存ライブラリのインストール時間を削減するためにもその2の構成が良いのではと考えています。</p><h2 id="試行錯誤-その3-playwright-github-actionを使う"><a href="#試行錯誤-その3-playwright-github-actionを使う" class="headerlink" title="試行錯誤 その3 playwright-github-actionを使う"></a>試行錯誤 その3 playwright-github-actionを使う</h2><p>こちらの方法は非推奨です。</p><p>以前は <code>microsoft/playwright-github-action</code> というPlaywright用のGitHub Actionが用意されていました。</p><p><a href="https://github.com/microsoft/playwright-github-action">microsoft&#x2F;playwright-github-action: Run Playwright tests on GitHub Actions</a></p><p>現在もレポジトリは残っていますが、READMEに「❌ You don’t need this GitHub Action」と非推奨である旨が大きく書かれています。</p><p>非推奨である理由として、どのバージョンのPlaywrightが実行されているかわからないから、と書かれています。おそらくサポート上の問題があったのでしょう。</p><p>こちらの<code>microsoft/playwright-github-action</code>を動かそうとすると以下のようなymlファイルになるかと思います。</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># .github\workflows\playwright-3.yml</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">Playwright</span> <span class="string">Tests</span> <span class="number">3</span></span><br><span class="line"><span class="attr">on:</span> <span class="string">push</span></span><br><span class="line"><span class="attr">jobs:</span></span><br><span class="line">  <span class="attr">test:</span></span><br><span class="line">    <span class="attr">timeout-minutes:</span> <span class="number">60</span></span><br><span class="line">    <span class="attr">runs-on:</span> <span class="string">ubuntu-latest</span></span><br><span class="line">    <span class="attr">steps:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">uses:</span> <span class="string">actions/checkout@v3</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">uses:</span> <span class="string">actions/setup-node@v3</span></span><br><span class="line">      <span class="attr">with:</span></span><br><span class="line">        <span class="attr">node-version:</span> <span class="number">18</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">uses:</span> <span class="string">microsoft/playwright-github-action@v1</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Install</span> <span class="string">dependencies</span></span><br><span class="line">      <span class="attr">run:</span> <span class="string">npm</span> <span class="string">ci</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Install</span> <span class="string">Playwright</span> <span class="string">Browsers</span></span><br><span class="line">      <span class="attr">run:</span> <span class="string">npx</span> <span class="string">playwright</span> <span class="string">install</span> <span class="string">--with-deps</span> <span class="string">chromium</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Run</span> <span class="string">Playwright</span> <span class="string">tests</span></span><br><span class="line">      <span class="attr">run:</span> <span class="string">npx</span> <span class="string">playwright</span> <span class="string">test</span></span><br></pre></td></tr></table></figure><p>Playwrightのインストール部分(<code>npx playwright install --with-deps chromium</code>)は本来不要であったと思いますが、レポジトリが半年以上更新されていないため、インストールをせず実行すると <code>npx playwright test</code> のタイミングで以下のエラーが出て止まってしまいます。</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">Error: browserType.launch: Executable doesn<span class="string">&#x27;t exist at /home/runner/.cache/ms-playwright/chromium-1071/chrome-linux/chrome</span></span><br><span class="line"><span class="string">╔═════════════════════════════════════════════════════════════════════════╗</span></span><br><span class="line"><span class="string">║ Looks like Playwright Test or Playwright was just installed or updated. ║</span></span><br><span class="line"><span class="string">║ Please run the following command to download new browsers:              ║</span></span><br><span class="line"><span class="string">║                                                                         ║</span></span><br><span class="line"><span class="string">║     npx playwright install                                              ║</span></span><br><span class="line"><span class="string">║                                                                         ║</span></span><br><span class="line"><span class="string">║ &lt;3 Playwright Team                                                      ║</span></span><br><span class="line"><span class="string">╚═════════════════════════════════════════════════════════════════════════╝</span></span><br></pre></td></tr></table></figure><p>最新版となるようインストールを行い、GitHub Actionsで実行してみると76秒かかりました。</p><img src="/images/20230828a/image_3.png" alt="" width="657" height="504" loading="lazy"><p><code>microsoft/playwright-github-action</code> と <code>npx playwright install</code> で二度手間となり長くなった、と考えることもできますが、<code>microsoft/playwright-github-action</code> 単体でもほどほどに掛かっています。</p><p>このGitHub Actionの活用を考えるよりは、現在推奨されている方法での実行を検討した方がよいでしょう。</p><h2 id="試行錯誤-その4-コンテナでの環境構築"><a href="#試行錯誤-その4-コンテナでの環境構築" class="headerlink" title="試行錯誤 その4 コンテナでの環境構築"></a>試行錯誤 その4 コンテナでの環境構築</h2><p>これまではnpmを用いて実行環境を作ってきましたが、GitHub Actionsではコンテナイメージを読みこんでその中で実行することもできます。</p><p>今回はplaywrightの用意している <code>mcr.microsoft.com/playwright</code> のコンテナを利用し、以下のようなymlファイルを配置しました。</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># .github\workflows\playwright-4.yml</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">Playwright</span> <span class="string">Tests</span> <span class="number">4</span></span><br><span class="line"><span class="attr">on:</span> <span class="string">push</span></span><br><span class="line"><span class="attr">jobs:</span></span><br><span class="line">  <span class="attr">test:</span></span><br><span class="line">    <span class="attr">timeout-minutes:</span> <span class="number">60</span></span><br><span class="line">    <span class="attr">runs-on:</span> <span class="string">ubuntu-latest</span></span><br><span class="line">    <span class="attr">container:</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">mcr.microsoft.com/playwright:v1.36.1-jammy</span></span><br><span class="line">    <span class="attr">steps:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">uses:</span> <span class="string">actions/checkout@v3</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">uses:</span> <span class="string">actions/setup-node@v3</span></span><br><span class="line">      <span class="attr">with:</span></span><br><span class="line">        <span class="attr">node-version:</span> <span class="number">18</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Install</span> <span class="string">dependencies</span></span><br><span class="line">      <span class="attr">run:</span> <span class="string">npm</span> <span class="string">ci</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Install</span> <span class="string">Playwright</span> <span class="string">Browsers</span></span><br><span class="line">      <span class="attr">run:</span> <span class="string">npx</span> <span class="string">playwright</span> <span class="string">install</span> <span class="string">--with-deps</span> <span class="string">chromium</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Run</span> <span class="string">your</span> <span class="string">tests</span></span><br><span class="line">      <span class="attr">run:</span> <span class="string">npx</span> <span class="string">playwright</span> <span class="string">test</span></span><br></pre></td></tr></table></figure><p>こちらをGitHub Actionsで実行してみると54秒かかりました。</p><img src="/images/20230828a/image_4.png" alt="" width="656" height="540" loading="lazy"><p>その1・その2と比較すると、<code>Install Playwright Browsers</code> の実行時間が大幅に短縮されています。</p><p>実行ログを確認してみると、コンテナ内にPlaywrightがすでに含まれているためアップデートの確認処理のみで終えられていることがわかります。</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">Run npx playwright install --with-deps chromium</span><br><span class="line">  npx playwright install --with-deps chromium</span><br><span class="line">  shell: sh -e &#123;0&#125;</span><br><span class="line">Installing dependencies...</span><br><span class="line">（省略）</span><br><span class="line">0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.</span><br></pre></td></tr></table></figure><p>しかしながら <code>Initialize container</code> で34秒掛かっており、他の方法と比べて大きく優位かとも言えないといったところ。</p><p>コンテナでの環境構築のメリットとしては、Playwightの実行時に大量のプラグインを必要とする場合や複数ブラウザでのテストを並列にせず実行する場合などが考えられます。つまり、依存ライブラリのインストールに時間がとても掛かってしまう場合ですね。</p><p>逆にデメリットとしては、コンテナ初期化の時間がかかってしまうこと。そして、Playwightのアップデートやコンテナのアップデートに追従してymlファイルの更新を掛けていかなければいけないことでしょうか。</p><p>一般的な環境には向かないとは思いますが、もしかするとコンテナ構築が銀の弾丸となるプロジェクトもあるのかもしれません。</p><h2 id="まとめ"><a href="#まとめ" class="headerlink" title="まとめ"></a>まとめ</h2><p>PlaywrightをCIで実行する際にどのようなymlファイルを書けばGitHub Actionsでの初期処理にかかる時間を短くできるかを試行錯誤しました。</p><p>結果的には、Playwright専用のレポジトリを作る、もしくはサブディレクトリの中で環境を構築。そのあとはnpmでの環境構築を行うのが良さそうだ、という結果になりました。</p><p>何かしらの参考になれば幸いです。</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;&lt;a</summary>
        
      
    
    
    
    <category term="Programming" scheme="https://future-architect.github.io/categories/Programming/"/>
    
    
    <category term="GitHubActions" scheme="https://future-architect.github.io/tags/GitHubActions/"/>
    
    <category term="Playwright" scheme="https://future-architect.github.io/tags/Playwright/"/>
    
  </entry>
  
</feed>
